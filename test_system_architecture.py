#!/usr/bin/env python3
"""
ç³»ç»Ÿæ¶æ„æµ‹è¯•
æµ‹è¯•LLMæ¥å£é›†æˆçš„ç³»ç»Ÿæ¶æ„ï¼Œä¸ä¾èµ–å¤–éƒ¨æœåŠ¡
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from aienhance import (
    create_system,
    MemorySystemConfig,
    ModelConfig,
    create_model_config,
    create_chat_message,
    MessageRole,
    LLMProviderFactory,
    EmbeddingProviderFactory
)


def test_module_imports():
    """æµ‹è¯•æ¨¡å—å¯¼å…¥"""
    print("\n" + "="*60)
    print("ğŸ“¦ æµ‹è¯•æ¨¡å—å¯¼å…¥")
    print("="*60)
    
    try:
        # æµ‹è¯•LLMç›¸å…³å¯¼å…¥
        from aienhance.llm import (
            LLMProvider, EmbeddingProvider, ChatMessage, ChatResponse,
            ModelConfig, MessageRole, LLMProviderFactory
        )
        print("âœ… LLMæ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•è®°å¿†ç³»ç»Ÿå¯¼å…¥
        from aienhance.memory import (
            MemorySystem, MemorySystemFactory, MemoryType
        )
        print("âœ… è®°å¿†ç³»ç»Ÿæ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•æ ¸å¿ƒç³»ç»Ÿå¯¼å…¥
        from aienhance.core import (
            MemoryCognitiveSystem, SystemFactory
        )
        print("âœ… æ ¸å¿ƒç³»ç»Ÿæ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_factory_registration():
    """æµ‹è¯•å·¥å‚ç±»æ³¨å†Œæœºåˆ¶"""
    print("\n" + "="*60)
    print("ğŸ­ æµ‹è¯•å·¥å‚ç±»æ³¨å†Œæœºåˆ¶")
    print("="*60)
    
    try:
        # æ£€æŸ¥LLMæä¾›å•†æ³¨å†Œ
        llm_providers = LLMProviderFactory.get_supported_providers()
        print(f"ğŸ“‹ æ”¯æŒçš„LLMæä¾›å•†: {llm_providers}")
        
        expected_llm_providers = ["ollama", "openai", "anthropic"]
        for provider in expected_llm_providers:
            if provider in llm_providers:
                print(f"âœ… {provider.upper()} LLMé€‚é…å™¨å·²æ³¨å†Œ")
            else:
                print(f"âš ï¸ {provider.upper()} LLMé€‚é…å™¨æœªæ³¨å†Œ")
        
        # æ£€æŸ¥åµŒå…¥æä¾›å•†æ³¨å†Œ
        embedding_providers = EmbeddingProviderFactory.get_supported_providers()
        print(f"ğŸ“‹ æ”¯æŒçš„åµŒå…¥æä¾›å•†: {embedding_providers}")
        
        expected_embedding_providers = ["ollama", "openai"]
        for provider in expected_embedding_providers:
            if provider in embedding_providers:
                print(f"âœ… {provider.upper()} åµŒå…¥é€‚é…å™¨å·²æ³¨å†Œ")
            else:
                print(f"âš ï¸ {provider.upper()} åµŒå…¥é€‚é…å™¨æœªæ³¨å†Œ")
        
        return len(llm_providers) > 0 and len(embedding_providers) > 0
        
    except Exception as e:
        print(f"âŒ å·¥å‚ç±»æ³¨å†Œæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_config_creation():
    """æµ‹è¯•é…ç½®åˆ›å»º"""
    print("\n" + "="*60)
    print("âš™ï¸ æµ‹è¯•é…ç½®åˆ›å»º")
    print("="*60)
    
    try:
        # æµ‹è¯•LLMé…ç½®åˆ›å»º
        llm_config = create_model_config(
            provider="ollama",
            model_name="test-model",
            api_base="http://localhost:11434",
            temperature=0.7,
            max_tokens=500
        )
        print(f"âœ… LLMé…ç½®åˆ›å»ºæˆåŠŸ: {llm_config.provider}/{llm_config.model_name}")
        
        # æµ‹è¯•è®°å¿†ç³»ç»Ÿé…ç½®åˆ›å»º
        memory_config = MemorySystemConfig(
            system_type="mirix",
            api_key="test-key",
            api_base="http://localhost:8000"
        )
        print(f"âœ… è®°å¿†ç³»ç»Ÿé…ç½®åˆ›å»ºæˆåŠŸ: {memory_config.system_type}")
        
        # æµ‹è¯•èŠå¤©æ¶ˆæ¯åˆ›å»º
        message = create_chat_message("user", "æµ‹è¯•æ¶ˆæ¯")
        print(f"âœ… èŠå¤©æ¶ˆæ¯åˆ›å»ºæˆåŠŸ: {message.role.value}")
        
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®åˆ›å»ºæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_system_creation():
    """æµ‹è¯•ç³»ç»Ÿåˆ›å»º"""
    print("\n" + "="*60)
    print("ğŸ› ï¸ æµ‹è¯•ç³»ç»Ÿåˆ›å»º")
    print("="*60)
    
    try:
        # æµ‹è¯•é»˜è®¤ç³»ç»Ÿåˆ›å»º
        system1 = create_system(system_type="default")
        print(f"âœ… é»˜è®¤ç³»ç»Ÿåˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ•™è‚²ç³»ç»Ÿåˆ›å»º
        system2 = create_system(system_type="educational")
        print(f"âœ… æ•™è‚²ç³»ç»Ÿåˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•ç ”ç©¶ç³»ç»Ÿåˆ›å»º
        system3 = create_system(system_type="research")
        print(f"âœ… ç ”ç©¶ç³»ç»Ÿåˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å¸¦é…ç½®çš„ç³»ç»Ÿåˆ›å»ºï¼ˆä¸åˆå§‹åŒ–å¤–éƒ¨æœåŠ¡ï¼‰
        system4 = create_system(
            system_type="default",
            llm_provider="ollama",
            llm_model_name="test-model",
            llm_api_base="http://localhost:11434"
        )
        print(f"âœ… å¸¦LLMé…ç½®çš„ç³»ç»Ÿåˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
        status = system4.get_system_status()
        print(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€: åˆå§‹åŒ–={status['initialized']}")
        
        if status.get('llm_provider'):
            print(f"ğŸ¤– LLMé…ç½®: {status['llm_provider']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿåˆ›å»ºæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_provider_instantiation():
    """æµ‹è¯•æä¾›å•†å®ä¾‹åŒ–"""
    print("\n" + "="*60)
    print("ğŸ­ æµ‹è¯•æä¾›å•†å®ä¾‹åŒ–")
    print("="*60)
    
    try:
        success_count = 0
        
        # æµ‹è¯•å„ä¸ªLLMæä¾›å•†çš„å®ä¾‹åŒ–
        llm_configs = [
            ("ollama", "test-model"),
            ("openai", "gpt-3.5-turbo"),
            ("anthropic", "claude-3-haiku-20240307")
        ]
        
        for provider, model in llm_configs:
            try:
                config = create_model_config(
                    provider=provider,
                    model_name=model,
                    api_base="http://localhost:11434" if provider == "ollama" else None
                )
                
                llm_provider = LLMProviderFactory.create_provider(config)
                print(f"âœ… {provider.upper()} LLMæä¾›å•†å®ä¾‹åŒ–æˆåŠŸ")
                success_count += 1
                
                # æ£€æŸ¥æä¾›å•†ä¿¡æ¯
                info = llm_provider.get_model_info()
                print(f"   ğŸ“‹ æ¨¡å‹ä¿¡æ¯: {info}")
                
            except Exception as e:
                print(f"âš ï¸ {provider.upper()} LLMæä¾›å•†å®ä¾‹åŒ–å¤±è´¥: {e}")
        
        # æµ‹è¯•åµŒå…¥æä¾›å•†å®ä¾‹åŒ–
        embedding_configs = [
            ("ollama", "test-embedding"),
            ("openai", "text-embedding-ada-002")
        ]
        
        for provider, model in embedding_configs:
            try:
                config = create_model_config(
                    provider=provider,
                    model_name=model,
                    api_base="http://localhost:11434" if provider == "ollama" else None
                )
                
                embedding_provider = EmbeddingProviderFactory.create_provider(config)
                print(f"âœ… {provider.upper()} åµŒå…¥æä¾›å•†å®ä¾‹åŒ–æˆåŠŸ")
                success_count += 1
                
            except Exception as e:
                print(f"âš ï¸ {provider.upper()} åµŒå…¥æä¾›å•†å®ä¾‹åŒ–å¤±è´¥: {e}")
        
        print(f"ğŸ“Š æä¾›å•†å®ä¾‹åŒ–æˆåŠŸç‡: {success_count}/{len(llm_configs) + len(embedding_configs)}")
        return success_count > 0
        
    except Exception as e:
        print(f"âŒ æä¾›å•†å®ä¾‹åŒ–æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_system_architecture():
    """æµ‹è¯•ç³»ç»Ÿæ¶æ„å®Œæ•´æ€§"""
    print("\n" + "="*60)
    print("ğŸ—ï¸ æµ‹è¯•ç³»ç»Ÿæ¶æ„å®Œæ•´æ€§")
    print("="*60)
    
    try:
        # åˆ›å»ºå®Œæ•´é…ç½®çš„ç³»ç»Ÿ
        system = create_system(
            system_type="educational",
            llm_provider="ollama",
            llm_model_name="test-model"
        )
        
        # æ£€æŸ¥ç³»ç»Ÿç»„ä»¶
        components = {
            "ç”¨æˆ·å»ºæ¨¡å™¨": hasattr(system, 'user_modeler'),
            "æƒ…å¢ƒåˆ†æå™¨": hasattr(system, 'context_analyzer'),
            "è®°å¿†æ¿€æ´»å™¨": hasattr(system, 'memory_activator'),
            "è¯­ä¹‰å¢å¼ºå™¨": hasattr(system, 'semantic_enhancer'),
            "ç±»æ¯”æ¨ç†å™¨": hasattr(system, 'analogy_reasoner'),
            "è‡ªé€‚åº”è¾“å‡º": hasattr(system, 'adaptive_output'),
            "LLMæä¾›å•†": hasattr(system, 'llm_provider'),
            "åµŒå…¥æä¾›å•†": hasattr(system, 'embedding_provider'),
            "è®°å¿†ç³»ç»Ÿ": hasattr(system, 'memory_system')
        }
        
        for component, exists in components.items():
            if exists:
                print(f"âœ… {component}: å·²åˆå§‹åŒ–")
            else:
                print(f"âš ï¸ {component}: æœªåˆå§‹åŒ–")
        
        # æ£€æŸ¥ç³»ç»Ÿé…ç½®
        status = system.get_system_status()
        print(f"\nğŸ“Š ç³»ç»ŸçŠ¶æ€è¯¦æƒ…:")
        print(f"  - åˆå§‹åŒ–çŠ¶æ€: {status['initialized']}")
        print(f"  - ç”¨æˆ·æ•°é‡: {status['user_count']}")
        print(f"  - ä¼šè¯æ•°é‡: {status['session_count']}")
        
        # æµ‹è¯•ç³»ç»Ÿæ–¹æ³•æ˜¯å¦å¯è°ƒç”¨ï¼ˆä¸å®é™…æ‰§è¡Œç½‘ç»œè¯·æ±‚ï¼‰
        callable_methods = [
            "process_query",
            "get_system_status", 
            "reset_session",
            "export_user_profile"
        ]
        
        for method in callable_methods:
            if hasattr(system, method) and callable(getattr(system, method)):
                print(f"âœ… {method}: æ–¹æ³•å¯è°ƒç”¨")
            else:
                print(f"âŒ {method}: æ–¹æ³•ä¸å¯è°ƒç”¨")
        
        return sum(components.values()) >= len(components) * 0.7  # è‡³å°‘70%çš„ç»„ä»¶æ­£å¸¸
        
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿæ¶æ„æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹LLMæ¥å£é›†æˆæ¶æ„æµ‹è¯•")
    print("æ—¶é—´:", asyncio.get_event_loop().time())
    
    test_results = {}
    
    # æ‰§è¡Œæµ‹è¯•
    tests = [
        ("æ¨¡å—å¯¼å…¥", test_module_imports),
        ("å·¥å‚æ³¨å†Œ", test_factory_registration),
        ("é…ç½®åˆ›å»º", test_config_creation),
        ("ç³»ç»Ÿåˆ›å»º", test_system_creation),
        ("æä¾›å•†å®ä¾‹åŒ–", test_provider_instantiation),
    ]
    
    # åŒæ­¥æµ‹è¯•
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            result = test_func()
            test_results[test_name] = "âœ… é€šè¿‡" if result else "âš ï¸ éƒ¨åˆ†å¤±è´¥"
        except Exception as e:
            test_results[test_name] = f"âŒ å¤±è´¥: {e}"
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
    
    # å¼‚æ­¥æµ‹è¯•
    async def run_async_tests():
        async_tests = [
            ("ç³»ç»Ÿæ¶æ„", test_system_architecture)
        ]
        
        for test_name, test_func in async_tests:
            print(f"\n{'='*20} {test_name} {'='*20}")
            try:
                result = await test_func()
                test_results[test_name] = "âœ… é€šè¿‡" if result else "âš ï¸ éƒ¨åˆ†å¤±è´¥"
            except Exception as e:
                test_results[test_name] = f"âŒ å¤±è´¥: {e}"
                print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
    
    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    asyncio.run(run_async_tests())
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“‹ æ¶æ„æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*60)
    
    for test_name, result in test_results.items():
        print(f"{test_name}: {result}")
    
    # ç»Ÿè®¡
    passed = sum(1 for r in test_results.values() if "âœ…" in r)
    partial = sum(1 for r in test_results.values() if "âš ï¸" in r)
    failed = sum(1 for r in test_results.values() if "âŒ" in r)
    
    print(f"\nğŸ“Š æµ‹è¯•ç»Ÿè®¡: é€šè¿‡={passed}, éƒ¨åˆ†å¤±è´¥={partial}, å¤±è´¥={failed}")
    
    if passed == len(test_results):
        print("ğŸ‰ æ‰€æœ‰æ¶æ„æµ‹è¯•é€šè¿‡ï¼LLMé›†æˆæ¶æ„æ­£å¸¸ã€‚")
        return True
    elif passed + partial > 0:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•é€šè¿‡ï¼Œç³»ç»Ÿæ¶æ„åŸºæœ¬æ­£å¸¸ã€‚")
        return True
    else:
        print("âŒ æ¶æ„æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿå®ç°ã€‚")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)