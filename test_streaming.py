#!/usr/bin/env python3
"""
æµ‹è¯•LLMæµå¼è°ƒç”¨åŠŸèƒ½
"""

import asyncio
import logging
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

import aienhance

def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    log_level = "INFO"
    log_format = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    
    logging.basicConfig(
        level=getattr(logging, log_level),
        format=log_format,
        handlers=[
            logging.StreamHandler(sys.stdout)
        ],
        force=True
    )
    
    # è®¾ç½® aienhance æ¨¡å—çš„æ—¥å¿—çº§åˆ«
    aienhance_logger = logging.getLogger('aienhance')
    aienhance_logger.setLevel(getattr(logging, log_level))
    
    return logging.getLogger(__name__)

logger = setup_logging()

async def test_streaming():
    """æµ‹è¯•æµå¼åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•LLMæµå¼è°ƒç”¨åŠŸèƒ½")
    print("=" * 60)
    
    try:
        # åˆ›å»ºç³»ç»Ÿ
        logger.info("åˆ›å»ºæ•™è‚²ç³»ç»Ÿ...")
        system = aienhance.create_educational_system(
            llm_provider="ollama",
            llm_model_name="qwen3:8b",
            memory_provider="none",  # ç®€åŒ–æµ‹è¯•ï¼Œä¸ä½¿ç”¨è®°å¿†ç³»ç»Ÿ
            config={
                "temperature": 0.7,
                "max_tokens": None,  # æ— é•¿åº¦é™åˆ¶
                "ollama_base_url": "http://localhost:11434",
            }
        )
        
        # åˆå§‹åŒ–
        logger.info("åˆå§‹åŒ–ç³»ç»Ÿ...")
        success = await system.initialize()
        if not success:
            print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            return
            
        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼Œå¼€å§‹æµ‹è¯•æµå¼å“åº”...")
        
        # æµ‹è¯•é—®é¢˜
        test_query = "è¯·è¯¦ç»†è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼ŒåŒ…æ‹¬å…¶ä¸»è¦ç±»å‹ã€åº”ç”¨åœºæ™¯å’Œå‘å±•è¶‹åŠ¿"
        
        print(f"\nğŸ“ æµ‹è¯•é—®é¢˜: {test_query}")
        print("\nğŸ”„ å¼€å§‹æµå¼å¤„ç†...")
        print("-" * 60)
        
        # å¤„ç†æŸ¥è¯¢
        result = await system.process(
            user_id="test_user",
            query=test_query,
            session_context={"test_mode": True}
        )
        
        print("-" * 60)
        
        if result.success:
            print("âœ… æµå¼å¤„ç†å®Œæˆ")
            print(f"ğŸ“Š å¤„ç†ç»“æœé•¿åº¦: {len(str(result.data))}")
            
            # æ˜¾ç¤ºæœ€ç»ˆå“åº”
            final_response = result.data.get("layer_outputs", {}).get("behavior", {}).get("adapted_response", {})
            if final_response:
                response_content = final_response.get("response_content", "æ— å“åº”å†…å®¹")
                print(f"ğŸ“ æœ€ç»ˆå“åº”é•¿åº¦: {len(response_content)}")
                print(f"ğŸ¯ å“åº”é¢„è§ˆ: {response_content[:200]}...")
            else:
                print("âš ï¸ æœªæ‰¾åˆ°æœ€ç»ˆå“åº”")
                
        else:
            print(f"âŒ å¤„ç†å¤±è´¥: {result.error_message}")
            
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")

if __name__ == "__main__":
    try:
        asyncio.run(test_streaming())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æµ‹è¯•ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æµ‹è¯•é”™è¯¯: {e}")