#!/usr/bin/env python3
"""
ç®€å•çš„è¯­ä¹‰ç”¨æˆ·å»ºæ¨¡åŠŸèƒ½æµ‹è¯•
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.abspath("."))

from aienhance.perception.semantic_user_modeler import SemanticUserModeler
from aienhance.llm.adapters.ollama_adapter import OllamaLLMAdapter
from aienhance.llm.interfaces import ModelConfig


async def test_simple_user_modeling():
    """ç®€å•çš„ç”¨æˆ·å»ºæ¨¡æµ‹è¯•"""
    print("ğŸ§  æµ‹è¯•åŸºäºLLMçš„è¯­ä¹‰ç”¨æˆ·å»ºæ¨¡")
    print("=" * 50)

    try:
        # 1. åˆ›å»ºLLMæä¾›å•†
        print("1. åˆ›å»ºLLMæä¾›å•†...")
        config = ModelConfig(
            provider="ollama",
            model_name="qwen3:8b",
            api_base="http://localhost:11434",
            temperature=0.3,
            max_tokens=500,
        )

        llm_provider = OllamaLLMAdapter(config)
        await llm_provider.initialize()
        print("âœ… LLMæä¾›å•†åˆå§‹åŒ–æˆåŠŸ")

        # 2. åˆ›å»ºè¯­ä¹‰ç”¨æˆ·å»ºæ¨¡å™¨
        print("2. åˆ›å»ºè¯­ä¹‰ç”¨æˆ·å»ºæ¨¡å™¨...")
        modeler = SemanticUserModeler(llm_provider)
        print("âœ… è¯­ä¹‰ç”¨æˆ·å»ºæ¨¡å™¨åˆ›å»ºæˆåŠŸ")

        # 3. æµ‹è¯•ç”¨æˆ·ç”»åƒåˆ›å»º
        print("3. æµ‹è¯•ç”¨æˆ·ç”»åƒåˆ›å»º...")

        test_data = {
            "query": "è¯·è¯¦ç»†è§£é‡Šæ·±åº¦å­¦ä¹ ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶åŸç†ï¼ŒåŒ…æ‹¬æ•°å­¦å…¬å¼å’Œä»£ç å®ç°ã€‚",
            "memory_context": [
                {"content": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ", "metadata": {"type": "user_query"}},
                {
                    "content": "è§£é‡Šä¸€ä¸‹ç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­ç®—æ³•",
                    "metadata": {"type": "user_query"},
                },
                {
                    "content": "PyTorchä¸­å¦‚ä½•å®ç°å·ç§¯ç¥ç»ç½‘ç»œï¼Ÿ",
                    "metadata": {"type": "user_query"},
                },
            ],
        }

        print(f"ç”¨æˆ·æŸ¥è¯¢: {test_data['query']}")
        print("å†å²è®°å½•: 3æ¡æŠ€æœ¯ç›¸å…³æŸ¥è¯¢")

        # åˆ›å»ºç”¨æˆ·ç”»åƒ
        user_profile = await modeler.create_user_profile("test_user", test_data)

        print("\nâœ… ç”¨æˆ·ç”»åƒåˆ›å»ºæˆåŠŸ!")
        print(f"è®¤çŸ¥ç‰¹å¾:")
        print(f"  æ€ç»´æ¨¡å¼: {user_profile.cognitive.thinking_mode.value}")
        print(f"  è®¤çŸ¥å¤æ‚åº¦: {user_profile.cognitive.cognitive_complexity:.2f}")
        print(f"  æŠ½è±¡æ€ç»´: {user_profile.cognitive.abstraction_level:.2f}")
        print(f"  åˆ›é€ æ€§: {user_profile.cognitive.creativity_tendency:.2f}")

        print(f"çŸ¥è¯†ç»“æ„:")
        print(f"  æ ¸å¿ƒé¢†åŸŸ: {user_profile.knowledge.core_domains}")
        print(f"  çŸ¥è¯†æ·±åº¦: {user_profile.knowledge.knowledge_depth}")
        print(f"  è·¨åŸŸèƒ½åŠ›: {user_profile.knowledge.cross_domain_ability:.2f}")

        print(f"äº¤äº’åå¥½:")
        print(f"  è®¤çŸ¥é£æ ¼: {user_profile.interaction.cognitive_style.value}")
        print(
            f"  ä¿¡æ¯å¯†åº¦åå¥½: {user_profile.interaction.information_density_preference:.2f}"
        )
        print(f"  å¤„ç†é€Ÿåº¦: {user_profile.interaction.processing_speed:.2f}")

        # 4. æµ‹è¯•ä¸åŒé¢†åŸŸçš„ç”¨æˆ·å»ºæ¨¡
        print("\n4. æµ‹è¯•ä¸åŒé¢†åŸŸçš„ç”¨æˆ·å»ºæ¨¡...")

        creative_data = {
            "query": "æˆ‘æƒ³è®¾è®¡ä¸€ä¸ªåˆ›æ–°çš„è‰ºæœ¯è£…ç½®ï¼Œèƒ½ç»™æˆ‘ä¸€äº›çµæ„Ÿå—ï¼Ÿ",
            "memory_context": [
                {
                    "content": "æœ€æ–°çš„æ•°å­—è‰ºæœ¯è¶‹åŠ¿æœ‰å“ªäº›ï¼Ÿ",
                    "metadata": {"type": "user_query"},
                },
                {
                    "content": "å¦‚ä½•ç”¨AIç”ŸæˆæŠ½è±¡è‰ºæœ¯ï¼Ÿ",
                    "metadata": {"type": "user_query"},
                },
            ],
        }

        creative_profile = await modeler.create_user_profile(
            "creative_user", creative_data
        )

        print("ğŸ¨ åˆ›æ„ç”¨æˆ·ç”»åƒ:")
        print(f"  æ€ç»´æ¨¡å¼: {creative_profile.cognitive.thinking_mode.value}")
        print(f"  æ ¸å¿ƒé¢†åŸŸ: {creative_profile.knowledge.core_domains}")
        print(f"  åˆ›é€ æ€§å€¾å‘: {creative_profile.cognitive.creativity_tendency:.2f}")

        print("\nâœ… è¯­ä¹‰ç”¨æˆ·å»ºæ¨¡æµ‹è¯•å®Œæˆ!")

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ ç®€å•è¯­ä¹‰ç”¨æˆ·å»ºæ¨¡æµ‹è¯•")
    print("æµ‹è¯•LLMé©±åŠ¨çš„ç”¨æˆ·ç”»åƒç”ŸæˆåŠŸèƒ½")
    print()

    # è¿è¡Œæµ‹è¯•
    try:
        asyncio.run(test_simple_user_modeling())
    except KeyboardInterrupt:
        print("\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
