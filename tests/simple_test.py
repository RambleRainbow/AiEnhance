#!/usr/bin/env python3
"""
ç®€å•çš„ç³»ç»Ÿæµ‹è¯•
"""

import asyncio
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))

import aienhance


async def simple_test():
    """ç®€å•æµ‹è¯•"""
    print("ğŸ§ª ç®€å•ç³»ç»Ÿæµ‹è¯•")

    # 1. åˆ›å»ºç³»ç»Ÿï¼ˆä¸é…ç½®LLMï¼‰
    print("1. åˆ›å»ºåŸºç¡€ç³»ç»Ÿ...")
    system = aienhance.create_system("default")
    print("   âœ… ç³»ç»Ÿåˆ›å»ºæˆåŠŸ")

    # 2. æµ‹è¯•åŸºç¡€æŸ¥è¯¢å¤„ç†
    print("2. æµ‹è¯•åŸºç¡€æŸ¥è¯¢...")
    response = await system.process_query(query="æµ‹è¯•æŸ¥è¯¢", user_id="test_user")
    print("   âœ… æŸ¥è¯¢å¤„ç†å®Œæˆ")
    print(
        f"   ğŸ“Š å¤„ç†æ­¥éª¤: {' â†’ '.join(response.processing_metadata.get('processing_steps', []))}"
    )
    print(f"   ğŸ‘¤ ç”¨æˆ·ç”»åƒ: {response.user_profile.cognitive.thinking_mode.value}")
    print(f"   âš™ï¸ é€‚é…ä¿¡æ¯: {response.adaptation_info.density_level.value}")

    # 3. åˆ›å»ºå¸¦LLMçš„ç³»ç»Ÿï¼ˆæµ‹è¯•é…ç½®ï¼‰
    print("3. æµ‹è¯•LLMé…ç½®...")
    try:
        llm_system = aienhance.create_system(
            system_type="educational", llm_provider="ollama", llm_model_name="qwen3:8b"
        )
        print("   âœ… LLMç³»ç»Ÿé…ç½®æˆåŠŸ")

        status = llm_system.get_system_status()
        print(f"   ğŸ“‹ LLMçŠ¶æ€: {status.get('llm_provider', 'None')}")

    except Exception as e:
        print(f"   âš ï¸ LLMé…ç½®é—®é¢˜: {e}")

    print("ğŸ‰ ç®€å•æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    asyncio.run(simple_test())
