#!/usr/bin/env python3
"""
Ollamaé›†æˆæµ‹è¯•
æµ‹è¯•AiEnhanceç³»ç»Ÿä¸Ollama qwen3:8bçš„é›†æˆ
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

import aienhance


async def test_ollama_integration():
    """æµ‹è¯•Ollamaé›†æˆ"""
    print("ğŸ§ª Ollamaé›†æˆæµ‹è¯•")
    print("=" * 50)

    # 1. æ£€æŸ¥OllamaæœåŠ¡
    print("1ï¸âƒ£ æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€...")
    import httpx
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get("http://localhost:11434/api/tags", timeout=5.0)
            if response.status_code == 200:
                models_data = response.json()
                available_models = [model['name'] for model in models_data.get('models', [])]
                print(f"   âœ… OllamaæœåŠ¡æ­£å¸¸ï¼Œå¯ç”¨æ¨¡å‹: {', '.join(available_models)}")

                # æ£€æŸ¥å¿…éœ€æ¨¡å‹
                if "qwen3:8b" not in available_models:
                    print("   âš ï¸ æœªæ‰¾åˆ°qwen3:8bæ¨¡å‹")
                    print("   ğŸ’¡ è¯·è¿è¡Œ: ollama pull qwen3:8b")
                    return False
                else:
                    print("   âœ… qwen3:8bæ¨¡å‹å·²å°±ç»ª")
            else:
                print(f"   âŒ OllamaæœåŠ¡å¼‚å¸¸: {response.status_code}")
                return False
    except Exception as e:
        print(f"   âŒ æ— æ³•è¿æ¥Ollama: {e}")
        print("   ğŸ’¡ è¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ: ollama serve")
        return False

    # 2. åˆ›å»ºAiEnhanceç³»ç»Ÿ
    print("\n2ï¸âƒ£ åˆ›å»ºAiEnhanceç³»ç»Ÿ...")
    try:
        system = aienhance.create_system(
            system_type="educational",
            llm_provider="ollama",
            llm_model_name="qwen3:8b",
            llm_api_base="http://localhost:11434",
            llm_temperature=0.7,
            llm_max_tokens=500
        )
        print("   âœ… ç³»ç»Ÿåˆ›å»ºæˆåŠŸ")

        # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
        status = system.get_system_status()
        print(f"   ğŸ“Š ç³»ç»ŸçŠ¶æ€: å·²åˆå§‹åŒ–={status.get('initialized', False)}")

    except Exception as e:
        print(f"   âŒ ç³»ç»Ÿåˆ›å»ºå¤±è´¥: {e}")
        return False

    # 3. æµ‹è¯•åŸºç¡€æŸ¥è¯¢
    print("\n3ï¸âƒ£ æµ‹è¯•åŸºç¡€æŸ¥è¯¢åŠŸèƒ½...")
    test_queries = [
        "ä½ å¥½",
        "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
        "è¯·ç”¨ä¸€å¥è¯è§£é‡Šæœºå™¨å­¦ä¹ "
    ]

    successful_tests = 0
    for i, query in enumerate(test_queries, 1):
        print(f"\n   æµ‹è¯• {i}: {query}")
        try:
            response = await system.process_query(
                query=query,
                user_id="test_user",
                context={"test_number": i}
            )

            if response.content:
                print(f"   âœ… å“åº”æˆåŠŸ ({len(response.content)}å­—ç¬¦)")
                print(f"      å†…å®¹é¢„è§ˆ: {response.content[:100]}...")
                successful_tests += 1

                # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯
                if hasattr(response, 'processing_metadata'):
                    metadata = response.processing_metadata
                    steps = ' â†’ '.join(metadata.get('processing_steps', []))
                    print(f"      å¤„ç†æ­¥éª¤: {steps}")

                # æ˜¾ç¤ºé€‚é…ä¿¡æ¯
                if hasattr(response, 'adaptation_info'):
                    adapt = response.adaptation_info
                    print(f"      é€‚é…å‚æ•°: {adapt.density_level.value}å¯†åº¦, è´Ÿè·={adapt.cognitive_load:.2f}")

            else:
                print("   âš ï¸ æ— å†…å®¹ç”Ÿæˆ")

        except Exception as e:
            print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")

    # 4. æµ‹è¯•ç»“æœç»Ÿè®¡
    print("\n4ï¸âƒ£ æµ‹è¯•ç»“æœç»Ÿè®¡")
    print(f"   æˆåŠŸ: {successful_tests}/{len(test_queries)}")

    if successful_tests == len(test_queries):
        print("   ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return True
    elif successful_tests > 0:
        print("   âš ï¸ éƒ¨åˆ†æµ‹è¯•é€šè¿‡")
        return True
    else:
        print("   âŒ æ‰€æœ‰æµ‹è¯•å¤±è´¥")
        return False


async def test_system_configurations():
    """æµ‹è¯•ä¸åŒç³»ç»Ÿé…ç½®"""
    print("\nğŸ”§ ç³»ç»Ÿé…ç½®æµ‹è¯•")
    print("=" * 50)

    configurations = [
        {
            "name": "é»˜è®¤ç³»ç»Ÿ",
            "config": {
                "system_type": "default",
                "llm_provider": "ollama",
                "llm_model_name": "qwen3:8b",
                "llm_temperature": 0.5
            }
        },
        {
            "name": "æ•™è‚²ç³»ç»Ÿ",
            "config": {
                "system_type": "educational",
                "llm_provider": "ollama",
                "llm_model_name": "qwen3:8b",
                "llm_temperature": 0.3
            }
        },
        {
            "name": "ç ”ç©¶ç³»ç»Ÿ",
            "config": {
                "system_type": "research",
                "llm_provider": "ollama",
                "llm_model_name": "qwen3:8b",
                "llm_temperature": 0.8
            }
        }
    ]

    test_query = "è¯·è§£é‡Šæ·±åº¦å­¦ä¹ "
    successful_configs = 0

    for config_info in configurations:
        print(f"\nğŸ§ª æµ‹è¯• {config_info['name']}")
        try:
            system = aienhance.create_system(**config_info['config'])
            response = await system.process_query(
                query=test_query,
                user_id="config_test_user"
            )

            if response.content:
                print("   âœ… é…ç½®å·¥ä½œæ­£å¸¸")
                print(f"   ğŸ“ å“åº”é•¿åº¦: {len(response.content)}å­—ç¬¦")

                if hasattr(response, 'adaptation_info'):
                    adapt = response.adaptation_info
                    print(f"   âš™ï¸ é€‚é…: {adapt.density_level.value}å¯†åº¦")

                successful_configs += 1
            else:
                print("   âš ï¸ æ— å†…å®¹ç”Ÿæˆ")

        except Exception as e:
            print(f"   âŒ é…ç½®å¤±è´¥: {e}")

    print(f"\nğŸ“Š é…ç½®æµ‹è¯•ç»“æœ: {successful_configs}/{len(configurations)} æˆåŠŸ")
    return successful_configs > 0


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ AiEnhance + Ollama é›†æˆæµ‹è¯•å¼€å§‹")
    print("=" * 60)

    try:
        # 1. åŸºç¡€é›†æˆæµ‹è¯•
        basic_success = await test_ollama_integration()

        # 2. é…ç½®æµ‹è¯•
        config_success = await test_system_configurations()

        # 3. æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ“‹ æµ‹è¯•æ€»ç»“")
        print("=" * 60)
        print(f"âœ… åŸºç¡€é›†æˆæµ‹è¯•: {'é€šè¿‡' if basic_success else 'å¤±è´¥'}")
        print(f"âœ… é…ç½®æµ‹è¯•: {'é€šè¿‡' if config_success else 'å¤±è´¥'}")

        if basic_success and config_success:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼AiEnhanceä¸Ollamaé›†æˆæˆåŠŸ")
            print("ğŸ’¡ ç°åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹å¼å¯åŠ¨å®Œæ•´ç³»ç»Ÿ:")
            print("   â€¢ python examples/quick_start.py")
            print("   â€¢ python demo_complete_system.py")
            return True
        else:
            print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
            return False

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
