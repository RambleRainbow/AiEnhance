# MIRIX ç»Ÿä¸€LLMé›†æˆæŒ‡å—

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•å®ç°MIRIXä¸é¡¹ç›®å¤§æ¨¡å‹æŠ½è±¡å±‚çš„éä¾µå…¥å¼é›†æˆã€‚

## ğŸ¯ é›†æˆç›®æ ‡

å®ç°**æœ€ä¼˜æ–¹æ¡ˆ**ï¼šè®©MIRIXä½¿ç”¨é¡¹ç›®ç»Ÿä¸€çš„å¤§æ¨¡å‹æŠ½è±¡ï¼Œè€Œä¸æ˜¯ç‹¬ç«‹çš„å¤§æ¨¡å‹é…ç½®ã€‚

### ä¼˜åŠ¿å¯¹æ¯”

| ç‰¹æ€§ | ç‹¬ç«‹æ¨¡å¼ | ç»Ÿä¸€æ¨¡å¼ (æœ¬æ–¹æ¡ˆ) |
|------|----------|-------------------|
| **å¤§æ¨¡å‹ç®¡ç†** | åˆ†ç¦»çš„ | ç»Ÿä¸€çš„ âœ… |
| **é…ç½®å¤æ‚åº¦** | é«˜ | ä½ âœ… |
| **å…¼å®¹æ€§** | å—é™ | å…¨é¢ âœ… |
| **ç»´æŠ¤æˆæœ¬** | é«˜ | ä½ âœ… |
| **ä¾µå…¥æ€§** | é«˜ | é›¶ âœ… |

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### æ ¸å¿ƒç»„ä»¶

1. **MirixLLMBridge**: LLMé…ç½®æ¡¥æ¥å™¨
2. **MirixUnifiedAdapter**: ç»Ÿä¸€è®°å¿†é€‚é…å™¨
3. **EnhancedSystemFactory**: å¢å¼ºç³»ç»Ÿå·¥å‚

### é›†æˆæµç¨‹

```mermaid
graph TB
    A[é¡¹ç›®LLMæŠ½è±¡] --> B[LLMæ¡¥æ¥å™¨]
    B --> C[MIRIXé…ç½®ç”Ÿæˆ]
    C --> D[MIRIX SDKåˆå§‹åŒ–]
    D --> E[ç»Ÿä¸€è®°å¿†ç³»ç»Ÿ]
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹å¼ä¸€ï¼šä¾¿æ·å·¥å‚å‡½æ•°

```python
import aienhance

# Ollama + MIRIXç»Ÿä¸€ç³»ç»Ÿ
system = aienhance.create_ollama_mirix_system(
    model_name="qwen3:8b",
    ollama_base="http://localhost:11434",
    system_type="educational"
)

# OpenAI + MIRIXç»Ÿä¸€ç³»ç»Ÿ  
system = aienhance.create_openai_mirix_system(
    model_name="gpt-4",
    api_key="your-openai-key",
    system_type="research"
)

# Anthropic + MIRIXç»Ÿä¸€ç³»ç»Ÿ
system = aienhance.create_preset_system(
    "anthropic_claude",
    api_key="your-anthropic-key"
)
```

### æ–¹å¼äºŒï¼šå¢å¼ºå·¥å‚

```python
import aienhance

# å®Œå…¨è‡ªå®šä¹‰é…ç½®
system = aienhance.create_enhanced_system(
    system_type="educational",
    memory_system_type="mirix_unified",
    llm_provider="ollama",
    llm_model_name="llama3.3:8b",
    llm_api_base="http://localhost:11434",
    llm_temperature=0.8,
    llm_max_tokens=1000,
    use_unified_llm=True  # å¯ç”¨ç»Ÿä¸€æ¨¡å¼
)
```

### æ–¹å¼ä¸‰ï¼šç›´æ¥é€‚é…å™¨ä½¿ç”¨

```python
from aienhance.llm.interfaces import ModelConfig, LLMProviderFactory
from aienhance.memory.adapters.mirix_unified_adapter import MirixUnifiedAdapter
from aienhance.memory.interfaces import MemorySystemConfig

# åˆ›å»ºLLMæä¾›å•†
llm_config = ModelConfig(
    provider="ollama",
    model_name="qwen3:8b",
    api_base="http://localhost:11434"
)
llm_provider = LLMProviderFactory.create_provider(llm_config)

# åˆ›å»ºç»Ÿä¸€é€‚é…å™¨
memory_config = MemorySystemConfig(system_type="mirix_unified")
adapter = MirixUnifiedAdapter(memory_config, llm_provider)

# åˆå§‹åŒ–
await adapter.initialize()
```

## ğŸ”§ æŠ€æœ¯å®ç°

### 1. LLMæ¡¥æ¥å™¨ (MirixLLMBridge)

**åŠŸèƒ½**ï¼šå°†é¡¹ç›®LLMé…ç½®è½¬æ¢ä¸ºMIRIXå…¼å®¹æ ¼å¼

**æ ¸å¿ƒç‰¹æ€§**ï¼š
- è‡ªåŠ¨ç¯å¢ƒå˜é‡è®¾ç½®
- ä¸´æ—¶é…ç½®æ–‡ä»¶ç”Ÿæˆ
- å¤šæä¾›å•†é€‚é…
- è‡ªåŠ¨èµ„æºæ¸…ç†

**ä»£ç ç¤ºä¾‹**ï¼š
```python
from aienhance.memory.adapters.mirix_llm_bridge import MirixLLMBridge

bridge = MirixLLMBridge(llm_provider)
config_path = bridge.create_mirix_config("my_agent")
init_params = bridge.get_initialization_params()
```

### 2. ç»Ÿä¸€é€‚é…å™¨ (MirixUnifiedAdapter)

**åŠŸèƒ½**ï¼šæ”¯æŒä¸¤ç§æ¨¡å¼çš„MIRIXé›†æˆ

**æ¨¡å¼å¯¹æ¯”**ï¼š
```python
# ç»Ÿä¸€æ¨¡å¼ï¼ˆæ¨èï¼‰
adapter = MirixUnifiedAdapter(memory_config, llm_provider)

# æ ‡å‡†æ¨¡å¼
adapter = MirixUnifiedAdapter(memory_config)  # llm_provider=None
```

**æ™ºèƒ½åˆ‡æ¢**ï¼š
- å¦‚æœæä¾›`llm_provider`ï¼Œè‡ªåŠ¨ä½¿ç”¨ç»Ÿä¸€æ¨¡å¼
- å¦‚æœæœªæä¾›ï¼Œå›é€€åˆ°æ ‡å‡†æ¨¡å¼

### 3. æä¾›å•†é€‚é…

**æ”¯æŒçš„LLMæä¾›å•†**ï¼š

| æä¾›å•† | æ¨¡å‹ç¤ºä¾‹ | é…ç½®è¦ç‚¹ |
|--------|----------|----------|
| **Ollama** | qwen3:8b, llama3.3:8b | æœ¬åœ°æœåŠ¡ï¼Œæ— éœ€APIå¯†é’¥ |
| **OpenAI** | gpt-4, gpt-3.5-turbo | éœ€è¦APIå¯†é’¥ |
| **Anthropic** | claude-3-sonnet | éœ€è¦APIå¯†é’¥ |
| **Google AI** | gemini-pro | éœ€è¦APIå¯†é’¥ |
| **Azure** | gpt-4 | éœ€è¦APIå¯†é’¥å’Œç«¯ç‚¹ |

**é…ç½®æ˜ å°„**ï¼š
```python
# é¡¹ç›®é…ç½® â†’ MIRIXé…ç½®
{
    "provider": "ollama",           # â†’ model_provider: "ollama"
    "model_name": "qwen3:8b",      # â†’ model: "qwen3:8b"
    "api_base": "http://...",      # â†’ model_endpoint: "http://..."
    "api_key": "sk-...",          # â†’ OPENAI_API_KEY ç¯å¢ƒå˜é‡
    "temperature": 0.7             # â†’ generation_config.temperature
}
```

## ğŸ“‹ é…ç½®å‚è€ƒ

### ç¯å¢ƒå˜é‡æ˜ å°„

| LLMæä¾›å•† | é¡¹ç›®é…ç½® | MIRIXç¯å¢ƒå˜é‡ |
|-----------|----------|---------------|
| OpenAI | `api_key` | `OPENAI_API_KEY` |
| Anthropic | `api_key` | `ANTHROPIC_API_KEY` |
| Google AI | `api_key` | `GEMINI_API_KEY` |
| Azure | `api_key` | `AZURE_API_KEY` |

### MIRIXé…ç½®ç”Ÿæˆ

**Ollamaç¤ºä¾‹**ï¼š
```yaml
agent_name: aienhance_unified
model_name: qwen3:8b
model_endpoint: http://localhost:11434
generation_config:
  temperature: 0.7
  max_tokens: 800
```

**OpenAIç¤ºä¾‹**ï¼š
```yaml
agent_name: aienhance_unified
model_name: gpt-4
generation_config:
  temperature: 0.7
  max_tokens: 1000
```

## ğŸ§ª æµ‹è¯•éªŒè¯

### è¿è¡Œé›†æˆæµ‹è¯•

```bash
# åŸºç¡€åŠŸèƒ½æµ‹è¯•
python test_unified_llm_integration.py

# SDKé›†æˆæµ‹è¯•ï¼ˆéœ€è¦MIRIXåŒ…ï¼‰
pip install mirix
python test_mirix_sdk.py

# å®Œæ•´ç³»ç»Ÿæµ‹è¯•
python ai.py "æµ‹è¯•ç»Ÿä¸€LLMé›†æˆ"
```

### æµ‹è¯•æ£€æŸ¥é¡¹

- [x] LLMæä¾›å•†åˆ›å»º
- [x] é…ç½®æ¡¥æ¥åŠŸèƒ½
- [x] MIRIXé€‚é…å™¨åˆå§‹åŒ–
- [x] å¤šæä¾›å•†å…¼å®¹æ€§
- [x] é…ç½®æ–‡ä»¶ç”Ÿæˆ
- [x] ç¯å¢ƒå˜é‡è®¾ç½®

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **MIRIXåŒ…æœªå®‰è£…**
   ```bash
   pip install mirix
   ```

2. **LLMæä¾›å•†ä¸å¯ç”¨**
   ```python
   # æ£€æŸ¥OllamaæœåŠ¡
   curl http://localhost:11434/api/tags
   
   # æ£€æŸ¥APIå¯†é’¥
   echo $OPENAI_API_KEY
   ```

3. **é…ç½®æ–‡ä»¶æƒé™**
   ```bash
   # æ£€æŸ¥ä¸´æ—¶ç›®å½•æƒé™
   ls -la /tmp/
   ```

4. **å†…å­˜ä¸è¶³**
   - å¤§æ¨¡å‹å¯èƒ½éœ€è¦è¾ƒå¤§å†…å­˜
   - è€ƒè™‘ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹

### è°ƒè¯•æ¨¡å¼

```python
import logging
logging.basicConfig(level=logging.DEBUG)

# å¯ç”¨è¯¦ç»†æ—¥å¿—
system = aienhance.create_ollama_mirix_system(
    model_name="qwen3:8b",
    debug=True  # å¦‚æœæ”¯æŒ
)
```

## ğŸ”® æœªæ¥æ‰©å±•

### è®¡åˆ’åŠŸèƒ½

1. **æµå¼å“åº”æ”¯æŒ**
   - é›†æˆLLMæµå¼API
   - MIRIXæµå¼è®°å¿†æ›´æ–°

2. **æ‰¹é‡æ“ä½œ**
   - æ‰¹é‡è®°å¿†æ·»åŠ 
   - å¹¶å‘æŸ¥è¯¢å¤„ç†

3. **é«˜çº§é…ç½®**
   - æ¨¡å‹åˆ‡æ¢
   - åŠ¨æ€å‚æ•°è°ƒæ•´

4. **ç›‘æ§é›†æˆ**
   - æ€§èƒ½æŒ‡æ ‡æ”¶é›†
   - ä½¿ç”¨ç»Ÿè®¡åˆ†æ

### æ‰©å±•ç¤ºä¾‹

```python
# æœªæ¥å¯èƒ½çš„API
system = aienhance.create_enhanced_system(
    llm_provider="ollama",
    llm_model_name="qwen3:8b",
    memory_system_type="mirix_unified",
    features={
        "streaming": True,
        "batch_processing": True,
        "monitoring": True,
        "auto_scaling": True
    }
)
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [MIRIXå®˜æ–¹æ–‡æ¡£](https://docs.mirix.io)
- [é¡¹ç›®LLMæŠ½è±¡å±‚æ–‡æ¡£](./aienhance/llm/README.md)
- [è®°å¿†ç³»ç»Ÿæ¥å£æ–‡æ¡£](./aienhance/memory/README.md)
- [ç³»ç»Ÿæ¶æ„è¯´æ˜](./ARCHITECTURE.md)

## ğŸ¤ è´¡çŒ®æŒ‡å—

### æ·»åŠ æ–°çš„LLMæä¾›å•†

1. åœ¨`MirixLLMBridge`ä¸­æ·»åŠ `_adapt_xxx_config`æ–¹æ³•
2. åœ¨`SYSTEM_PRESETS`ä¸­æ·»åŠ é¢„è®¾é…ç½®
3. æ·»åŠ å¯¹åº”çš„ä¾¿æ·å·¥å‚å‡½æ•°
4. æ›´æ–°æµ‹è¯•ç”¨ä¾‹

### æäº¤ä»£ç 

```bash
# è¿è¡Œæµ‹è¯•
python test_unified_llm_integration.py

# æ£€æŸ¥ä»£ç è´¨é‡
ruff check .

# æäº¤æ›´æ”¹
git add .
git commit -m "feat: æ·»åŠ XXXæä¾›å•†æ”¯æŒ"
```

---

è¿™ä¸ªç»Ÿä¸€LLMé›†æˆæ–¹æ¡ˆå®ç°äº†**é›¶ä¾µå…¥**çš„MIRIXå¤§æ¨¡å‹é…ç½®ï¼Œè®©é¡¹ç›®èƒ½å¤Ÿåœ¨ä¸ä¿®æ”¹MIRIXæºç çš„æƒ…å†µä¸‹ï¼Œä½¿ç”¨ç»Ÿä¸€çš„å¤§æ¨¡å‹æŠ½è±¡å±‚ï¼Œå¤§å¤§ç®€åŒ–äº†ç³»ç»Ÿçš„é…ç½®å’Œç»´æŠ¤å¤æ‚åº¦ã€‚