#!/usr/bin/env python3
"""
æµ‹è¯•OllamaåµŒå…¥æœåŠ¡å…¼å®¹æ€§
éªŒè¯Ollamaå¯ä»¥é€šè¿‡OpenAI APIå…¼å®¹æ¥å£æä¾›åµŒå…¥æœåŠ¡
"""

import asyncio
import json
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import aiohttp
from aienhance.config import Config


async def test_ollama_embedding_directly():
    """ç›´æ¥æµ‹è¯•OllamaåµŒå…¥æœåŠ¡"""
    print("ğŸ§ª æµ‹è¯•OllamaåµŒå…¥æœåŠ¡")
    print("=" * 40)
    
    async with aiohttp.ClientSession() as session:
        # æµ‹è¯•åŸç”ŸOllamaåµŒå…¥æ¥å£
        print("\n1ï¸âƒ£ æµ‹è¯•åŸç”ŸOllamaåµŒå…¥æ¥å£")
        try:
            payload = {
                "model": "nomic-embed-text",
                "prompt": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"
            }
            
            async with session.post(
                f"{Config.OLLAMA_BASE_URL}/api/embeddings",
                json=payload
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    embedding = result.get("embedding", [])
                    print(f"   âœ… åŸç”Ÿæ¥å£æˆåŠŸ")
                    print(f"   å‘é‡ç»´åº¦: {len(embedding)}")
                else:
                    print(f"   âŒ åŸç”Ÿæ¥å£å¤±è´¥: {response.status}")
        except Exception as e:
            print(f"   âŒ åŸç”Ÿæ¥å£å¼‚å¸¸: {e}")
        
        # æµ‹è¯•OpenAIå…¼å®¹æ¥å£
        print("\n2ï¸âƒ£ æµ‹è¯•OpenAIå…¼å®¹æ¥å£")
        try:
            headers = {
                "Authorization": "Bearer fake_key_for_ollama",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "nomic-embed-text",
                "input": ["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬"]
            }
            
            async with session.post(
                f"{Config.OLLAMA_BASE_URL}/v1/embeddings",
                json=payload,
                headers=headers
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    embeddings = result.get("data", [])
                    if embeddings:
                        embedding = embeddings[0].get("embedding", [])
                        print(f"   âœ… OpenAIå…¼å®¹æ¥å£æˆåŠŸ")
                        print(f"   å‘é‡ç»´åº¦: {len(embedding)}")
                        print(f"   æ•°æ®æ ¼å¼: {list(result.keys())}")
                    else:
                        print(f"   âš ï¸  OpenAIå…¼å®¹æ¥å£è¿”å›ç©ºæ•°æ®")
                else:
                    error_text = await response.text()
                    print(f"   âŒ OpenAIå…¼å®¹æ¥å£å¤±è´¥: {response.status}")
                    print(f"   é”™è¯¯è¯¦æƒ…: {error_text}")
        except Exception as e:
            print(f"   âŒ OpenAIå…¼å®¹æ¥å£å¼‚å¸¸: {e}")
        
        # æµ‹è¯•ä¸åŒæ¨¡å‹
        print("\n3ï¸âƒ£ æµ‹è¯•å…¶ä»–å¯ç”¨åµŒå…¥æ¨¡å‹")
        embedding_models = ["bge-m3", "nomic-embed-text"]
        
        for model in embedding_models:
            try:
                headers = {
                    "Authorization": "Bearer fake_key_for_ollama",
                    "Content-Type": "application/json"
                }
                
                payload = {
                    "model": model,
                    "input": ["æµ‹è¯•æ–‡æœ¬"]
                }
                
                async with session.post(
                    f"{Config.OLLAMA_BASE_URL}/v1/embeddings",
                    json=payload,
                    headers=headers
                ) as response:
                    if response.status == 200:
                        result = await response.json()
                        embeddings = result.get("data", [])
                        if embeddings:
                            dim = len(embeddings[0].get("embedding", []))
                            print(f"   âœ… {model}: {dim}ç»´")
                        else:
                            print(f"   âš ï¸  {model}: æ— æ•°æ®")
                    else:
                        print(f"   âŒ {model}: {response.status}")
            except Exception as e:
                print(f"   âŒ {model}: {e}")


async def test_graphiti_embedding_config():
    """æµ‹è¯•Graphitiçš„åµŒå…¥é…ç½®"""
    print("\n" + "=" * 40)
    print("ğŸ”§ GraphitiåµŒå…¥é…ç½®åˆ†æ")
    print("=" * 40)
    
    print("\nå½“å‰Dockerç¯å¢ƒå˜é‡:")
    print("  OPENAI_BASE_URL=http://host.docker.internal:11434/v1")
    print("  OPENAI_API_KEY=fake_key_for_ollama")
    print("  EMBEDDER_MODEL_NAME=nomic-embed-text")
    print("  EMBEDDER=openai")
    
    print("\né—®é¢˜åˆ†æ:")
    print("  â€¢ Graphitiä»åœ¨ä½¿ç”¨text-embedding-3-smallæ¨¡å‹")
    print("  â€¢ å¯èƒ½éœ€è¦åœ¨ä»£ç å±‚é¢æŒ‡å®šåµŒå…¥æ¨¡å‹åç§°")
    print("  â€¢ æˆ–è€…éœ€è¦é‡å»ºDockeré•œåƒä»¥åº”ç”¨ç¯å¢ƒå˜é‡")
    
    print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
    print("  1. åœ¨Graphitiæºç ä¸­æŸ¥æ‰¾é»˜è®¤æ¨¡å‹é…ç½®")
    print("  2. æ£€æŸ¥æ˜¯å¦éœ€è¦è®¾ç½®å…¶ä»–ç¯å¢ƒå˜é‡")
    print("  3. éªŒè¯Ollamaçš„OpenAIå…¼å®¹æ€§")


async def main():
    """ä¸»å‡½æ•°"""
    await test_ollama_embedding_directly()
    await test_graphiti_embedding_config()


if __name__ == "__main__":
    asyncio.run(main())