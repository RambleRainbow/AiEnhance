#!/usr/bin/env python3
"""
åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿæµå¼æ¼”ç¤ºå·¥å…·
å±•ç¤ºæ„ŸçŸ¥å±‚ã€è®¤çŸ¥å±‚ã€è¡Œä¸ºå±‚ã€åä½œå±‚çš„é€å±‚å¤„ç†è¿‡ç¨‹
"""

import aienhance
import asyncio
import sys
import argparse
from pathlib import Path
from typing import AsyncIterator, Dict, Any
import time
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))


class LayeredCognitiveStreamingDemo:
    """åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿæµå¼æ¼”ç¤º"""

    def __init__(self):
        self.system = None
        self.processing_stats = {
            'perception_time': 0,
            'cognition_time': 0, 
            'behavior_time': 0,
            'collaboration_time': 0,
            'total_time': 0
        }

    async def check_dependencies(self):
        """æ£€æŸ¥ç³»ç»Ÿä¾èµ–"""
        print("ğŸ” æ£€æŸ¥ç³»ç»Ÿä¾èµ–...")
        
        # æ£€æŸ¥Ollama
        try:
            import httpx
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    "http://localhost:11434/api/tags", 
                    timeout=3.0
                )
                if response.status_code == 200:
                    print("âœ… OllamaæœåŠ¡æ­£å¸¸")
                    return True
                else:
                    print("âŒ OllamaæœåŠ¡å¼‚å¸¸")
                    return False
        except Exception as e:
            print(f"âŒ Ollamaè¿æ¥å¤±è´¥: {e}")
            print("ğŸ’¡ è¯·ç¡®ä¿è¿è¡Œ: ollama serve")
            return False

    async def initialize_layered_system(self, system_type="educational"):
        """åˆå§‹åŒ–åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿ"""
        try:
            print(f"ğŸ§  åˆå§‹åŒ–åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿ (ç±»å‹: {system_type})...")
            
            # ä½¿ç”¨å·¥å‚æ–¹æ³•åˆ›å»ºåˆ†å±‚ç³»ç»Ÿ
            if system_type == "educational":
                self.system = aienhance.create_educational_layered_system(
                    model_name="qwen3:8b",
                    llm_temperature=0.7,
                    llm_max_tokens=800
                )
            elif system_type == "research":
                self.system = aienhance.create_research_layered_system(
                    model_name="qwen3:8b"
                )
            else:
                # å¯¹äºå…¶ä»–ç±»å‹ï¼Œä½¿ç”¨é€šç”¨åˆ†å±‚ç³»ç»Ÿ
                self.system = aienhance.create_layered_system(
                    system_type=system_type,
                    memory_system_type="mirix_unified",
                    llm_provider="ollama",
                    llm_model_name="qwen3:8b",
                    llm_temperature=0.7,
                    llm_max_tokens=800
                )
            
            # åˆå§‹åŒ–ç³»ç»Ÿ
            await self.system.initialize_layers()
            
            print("âœ… åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            print("ğŸ“Š ç³»ç»Ÿæ¶æ„:")
            print("   ğŸ“‹ æ„ŸçŸ¥å±‚ (Perception): ç”¨æˆ·å»ºæ¨¡ä¸ä¸Šä¸‹æ–‡åˆ†æ")
            print("   ğŸ§  è®¤çŸ¥å±‚ (Cognition): è®°å¿†æ¿€æ´»ä¸è¯­ä¹‰å¢å¼º") 
            print("   ğŸ¯ è¡Œä¸ºå±‚ (Behavior): å†…å®¹é€‚é…ä¸ç”Ÿæˆ")
            if system_type != "lightweight":
                print("   ğŸ¤ åä½œå±‚ (Collaboration): å¤šå…ƒè§‚ç‚¹ä¸è®¤çŸ¥æŒ‘æˆ˜")
            
            return True
            
        except Exception as e:
            print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    async def stream_layered_processing(self, 
                                      query: str, 
                                      user_id: str = "demo_user",
                                      show_details: bool = True) -> AsyncIterator[str]:
        """åˆ†å±‚æµå¼å¤„ç†ï¼Œå±•ç¤ºæ¯å±‚çš„è¯¦ç»†è¿‡ç¨‹"""
        
        start_time = time.time()
        
        try:
            # æ„å»ºç³»ç»Ÿè¾“å…¥ - ç›´æ¥ä½¿ç”¨å­—å…¸ï¼Œå› ä¸ºSystemInputä¸å­˜åœ¨
            context = {
                "source": "layered_streaming_demo",
                "timestamp": time.time(),
                "show_details": show_details
            }
            
            if show_details:
                yield "ğŸš€ å¼€å§‹åˆ†å±‚è®¤çŸ¥å¤„ç†...\n\n"
            
            # é€å±‚å¤„ç†å¹¶æµå¼è¾“å‡º
            async for chunk in self._process_with_layer_details(query, user_id, context, show_details):
                yield chunk
            
            # è·å–å¤„ç†ç»“æœ
            result = getattr(self, '_processing_result', None)
            
            # è¾“å‡ºæœ€ç»ˆç»“æœ
            if show_details:
                yield "\n" + "="*50 + "\n"
                yield "ğŸ“‹ æœ€ç»ˆè¾“å‡º:\n"
                yield "="*50 + "\n"
            
            if result and hasattr(result, 'final_output'):
                content = result.final_output
                
                # æµå¼è¾“å‡ºä¸»è¦å†…å®¹
                sentences = self._split_content_for_streaming(content)
                for sentence in sentences:
                    if sentence.strip():
                        yield sentence + " "
                        await asyncio.sleep(0.05)  # æµå¼å»¶è¿Ÿ
                
                yield "\n"
                
                # å¦‚æœæœ‰åä½œå±‚å¢å¼ºå†…å®¹
                if (hasattr(result, 'collaboration_output') and 
                    result.collaboration_output and 
                    hasattr(result.collaboration_output, 'enhanced_content') and
                    result.collaboration_output.enhanced_content):
                    
                    if show_details:
                        yield "\nğŸ¤ åä½œå±‚å¢å¼ºå†…å®¹:\n"
                        yield "-" * 30 + "\n"
                    
                    enhanced = result.collaboration_output.enhanced_content
                    enhanced_sentences = self._split_content_for_streaming(enhanced)
                    for sentence in enhanced_sentences:
                        if sentence.strip():
                            yield sentence + " "
                            await asyncio.sleep(0.05)
                    yield "\n"
            else:
                yield "æŠ±æ­‰ï¼Œç³»ç»Ÿå¤„ç†å‡ºç°é—®é¢˜ã€‚è¯·æ£€æŸ¥é…ç½®ã€‚\n"
            
            # å¤„ç†ç»Ÿè®¡ä¿¡æ¯
            total_time = time.time() - start_time
            self.processing_stats['total_time'] = total_time
            
            if show_details:
                yield f"\nâ±ï¸ æ€»å¤„ç†æ—¶é—´: {total_time:.2f}ç§’\n"
                yield self._format_processing_stats()
                
        except Exception as e:
            yield f"\nâŒ åˆ†å±‚å¤„ç†å¤±è´¥: {e}\n"

    async def _process_with_layer_details(self, query, user_id, context, show_details=True):
        """å¸¦æœ‰è¯¦ç»†å±‚æ¬¡ä¿¡æ¯çš„å¤„ç†"""
        
        if not show_details:
            # ç›´æ¥å¤„ç†ï¼Œä¸æ˜¾ç¤ºç»†èŠ‚
            result = await self.system.process_through_layers(
                query=query,
                user_id=user_id,
                context=context
            )
            # ä¸èƒ½åœ¨ç”Ÿæˆå™¨ä¸­ä½¿ç”¨returnï¼Œæ‰€ä»¥ç›´æ¥è¿”å›resultï¼Œåç»­å¤„ç†
            self._processing_result = result
            return
        
        # è¯¦ç»†æ˜¾ç¤ºæ¯å±‚å¤„ç†
        result = None
        layer_start_time = time.time()
        
        try:
            # 1. æ„ŸçŸ¥å±‚å¤„ç†
            yield "ğŸ“‹ æ„ŸçŸ¥å±‚å¤„ç†ä¸­...\n"
            yield "   â€¢ åˆ†æç”¨æˆ·ç”»åƒå’Œåå¥½\n"
            yield "   â€¢ è¯†åˆ«æŸ¥è¯¢ä¸Šä¸‹æ–‡å’Œæ„å›¾\n"
            yield "   â€¢ æ„å»ºä¸ªæ€§åŒ–ç†è§£æ¨¡å‹\n"
            
            perception_start = time.time()
            # è¿™é‡Œå®é™…è°ƒç”¨ç³»ç»Ÿå¤„ç†ï¼Œä½†æˆ‘ä»¬åªæ˜¾ç¤ºä¸€æ¬¡å®Œæ•´ç»“æœ
            result = await self.system.process_through_layers(
                query=query,
                user_id=user_id,
                context=context
            )
            self.processing_stats['perception_time'] = time.time() - perception_start
            
            yield f"   âœ… æ„ŸçŸ¥å±‚å®Œæˆ ({self.processing_stats['perception_time']:.2f}s)\n\n"
            
            # 2. è®¤çŸ¥å±‚å¤„ç†  
            cognition_start = time.time()
            yield "ğŸ§  è®¤çŸ¥å±‚å¤„ç†ä¸­...\n"
            yield "   â€¢ æ¿€æ´»ç›¸å…³è®°å¿†ç½‘ç»œ\n"
            yield "   â€¢ è¿›è¡Œè¯­ä¹‰ç†è§£å¢å¼º\n"
            yield "   â€¢ æ‰§è¡Œç±»æ¯”æ¨ç†åˆ†æ\n"
            
            await asyncio.sleep(0.3)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            self.processing_stats['cognition_time'] = time.time() - cognition_start
            yield f"   âœ… è®¤çŸ¥å±‚å®Œæˆ ({self.processing_stats['cognition_time']:.2f}s)\n\n"
            
            # 3. è¡Œä¸ºå±‚å¤„ç†
            behavior_start = time.time()
            yield "ğŸ¯ è¡Œä¸ºå±‚å¤„ç†ä¸­...\n"
            yield "   â€¢ é€‚é…å†…å®¹è¡¨è¾¾æ–¹å¼\n"
            yield "   â€¢ è°ƒæ•´ä¿¡æ¯å¯†åº¦å’Œç²’åº¦\n"
            yield "   â€¢ ç”Ÿæˆä¸ªæ€§åŒ–å›åº”\n"
            
            await asyncio.sleep(0.2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            self.processing_stats['behavior_time'] = time.time() - behavior_start
            yield f"   âœ… è¡Œä¸ºå±‚å®Œæˆ ({self.processing_stats['behavior_time']:.2f}s)\n\n"
            
            # 4. åä½œå±‚å¤„ç† (å¦‚æœå¯ç”¨)
            if (hasattr(self.system, 'config') and 
                self.system.config.get('enable_collaboration', True)):
                
                collaboration_start = time.time()
                yield "ğŸ¤ åä½œå±‚å¤„ç†ä¸­...\n"
                yield "   â€¢ ç”Ÿæˆå¤šå…ƒè§‚ç‚¹è§†è§’\n"
                yield "   â€¢ åˆ›å»ºè®¤çŸ¥æŒ‘æˆ˜é—®é¢˜\n" 
                yield "   â€¢ å¢å¼ºåä½œæ€è€ƒæ·±åº¦\n"
                
                await asyncio.sleep(0.2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                self.processing_stats['collaboration_time'] = time.time() - collaboration_start
                yield f"   âœ… åä½œå±‚å®Œæˆ ({self.processing_stats['collaboration_time']:.2f}s)\n\n"
            
            # å°†ç»“æœå­˜å‚¨åˆ°å®ä¾‹å˜é‡ä¸­ï¼Œä¾›åç»­ä½¿ç”¨
            self._processing_result = result
            
        except Exception as e:
            yield f"âŒ å±‚æ¬¡å¤„ç†é”™è¯¯: {e}\n"
            self._processing_result = None

    def _split_content_for_streaming(self, content: str) -> list:
        """å°†å†…å®¹åˆ†å‰²ä¸ºé€‚åˆæµå¼è¾“å‡ºçš„ç‰‡æ®µ"""
        import re
        
        # æŒ‰å¥å­åˆ†å‰²
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', content)
        
        # è¿‡æ»¤ç©ºå¥å­å¹¶æ·»åŠ æ ‡ç‚¹
        result = []
        for sentence in sentences:
            sentence = sentence.strip()
            if sentence:
                # æ ¹æ®åŸæ–‡æ¢å¤æ ‡ç‚¹
                if sentence[-1] not in 'ã€‚ï¼ï¼Ÿ':
                    if '?' in sentence or 'ï¼Ÿ' in sentence:
                        sentence += 'ï¼Ÿ'
                    elif '!' in sentence or 'ï¼' in sentence:
                        sentence += 'ï¼'
                    else:
                        sentence += 'ã€‚'
                result.append(sentence)
        
        return result

    def _format_processing_stats(self) -> str:
        """æ ¼å¼åŒ–å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.processing_stats
        return f"""
ğŸ“Š åˆ†å±‚å¤„ç†ç»Ÿè®¡:
   ğŸ“‹ æ„ŸçŸ¥å±‚: {stats['perception_time']:.2f}s
   ğŸ§  è®¤çŸ¥å±‚: {stats['cognition_time']:.2f}s  
   ğŸ¯ è¡Œä¸ºå±‚: {stats['behavior_time']:.2f}s
   ğŸ¤ åä½œå±‚: {stats['collaboration_time']:.2f}s
   ğŸ“ˆ æ€»è€—æ—¶: {stats['total_time']:.2f}s
"""

    async def interactive_layered_demo(self, system_type="educational"):
        """äº¤äº’å¼åˆ†å±‚æ¼”ç¤º"""
        print("ğŸš€ åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿäº¤äº’æ¼”ç¤º")
        print("=" * 60)
        print("ğŸ’¡ åŠŸèƒ½è¯´æ˜:")
        print("  â€¢ å¯è§†åŒ–å±•ç¤ºå››å±‚è®¤çŸ¥å¤„ç†è¿‡ç¨‹")
        print("  â€¢ æ”¯æŒå¤šç§ç³»ç»Ÿç±»å‹é…ç½®")
        print("  â€¢ å®æ—¶æµå¼è¾“å‡ºå¤„ç†ç»“æœ")
        print("=" * 60)
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        if not await self.initialize_layered_system(system_type):
            return
        
        session_count = 0
        
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input(f"\n[{session_count}] ğŸ¤” è¯·è¾“å…¥é—®é¢˜ (è¾“å…¥'quit'é€€å‡º): ").strip()
                
                # å¤„ç†é€€å‡ºå‘½ä»¤
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                    print("ğŸ‘‹ æ„Ÿè°¢ä½“éªŒåˆ†å±‚è®¤çŸ¥ç³»ç»Ÿï¼")
                    break
                elif not user_input:
                    continue
                
                print(f"\nğŸ¯ å¤„ç†æŸ¥è¯¢: {user_input}")
                print("-" * 50)
                
                # æµå¼å¤„ç†å¹¶è¾“å‡º
                async for chunk in self.stream_layered_processing(
                    query=user_input,
                    user_id=f"interactive_user_{session_count}",
                    show_details=True
                ):
                    print(chunk, end='', flush=True)
                
                session_count += 1
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
                break
            except Exception as e:
                print(f"âŒ äº¤äº’é”™è¯¯: {e}")

    async def demo_showcase(self):
        """æ¼”ç¤ºå±•ç¤ºæ¨¡å¼"""
        print("ğŸ® åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿæ¼”ç¤ºå±•ç¤º")
        print("=" * 60)
        
        # é¢„å®šä¹‰æ¼”ç¤ºæŸ¥è¯¢
        demo_scenarios = [
            {
                "name": "æ•™è‚²åœºæ™¯",
                "system_type": "educational", 
                "query": "ä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿè¯·ç”¨ç®€å•æ˜“æ‡‚çš„æ–¹å¼è§£é‡Š"
            },
            {
                "name": "ç ”ç©¶åœºæ™¯",
                "system_type": "research",
                "query": "åˆ†æäººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨å‰æ™¯å’ŒæŒ‘æˆ˜"
            },
            {
                "name": "åˆ›æ„åœºæ™¯", 
                "system_type": "creative",
                "query": "è®¾è®¡ä¸€ä¸ªæœªæ¥æ™ºèƒ½åŸå¸‚çš„åˆ›æ–°äº¤é€šç³»ç»Ÿ"
            },
            {
                "name": "è½»é‡åœºæ™¯",
                "system_type": "lightweight",
                "query": "ç®€å•ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ "
            }
        ]
        
        for i, scenario in enumerate(demo_scenarios, 1):
            print(f"\n{i}ï¸âƒ£ {scenario['name']}æ¼”ç¤º")
            print("=" * 40)
            print(f"ğŸ¯ æŸ¥è¯¢: {scenario['query']}")
            print(f"âš™ï¸ ç³»ç»Ÿç±»å‹: {scenario['system_type']}")
            print("-" * 40)
            
            # åˆå§‹åŒ–å¯¹åº”ç±»å‹çš„ç³»ç»Ÿ
            await self.initialize_layered_system(scenario['system_type'])
            
            # æµå¼å¤„ç†
            async for chunk in self.stream_layered_processing(
                query=scenario['query'],
                user_id=f"demo_user_{i}",
                show_details=(scenario['system_type'] != 'lightweight')
            ):
                print(chunk, end='', flush=True)
            
            print("\n" + "=" * 40)
            
            # çŸ­æš‚åœé¡¿
            if i < len(demo_scenarios):
                print("â¸ï¸ æš‚åœ3ç§’...")
                await asyncio.sleep(3)
                
        print("\nğŸ‰ æ¼”ç¤ºå±•ç¤ºå®Œæˆï¼")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.system and hasattr(self.system, 'cleanup'):
                await self.system.cleanup()
                print("ğŸ§¹ ç³»ç»Ÿèµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿæµå¼æ¼”ç¤ºå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python layered_streaming_demo.py -i                                   # äº¤äº’æ¨¡å¼
  python layered_streaming_demo.py -d                                   # æ¼”ç¤ºå±•ç¤º
  python layered_streaming_demo.py -i --type research                   # ç ”ç©¶ç³»ç»Ÿäº¤äº’
  python layered_streaming_demo.py -d --type creative                   # åˆ›æ„ç³»ç»Ÿæ¼”ç¤º
        """
    )
    
    parser.add_argument('-i', '--interactive', action='store_true',
                        help='å¯åŠ¨äº¤äº’å¼åˆ†å±‚æ¼”ç¤º')
    parser.add_argument('-d', '--demo', action='store_true', 
                        help='è¿è¡Œæ¼”ç¤ºå±•ç¤ºæ¨¡å¼')
    parser.add_argument('--type', 
                        choices=['educational', 'research', 'creative', 'lightweight'],
                        default='educational',
                        help='åˆ†å±‚ç³»ç»Ÿç±»å‹ (é»˜è®¤: educational)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ¼”ç¤ºå®ä¾‹
    demo = LayeredCognitiveStreamingDemo()
    
    try:
        # æ£€æŸ¥ä¾èµ–
        if not await demo.check_dependencies():
            return
        
        # æ ¹æ®å‚æ•°æ‰§è¡Œç›¸åº”æ¨¡å¼
        if args.interactive:
            await demo.interactive_layered_demo(args.type)
        elif args.demo:
            await demo.demo_showcase()
        else:
            # é»˜è®¤æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
            parser.print_help()
            print("\nğŸ’¡ å¿«é€Ÿå¼€å§‹:")
            print("  python layered_streaming_demo.py -i  # äº¤äº’å¼æ¼”ç¤º")
            print("  python layered_streaming_demo.py -d  # æ¼”ç¤ºå±•ç¤º")
            
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºç¨‹åºé”™è¯¯: {e}")
    finally:
        await demo.cleanup()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"âŒ ç¨‹åºé”™è¯¯: {e}")