#!/usr/bin/env python3
"""
AiEnhance Gradioç•Œé¢æ¼”ç¤ºè„šæœ¬
ç®€åŒ–ç‰ˆæœ¬ï¼Œç”¨äºå¿«é€Ÿå±•ç¤ºåˆ†å±‚è®¤çŸ¥ç³»ç»Ÿçš„å¯è§†åŒ–åŠŸèƒ½
"""

import gradio as gr
import json
import asyncio
from typing import Dict, Any, Tuple

# æ¨¡æ‹Ÿæ•°æ®ï¼Œç”¨äºæ¼”ç¤ºç•Œé¢åŠŸèƒ½
DEMO_SYSTEM_INFO = {
    "system_type": "educational_layered",
    "initialized": True,
    "layers": {
        "perception": "âœ… å·²åˆå§‹åŒ–",
        "cognition": "âœ… å·²åˆå§‹åŒ–", 
        "behavior": "âœ… å·²åˆå§‹åŒ–",
        "collaboration": "âœ… å·²åˆå§‹åŒ–"
    },
    "memory_system": {
        "type": "mirix_unified",
        "mode": "unified",
        "llm_provider": "ollama/qwen3:8b"
    }
}

DEMO_LAYER_OUTPUTS = {
    "perception": {
        "ç”¨æˆ·å»ºæ¨¡": {
            "å­¦ä¹ åå¥½": "è§†è§‰åŒ–å­¦ä¹ ",
            "çŸ¥è¯†æ°´å¹³": "ä¸­çº§",
            "å…´è¶£é¢†åŸŸ": "äººå·¥æ™ºèƒ½æŠ€æœ¯"
        },
        "ä¸Šä¸‹æ–‡åˆ†æ": {
            "æŸ¥è¯¢ç±»å‹": "æ¦‚å¿µè§£é‡Š",
            "å¤æ‚åº¦": "ä¸­ç­‰",
            "é¢„æœŸæ·±åº¦": "è¯¦ç»†"
        }
    },
    "cognition": {
        "è®°å¿†æ¿€æ´»": {
            "ç›¸å…³æ¦‚å¿µæ•°": 15,
            "æ¿€æ´»å¼ºåº¦": 0.85,
            "æ£€ç´¢æ—¶é—´": "0.23ç§’"
        },
        "è¯­ä¹‰å¢å¼º": {
            "æ¦‚å¿µè¡¥å……": 3,
            "å…³è”å»ºç«‹": 8,
            "çŸ¥è¯†æ¡¥æ¥": 5
        }
    },
    "behavior": {
        "å“åº”ç”Ÿæˆ": {
            "ç”Ÿæˆç­–ç•¥": "åˆ†å±‚è§£é‡Š",
            "è¯­è¨€é£æ ¼": "æ•™å­¦å¼",
            "ç»“æ„åŒ–ç¨‹åº¦": "é«˜"
        },
        "è¾“å‡ºä¼˜åŒ–": {
            "å¯è¯»æ€§è¯„åˆ†": 0.92,
            "å‡†ç¡®æ€§è¯„åˆ†": 0.89,
            "å®Œæ•´æ€§è¯„åˆ†": 0.91
        }
    },
    "collaboration": {
        "å¤šä»£ç†åè°ƒ": "æœªå¯ç”¨",
        "èµ„æºæ•´åˆ": "æœ¬åœ°èµ„æº",
        "çŠ¶æ€": "å•ä»£ç†æ¨¡å¼"
    }
}

DEMO_MEMORY_STATUS = {
    "ç³»ç»Ÿç±»å‹": "mirix_unified",
    "åˆå§‹åŒ–çŠ¶æ€": True,
    "LLMæ¨¡å¼": "unified",
    "è®°å¿†æ€»æ•°": 127,
    "è®°å¿†ç±»å‹ç»Ÿè®¡": {
        "episodic": 45,
        "semantic": 32,
        "procedural": 28,
        "core": 15,
        "knowledge": 7
    },
    "æŸ¥è¯¢æ—¶é—´": "0.045ç§’"
}


def demo_initialize_system(system_type: str, llm_provider: str, llm_model: str, temperature: float) -> str:
    """æ¼”ç¤ºç³»ç»Ÿåˆå§‹åŒ–"""
    demo_info = DEMO_SYSTEM_INFO.copy()
    demo_info["system_type"] = system_type
    demo_info["memory_system"]["llm_provider"] = f"{llm_provider}/{llm_model}"
    demo_info["temperature"] = temperature
    
    return f"âœ… {system_type} ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼\n\nç³»ç»Ÿä¿¡æ¯ï¼š\n{json.dumps(demo_info, ensure_ascii=False, indent=2)}"


def demo_process_query(query: str) -> Tuple[str, str, str, str, str, str]:
    """æ¼”ç¤ºæŸ¥è¯¢å¤„ç†"""
    if not query.strip():
        return "âŒ è¯·è¾“å…¥æŸ¥è¯¢é—®é¢˜", "", "", "", "", ""
    
    # æ¨¡æ‹Ÿæœ€ç»ˆå“åº”
    final_response = f"""
ğŸ¤– åŸºäºåˆ†å±‚è®¤çŸ¥ç³»ç»Ÿçš„å›ç­”:

æ‚¨è¯¢é—®å…³äºã€Œ{query}ã€ï¼Œæˆ‘é€šè¿‡å››å±‚å¤„ç†ä¸ºæ‚¨æä¾›è¯¦ç»†è§£ç­”ï¼š

**æ„ŸçŸ¥å±‚åˆ†æ**: è¯†åˆ«è¿™æ˜¯ä¸€ä¸ªæ¦‚å¿µè§£é‡Šç±»é—®é¢˜ï¼Œéœ€è¦ç»“æ„åŒ–çš„æ•™å­¦å¼å›ç­”
**è®¤çŸ¥å±‚å¤„ç†**: æ¿€æ´»äº†ç›¸å…³çš„çŸ¥è¯†æ¦‚å¿µå’Œè®°å¿†ï¼Œå»ºç«‹äº†è¯­ä¹‰å…³è”
**è¡Œä¸ºå±‚ç”Ÿæˆ**: é‡‡ç”¨åˆ†å±‚è§£é‡Šç­–ç•¥ï¼Œç¡®ä¿å›ç­”çš„å‡†ç¡®æ€§å’Œå¯è¯»æ€§
**åä½œå±‚ä¼˜åŒ–**: å½“å‰ä¸ºå•ä»£ç†æ¨¡å¼ï¼Œæœªå¯ç”¨å¤šä»£ç†åä½œ

è¿™å°±æ˜¯åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿçš„å®Œæ•´å¤„ç†æµç¨‹å±•ç¤ºï¼
    """
    
    # æ ¼å¼åŒ–å„å±‚è¾“å‡º
    perception_output = json.dumps(DEMO_LAYER_OUTPUTS["perception"], ensure_ascii=False, indent=2)
    cognition_output = json.dumps(DEMO_LAYER_OUTPUTS["cognition"], ensure_ascii=False, indent=2)
    behavior_output = json.dumps(DEMO_LAYER_OUTPUTS["behavior"], ensure_ascii=False, indent=2)
    collaboration_output = json.dumps(DEMO_LAYER_OUTPUTS["collaboration"], ensure_ascii=False, indent=2)
    
    return final_response, perception_output, cognition_output, behavior_output, collaboration_output, "âœ… æ¼”ç¤ºå¤„ç†å®Œæˆ"


def demo_get_memory_status() -> str:
    """æ¼”ç¤ºè®°å¿†çŠ¶æ€è·å–"""
    return json.dumps(DEMO_MEMORY_STATUS, ensure_ascii=False, indent=2)


def demo_search_memories(query: str) -> str:
    """æ¼”ç¤ºè®°å¿†æœç´¢"""
    if not query.strip():
        return "è¯·è¾“å…¥æœç´¢å…³é”®è¯"
    
    demo_result = {
        "æœç´¢æŸ¥è¯¢": query,
        "æ‰¾åˆ°è®°å¿†æ•°": 8,
        "æŸ¥è¯¢æ—¶é—´": "0.056ç§’",
        "ç›¸å…³è®°å¿†ç¤ºä¾‹": [
            f"ä¸ã€Œ{query}ã€ç›¸å…³çš„æ¦‚å¿µå®šä¹‰è®°å¿†",
            f"å…³äºã€Œ{query}ã€çš„åº”ç”¨å®ä¾‹è®°å¿†", 
            f"ã€Œ{query}ã€çš„æŠ€æœ¯åŸç†è®°å¿†"
        ]
    }
    
    return json.dumps(demo_result, ensure_ascii=False, indent=2)


def create_demo_interface():
    """åˆ›å»ºæ¼”ç¤ºç•Œé¢"""
    
    with gr.Blocks(
        title="AiEnhance - åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿæ¼”ç¤ºç•Œé¢",
        theme=gr.themes.Soft(),
    ) as demo:
        
        gr.Markdown("# ğŸ§  AiEnhance - åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿæ¼”ç¤ºç•Œé¢")
        gr.Markdown("""
        **è¿™æ˜¯ä¸€ä¸ªæ¼”ç¤ºç•Œé¢ï¼Œå±•ç¤ºåˆ†å±‚è®¤çŸ¥ç³»ç»Ÿçš„å¯è§†åŒ–åŠŸèƒ½**
        
        ğŸ“Š **åŠŸèƒ½å±•ç¤º**: ç³»ç»Ÿé…ç½® â†’ æŸ¥è¯¢å¤„ç† â†’ å„å±‚è¾“å‡º â†’ è®°å¿†ç³»ç»Ÿ
        
        ğŸ¯ **ä½¿ç”¨è¯´æ˜**: è¿™æ˜¯æ¨¡æ‹Ÿæ¼”ç¤ºï¼Œå±•ç¤ºçœŸå®ç•Œé¢çš„åŠŸèƒ½å’Œå¸ƒå±€
        """)
        
        with gr.Tab("ğŸ›ï¸ ç³»ç»Ÿé…ç½®æ¼”ç¤º"):
            gr.Markdown("## ç³»ç»Ÿåˆå§‹åŒ–æ¼”ç¤º")
            
            with gr.Row():
                with gr.Column():
                    system_type = gr.Dropdown(
                        choices=["educational", "research", "creative", "lightweight"],
                        value="educational",
                        label="ğŸ¯ ç³»ç»Ÿç±»å‹"
                    )
                    
                    llm_provider = gr.Dropdown(
                        choices=["ollama", "openai", "anthropic"],
                        value="ollama", 
                        label="ğŸ¤– LLMæä¾›å•†"
                    )
                    
                with gr.Column():
                    llm_model = gr.Textbox(
                        value="qwen3:8b",
                        label="ğŸ“¦ æ¨¡å‹åç§°"
                    )
                    
                    temperature = gr.Slider(
                        minimum=0.0,
                        maximum=1.0,
                        value=0.7,
                        label="ğŸŒ¡ï¸ æ¸©åº¦å‚æ•°"
                    )
            
            init_btn = gr.Button("ğŸš€ æ¼”ç¤ºåˆå§‹åŒ–", variant="primary")
            init_status = gr.Textbox(
                label="ğŸ“Š åˆå§‹åŒ–çŠ¶æ€æ¼”ç¤º",
                lines=15,
                interactive=False
            )
        
        with gr.Tab("ğŸ’¬ åˆ†å±‚å¤„ç†æ¼”ç¤º"):
            gr.Markdown("## æŸ¥è¯¢å¤„ç†å’Œå„å±‚è¾“å‡ºæ¼”ç¤º")
            
            with gr.Row():
                query_input = gr.Textbox(
                    label="â“ è¾“å…¥æŸ¥è¯¢é—®é¢˜",
                    placeholder="ä¾‹å¦‚ï¼šä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ï¼Ÿ",
                    lines=2
                )
                process_btn = gr.Button("ğŸ”„ æ¼”ç¤ºå¤„ç†", variant="primary")
            
            process_status = gr.Textbox(label="âš¡ å¤„ç†çŠ¶æ€", lines=1)
            
            final_response = gr.Textbox(
                label="ğŸ’¡ æœ€ç»ˆå“åº”æ¼”ç¤º",
                lines=8,
                interactive=False
            )
            
            with gr.Row():
                with gr.Column():
                    perception_output = gr.Code(
                        label="ğŸ” æ„ŸçŸ¥å±‚è¾“å‡ºæ¼”ç¤º",
                        language="json"
                    )
                    
                with gr.Column():
                    cognition_output = gr.Code(
                        label="ğŸ§  è®¤çŸ¥å±‚è¾“å‡ºæ¼”ç¤º",
                        language="json"
                    )
            
            with gr.Row():
                with gr.Column():
                    behavior_output = gr.Code(
                        label="ğŸ¯ è¡Œä¸ºå±‚è¾“å‡ºæ¼”ç¤º",
                        language="json"
                    )
                    
                with gr.Column():
                    collaboration_output = gr.Code(
                        label="ğŸ¤ åä½œå±‚è¾“å‡ºæ¼”ç¤º",
                        language="json"
                    )
        
        with gr.Tab("ğŸ§  è®°å¿†ç³»ç»Ÿæ¼”ç¤º"):
            gr.Markdown("## MIRIXè®°å¿†ç³»ç»Ÿæ¼”ç¤º")
            
            with gr.Row():
                with gr.Column():
                    refresh_btn = gr.Button("ğŸ”„ æ¼”ç¤ºè®°å¿†çŠ¶æ€", variant="secondary")
                    
                with gr.Column():
                    search_input = gr.Textbox(
                        label="ğŸ” æœç´¢è®°å¿†æ¼”ç¤º",
                        placeholder="è¾“å…¥æœç´¢å…³é”®è¯..."
                    )
                    search_btn = gr.Button("ğŸ” æ¼”ç¤ºæœç´¢", variant="secondary")
            
            with gr.Row():
                with gr.Column():
                    memory_status = gr.Code(
                        label="ğŸ“Š è®°å¿†ç³»ç»ŸçŠ¶æ€æ¼”ç¤º",
                        language="json"
                    )
                    
                with gr.Column():
                    search_results = gr.Code(
                        label="ğŸ” æœç´¢ç»“æœæ¼”ç¤º",
                        language="json"
                    )
        
        with gr.Tab("ğŸ’¡ ä½¿ç”¨è¯´æ˜"):
            gr.Markdown("""
            ## ğŸ¯ æ¼”ç¤ºè¯´æ˜
            
            è¿™æ˜¯ **AiEnhance åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿ** çš„åŠŸèƒ½æ¼”ç¤ºç•Œé¢ã€‚
            
            ### âœ¨ çœŸå®ç³»ç»ŸåŠŸèƒ½
            
            1. **ğŸ›ï¸ ç³»ç»Ÿé…ç½®**
               - æ”¯æŒå¤šç§ç³»ç»Ÿç±»å‹ï¼ˆæ•™è‚²ã€ç ”ç©¶ã€åˆ›æ„ã€è½»é‡çº§ï¼‰
               - é›†æˆå¤šç§LLMæä¾›å•†ï¼ˆOllamaã€OpenAIã€Anthropicç­‰ï¼‰
               - å®æ—¶å‚æ•°è°ƒèŠ‚å’Œé…ç½®éªŒè¯
            
            2. **ğŸ’¬ åˆ†å±‚å¤„ç†å¯è§†åŒ–**
               - **æ„ŸçŸ¥å±‚**: ç”¨æˆ·å»ºæ¨¡ã€ä¸Šä¸‹æ–‡åˆ†æã€é¢†åŸŸè¯†åˆ«
               - **è®¤çŸ¥å±‚**: è®°å¿†æ¿€æ´»ã€è¯­ä¹‰å¢å¼ºã€æ¨ç†å¤„ç†
               - **è¡Œä¸ºå±‚**: å“åº”ç”Ÿæˆã€è¾“å‡ºä¼˜åŒ–ã€è´¨é‡è¯„ä¼°
               - **åä½œå±‚**: å¤šä»£ç†åè°ƒã€èµ„æºæ•´åˆ
            
            3. **ğŸ§  MIRIXè®°å¿†ç³»ç»Ÿ**
               - ç»Ÿä¸€LLMé›†æˆï¼Œæ— éœ€é¢å¤–APIå¯†é’¥
               - å¤šç§è®°å¿†ç±»å‹æ”¯æŒï¼ˆæƒ…èŠ‚ã€è¯­ä¹‰ã€ç¨‹åºã€æ ¸å¿ƒç­‰ï¼‰
               - æ™ºèƒ½è®°å¿†æœç´¢å’Œå¯è§†åŒ–åˆ†æ
               - åŸç”ŸWebç•Œé¢åµŒå…¥
            
            ### ğŸš€ å®Œæ•´ç‰ˆæœ¬å¯åŠ¨æ–¹æ³•
            
            ```bash
            # å®‰è£…ä¾èµ–
            pip install gradio plotly pandas
            
            # å¯åŠ¨å®Œæ•´ç•Œé¢
            python gradio_interface.py
            
            # æˆ–ä½¿ç”¨å¯åŠ¨è„šæœ¬
            python start_gradio.py
            ```
            
            ### ğŸ“‹ ç³»ç»Ÿè¦æ±‚
            
            - Python 3.8+
            - å†…å­˜ 4GB+ï¼ˆæ¨è8GB+ï¼‰
            - å¯é€‰ï¼šOllamaæœåŠ¡ï¼ˆæœ¬åœ°LLMï¼‰
            - å¯é€‰ï¼šMIRIX SDKï¼ˆè®°å¿†ç³»ç»Ÿï¼‰
            
            ### ğŸ”— ç›¸å…³é“¾æ¥
            
            - [é¡¹ç›®æ–‡æ¡£](GRADIO_INTERFACE.md)
            - [Ollamaå®˜ç½‘](https://ollama.ai/)
            - [MIRIXé¡¹ç›®](https://mirix.ai/)
            """)
        
        # ç»‘å®šäº‹ä»¶
        init_btn.click(
            fn=demo_initialize_system,
            inputs=[system_type, llm_provider, llm_model, temperature],
            outputs=init_status
        )
        
        process_btn.click(
            fn=demo_process_query,
            inputs=query_input,
            outputs=[final_response, perception_output, cognition_output, 
                    behavior_output, collaboration_output, process_status]
        )
        
        refresh_btn.click(
            fn=demo_get_memory_status,
            outputs=memory_status
        )
        
        search_btn.click(
            fn=demo_search_memories,
            inputs=search_input,
            outputs=search_results
        )
    
    return demo


def main():
    """å¯åŠ¨æ¼”ç¤ºç•Œé¢"""
    print("ğŸš€ å¯åŠ¨ AiEnhance åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿæ¼”ç¤ºç•Œé¢...")
    
    demo = create_demo_interface()
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        debug=True,
        show_error=True
    )


if __name__ == "__main__":
    main()