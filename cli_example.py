#!/usr/bin/env python3
"""
AiEnhance å‘½ä»¤è¡Œå·¥å…·
ç®€å•çš„å‘½ä»¤è¡Œç•Œé¢ï¼Œå¿«é€Ÿä½“éªŒè®°å¿†-è®¤çŸ¥ååŒç³»ç»Ÿ
"""

import aienhance
import asyncio
import sys
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))


class AiEnhanceCliTool:
    """AiEnhanceå‘½ä»¤è¡Œå·¥å…·"""

    def __init__(self):
        self.system = None

    async def check_ollama(self):
        """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
        try:
            import httpx
            async with httpx.AsyncClient() as client:
                response = await client.get("http://localhost:11434/api/tags", timeout=3.0)
                if response.status_code == 200:
                    return True
                return False
        except:
            return False

    async def initialize_system(self, system_type="educational", temperature=0.7, use_memory=True):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        try:
            if use_memory:
                # å®Œæ•´ç³»ç»Ÿé…ç½®ï¼Œä½¿ç”¨ç»Ÿä¸€LLMæ¨¡å¼
                self.system = aienhance.create_ollama_mirix_system(
                    model_name="qwen3:8b",
                    ollama_base="http://localhost:11434",
                    system_type=system_type,
                    llm_temperature=temperature,
                    llm_max_tokens=800,
                    embedding_provider="ollama",
                    embedding_model_name="bge-m3:latest"
                )
            else:
                # ç®€åŒ–é…ç½®ï¼Œä»…ä½¿ç”¨LLMåŠŸèƒ½
                print("âš ï¸  ç®€åŒ–æ¨¡å¼ï¼šä»…å¯ç”¨LLMåŠŸèƒ½ï¼Œä¸åŒ…å«è®°å¿†ç³»ç»Ÿ")
                self.system = aienhance.create_system(
                    system_type=system_type,
                    llm_provider="ollama",
                    llm_model_name="qwen3:8b",
                    llm_temperature=temperature,
                    llm_max_tokens=800
                )
            return True
        except Exception as e:
            print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            # å¦‚æœå®Œæ•´æ¨¡å¼å¤±è´¥ï¼Œå°è¯•ç®€åŒ–æ¨¡å¼
            if use_memory:
                print("ğŸ”„ å°è¯•ç®€åŒ–æ¨¡å¼...")
                return await self.initialize_system(system_type, temperature, use_memory=False)
            return False

    async def single_query(self, query, system_type="educational", temperature=0.7, show_details=False):
        """å•æ¬¡æŸ¥è¯¢"""
        print("ğŸ”§ åˆå§‹åŒ–ç³»ç»Ÿ...")
        if not await self.initialize_system(system_type, temperature):
            return

        print("ğŸ¤” å¤„ç†æŸ¥è¯¢ä¸­...")
        try:
            # ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿èµ„æºæ¸…ç†
            async with self.system:
                response = await self.system.process_query(
                    query=query,
                    user_id="cli_user",
                    context={"source": "cli"}
                )

                print("\n" + "="*50)
                print("ğŸ¤– AIå›ç­”:")
                print("="*50)
                if response.content:
                    print(response.content)
                else:
                    print("(æ— å†…å®¹ç”Ÿæˆ - è¯·æ£€æŸ¥OllamaæœåŠ¡)")

                if show_details:
                    print("\n" + "="*50)
                    print("ğŸ“Š è¯¦ç»†ä¿¡æ¯:")
                    print("="*50)

                    # å¤„ç†æ­¥éª¤
                    if hasattr(response, 'processing_metadata'):
                        steps = response.processing_metadata.get(
                            'processing_steps', [])
                        print(f"ğŸ”„ å¤„ç†æ­¥éª¤: {' â†’ '.join(steps)}")

                    # ç”¨æˆ·ç”»åƒ
                    if hasattr(response, 'user_profile'):
                        profile = response.user_profile.cognitive
                        print(f"ğŸ‘¤ ç”¨æˆ·ç”»åƒ:")
                        print(f"   æ€ç»´æ¨¡å¼: {profile.thinking_mode.value}")
                        print(f"   è®¤çŸ¥å¤æ‚åº¦: {profile.cognitive_complexity:.2f}")
                        print(f"   æŠ½è±¡æ°´å¹³: {profile.abstraction_level:.2f}")

                    # é€‚é…ä¿¡æ¯
                    if hasattr(response, 'adaptation_info'):
                        adapt = response.adaptation_info
                        print(f"âš™ï¸ é€‚é…ç­–ç•¥:")
                        print(f"   è¾“å‡ºå¯†åº¦: {adapt.density_level.value}")
                        print(f"   ç»“æ„ç±»å‹: {adapt.structure_type.value}")
                        print(f"   è®¤çŸ¥è´Ÿè·: {adapt.cognitive_load:.2f}")

                    # ç³»ç»ŸçŠ¶æ€
                    status = self.system.get_system_status()
                    print(f"ğŸ” ç³»ç»ŸçŠ¶æ€:")
                    print(f"   ç³»ç»Ÿç±»å‹: {system_type}")
                    print(
                        f"   LLMé…ç½®: {status.get('llm_provider', {}).get('provider', 'None')}")
                    print(f"   å“åº”é•¿åº¦: {len(response.content)}å­—ç¬¦")

        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}")

    async def interactive_mode(self, system_type="educational", temperature=0.7):
        """äº¤äº’æ¨¡å¼"""
        print("ğŸš€ AiEnhance äº¤äº’æ¨¡å¼")
        print("="*50)
        print("ğŸ’¡ æç¤º:")
        print("  â€¢ ç›´æ¥è¾“å…¥é—®é¢˜ï¼ŒæŒ‰å›è½¦å‘é€")
        print("  â€¢ è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("  â€¢ è¾“å…¥ 'clear' æ¸…å±")
        print("  â€¢ è¾“å…¥ 'status' æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€")
        print("="*50)

        # åˆå§‹åŒ–ç³»ç»Ÿ
        print("ğŸ”§ åˆå§‹åŒ–ç³»ç»Ÿ...")
        if not await self.initialize_system(system_type, temperature):
            return
        print(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ (ç±»å‹: {system_type}, æ¸©åº¦: {temperature})")

        session_count = 0

        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input(f"\n[{session_count}] ğŸ‘¤ æ‚¨: ").strip()

                # å¤„ç†ç‰¹æ®Šå‘½ä»¤
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                    print("ğŸ‘‹ å†è§ï¼æ„Ÿè°¢ä½¿ç”¨AiEnhance")
                    break
                elif user_input.lower() == 'clear':
                    import os
                    os.system('clear' if os.name == 'posix' else 'cls')
                    continue
                elif user_input.lower() == 'status':
                    status = self.system.get_system_status()
                    print(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€: {status}")
                    continue
                elif not user_input:
                    continue

                # å¤„ç†æŸ¥è¯¢
                print("ğŸ¤” æ€è€ƒä¸­...")
                response = await self.system.process_query(
                    query=user_input,
                    user_id="interactive_user",
                    context={"session": session_count}
                )

                # æ˜¾ç¤ºå“åº”
                print(f"ğŸ¤– AI: ", end="")
                if response.content:
                    print(response.content)

                    # æ˜¾ç¤ºç®€è¦ä¿¡æ¯
                    if hasattr(response, 'adaptation_info'):
                        adapt = response.adaptation_info
                        print(
                            f"    âš™ï¸ [{adapt.density_level.value}å¯†åº¦, è´Ÿè·{adapt.cognitive_load:.1f}]")
                else:
                    print("(æ— æ³•ç”Ÿæˆå“åº”)")

                session_count += 1

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
                break
            except Exception as e:
                print(f"âŒ å¤„ç†é”™è¯¯: {e}")

    async def demo_mode(self):
        """æ¼”ç¤ºæ¨¡å¼"""
        print("ğŸ® AiEnhance æ¼”ç¤ºæ¨¡å¼")
        print("="*50)

        # æ¼”ç¤ºæŸ¥è¯¢
        demo_queries = [
            ("åŸºç¡€é—®ç­”", "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"),
            ("çŸ¥è¯†è§£é‡Š", "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿè¯·ç®€å•è§£é‡Š"),
            ("åˆ›æ„æ€ç»´", "è®¾è®¡ä¸€ä¸ªæ™ºèƒ½å®¶å±…ç³»ç»Ÿçš„åŸºæœ¬æ–¹æ¡ˆ"),
            ("é—®é¢˜åˆ†æ", "åˆ†æä¸€ä¸‹è¿œç¨‹å·¥ä½œçš„åˆ©å¼Š")
        ]

        # åˆå§‹åŒ–ç³»ç»Ÿ
        print("ğŸ”§ åˆå§‹åŒ–æ¼”ç¤ºç³»ç»Ÿ...")
        if not await self.initialize_system("educational", 0.7):
            return
        print("âœ… ç³»ç»Ÿå°±ç»ª\n")

        for i, (category, query) in enumerate(demo_queries, 1):
            print(f"{i}ï¸âƒ£ {category}æ¼”ç¤º")
            print(f"ğŸ‘¤ ç”¨æˆ·: {query}")
            print("ğŸ¤” AIæ€è€ƒä¸­...")

            try:
                response = await self.system.process_query(
                    query=query,
                    user_id="demo_user",
                    context={"demo_type": category}
                )

                if response.content:
                    print(f"ğŸ¤– AI: {response.content}")

                    # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯
                    if hasattr(response, 'adaptation_info'):
                        adapt = response.adaptation_info
                        print(
                            f"ğŸ“Š é€‚é…ä¿¡æ¯: {adapt.density_level.value}å¯†åº¦, è®¤çŸ¥è´Ÿè·{adapt.cognitive_load:.2f}")
                else:
                    print("ğŸ¤– AI: (æ— å“åº”ç”Ÿæˆ)")

                print("-" * 50)

                # çŸ­æš‚åœé¡¿
                if i < len(demo_queries):
                    await asyncio.sleep(1)

            except Exception as e:
                print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
                print("-" * 50)

        print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="AiEnhance å‘½ä»¤è¡Œå·¥å…· - è®°å¿†-è®¤çŸ¥ååŒç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python ai.py "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"                    # å•æ¬¡æŸ¥è¯¢
  python ai.py -i                                    # äº¤äº’æ¨¡å¼  
  python ai.py -d                                    # æ¼”ç¤ºæ¨¡å¼
  python ai.py "è§£é‡Šæ·±åº¦å­¦ä¹ " --type research        # ç ”ç©¶æ¨¡å¼æŸ¥è¯¢
  python ai.py "åˆ›æ„å†™ä½œ" --temp 0.9 --details       # é«˜åˆ›é€ æ€§ + è¯¦ç»†ä¿¡æ¯
        """
    )

    # ä½ç½®å‚æ•°
    parser.add_argument('query', nargs='?', help='è¦å¤„ç†çš„æŸ¥è¯¢é—®é¢˜')

    # å¯é€‰å‚æ•°
    parser.add_argument('-i', '--interactive',
                        action='store_true', help='å¯åŠ¨äº¤äº’æ¨¡å¼')
    parser.add_argument('-d', '--demo', action='store_true', help='è¿è¡Œæ¼”ç¤ºæ¨¡å¼')
    parser.add_argument('--type', choices=['default', 'educational', 'research'],
                        default='educational', help='ç³»ç»Ÿç±»å‹ (é»˜è®¤: educational)')
    parser.add_argument('--temp', type=float, default=0.7,
                        help='æ¸©åº¦å‚æ•° 0.0-1.0 (é»˜è®¤: 0.7)')
    parser.add_argument('--details', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†çš„å¤„ç†ä¿¡æ¯')

    args = parser.parse_args()

    # åˆ›å»ºå·¥å…·å®ä¾‹
    tool = AiEnhanceCliTool()

    # æ£€æŸ¥OllamaæœåŠ¡
    print("ğŸ” æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€...")
    if not await tool.check_ollama():
        print("âŒ OllamaæœåŠ¡æœªè¿è¡Œæˆ–æ¨¡å‹æœªå®‰è£…")
        print("ğŸ’¡ è¯·ç¡®ä¿:")
        print("   1. OllamaæœåŠ¡è¿è¡Œ: ollama serve")
        print("   2. æ¨¡å‹å·²å®‰è£…: ollama pull qwen3:8b")
        return
    print("âœ… OllamaæœåŠ¡æ­£å¸¸")

    # æ ¹æ®å‚æ•°é€‰æ‹©æ¨¡å¼
    if args.interactive:
        await tool.interactive_mode(args.type, args.temp)
    elif args.demo:
        await tool.demo_mode()
    elif args.query:
        await tool.single_query(args.query, args.type, args.temp, args.details)
    else:
        # é»˜è®¤æ˜¾ç¤ºå¸®åŠ©
        parser.print_help()
        print("\nğŸ’¡ å¿«é€Ÿå¼€å§‹:")
        print('  python ai.py "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"')
        print("  python ai.py -i  # è¿›å…¥äº¤äº’æ¨¡å¼")
        print("  python ai.py -d  # æŸ¥çœ‹æ¼”ç¤º")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"âŒ ç¨‹åºé”™è¯¯: {e}")
