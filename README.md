# AiEnhance - è®°å¿†-è®¤çŸ¥ååŒç³»ç»Ÿ

ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ å’Œè®¤çŸ¥ç§‘å­¦çš„AIè®¤çŸ¥å¢å¼ºç³»ç»Ÿï¼Œå®ç°è®°å¿†-è®¤çŸ¥ååŒå¤„ç†ã€‚

## æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„è®°å¿†-è®¤çŸ¥ååŒç³»ç»Ÿï¼Œè¶…è¶Šä¼ ç»ŸRAGï¼ˆRetrieval-Augmented Generationï¼‰æ¨¡å¼ï¼Œæ„å»ºå…·å¤‡"è®°å¿†è¿‡æ»¤ä¸é‡æ„èƒ½åŠ›ã€è¯­ä¹‰æ˜¾åŒ–ä¸è”æƒ³èƒ½åŠ›ã€è®¤çŸ¥è¡¥å…¨ä¸æ”¾å¤§èƒ½åŠ›"çš„æ™ºèƒ½ç³»ç»Ÿã€‚

## æ ¸å¿ƒç‰¹æ€§

### ğŸ—ï¸ å››å±‚æ¶æ„
- **æ„ŸçŸ¥å±‚** - ç”¨æˆ·å»ºæ¨¡å’Œæƒ…å¢ƒåˆ†æ
- **è®¤çŸ¥å±‚** - è®°å¿†æ¿€æ´»ã€è¯­ä¹‰å¢å¼ºã€ç±»æ¯”æ¨ç†
- **è¡Œä¸ºå±‚** - è‡ªé€‚åº”è¾“å‡º
- **åä½œå±‚** - äººæœºè®¤çŸ¥åä½œ

### ğŸ§  æ ¸å¿ƒèƒ½åŠ›
- **å¤šå…ƒåŒ–è®°å¿†** - æ”¯æŒå¤šç§è®°å¿†ç³»ç»Ÿï¼ˆMIRIX SDKã€Mem0ã€Graphitiï¼‰
- **ç®€åŒ–éƒ¨ç½²** - MIRIX SDKé›†æˆï¼Œæ— éœ€å¤æ‚Dockeré…ç½®  
- **çµæ´»LLM** - å¤šLLMæä¾›å•†æ”¯æŒï¼ˆOllamaã€OpenAIã€Anthropicï¼‰
- **è®¤çŸ¥åä½œ** - è¾©è¯è§†è§’ã€è®¤çŸ¥æŒ‘æˆ˜ã€ç”¨æˆ·å»ºæ¨¡
- **å³è£…å³ç”¨** - pip installå³å¯å¼€å§‹ä½¿ç”¨

## è®¾è®¡ç†å¿µ

ç³»ç»Ÿè®¾è®¡ç«‹è¶³äºä»¥ä¸‹æ ¸å¿ƒç†å¿µï¼š

1. **è®°å¿†é©±åŠ¨** - ä»¥è®°å¿†ä¸ºæ ¸å¿ƒçš„è®¤çŸ¥å¤„ç†
2. **ååŒå¢å¼º** - AIä¸äººç±»å…±æ„è®¤çŸ¥ä½“ç³»
3. **é€‚åº”æ€§** - æ ¹æ®ç”¨æˆ·ç‰¹å¾åŠ¨æ€è°ƒæ•´

## æŠ€æœ¯æ ˆ

- **è¯­è¨€**: Python 3.12.9
- **åŒ…ç®¡ç†**: uv
- **ä»£ç è´¨é‡**: ruff
- **ç‰ˆæœ¬æ§åˆ¶**: Git
- **å®¹å™¨åŒ–**: Docker + Docker Compose
- **AIæ¡†æ¶**: Ollama (æœ¬åœ°LLM)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.12.9+
- UVåŒ…ç®¡ç†å™¨ï¼ˆæ¨èï¼‰æˆ–pip
- Ollama (æœ¬åœ°LLMæœåŠ¡)

### å®‰è£…

```bash
# ä½¿ç”¨UVåŒ…ç®¡ç†å™¨ï¼ˆæ¨èï¼‰
git clone https://github.com/your-username/AiEnhance.git
cd AiEnhance
uv sync

# æˆ–ä½¿ç”¨ä¼ ç»Ÿpipæ–¹å¼
pip install -e .
```

### è¿è¡Œç¤ºä¾‹

#### å‘½ä»¤è¡Œç•Œé¢
```bash
# ä½¿ç”¨UV
uv run aienhance "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"
uv run aienhance -i  # äº¤äº’æ¨¡å¼

# æˆ–ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼
python cli_example.py "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"
```

#### Gradio Webç•Œé¢
```bash
# ä½¿ç”¨UV
uv run aienhance-gradio

# æˆ–ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼
python gradio_interface.py
```

è®¿é—® `http://localhost:7860` å¼€å§‹ä½¿ç”¨Webç•Œé¢ã€‚

### Ollamaè®¾ç½®

é¦–æ¬¡ä½¿ç”¨éœ€è¦å®‰è£…å’Œé…ç½®Ollamaï¼š

```bash
# å®‰è£…Ollama
# macOS
brew install ollama

# Linux  
curl -fsSL https://ollama.ai/install.sh | sh

# å¯åŠ¨OllamaæœåŠ¡
ollama serve

# å®‰è£…æ¨èæ¨¡å‹
ollama pull qwen3:8b
ollama pull bge-m3:latest
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
AiEnhance/
â”œâ”€â”€ aienhance/              # æ ¸å¿ƒåŒ…
â”‚   â”œâ”€â”€ core/              # æ ¸å¿ƒç³»ç»Ÿ
â”‚   â”œâ”€â”€ perception/        # æ„ŸçŸ¥å±‚
â”‚   â”œâ”€â”€ cognition/         # è®¤çŸ¥å±‚
â”‚   â”œâ”€â”€ behavior/          # è¡Œä¸ºå±‚
â”‚   â”œâ”€â”€ collaboration/     # åä½œå±‚
â”‚   â”œâ”€â”€ memory/            # è®°å¿†ç³»ç»Ÿé€‚é…å™¨
â”‚   â””â”€â”€ llm/               # LLMé€‚é…å™¨
â”œâ”€â”€ cli_example.py         # å‘½ä»¤è¡Œç¤ºä¾‹
â”œâ”€â”€ gradio_interface.py    # Webç•Œé¢
â”œâ”€â”€ tests/                 # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ scripts/               # è¾…åŠ©è„šæœ¬
â”œâ”€â”€ docker/                # Dockeré…ç½®
â””â”€â”€ docs/                  # æ–‡æ¡£
```

## å¼€å‘

### ä»£ç è´¨é‡æ£€æŸ¥
```bash
uv run ruff check .    # ä»£ç æ£€æŸ¥
uv run ruff format .   # ä»£ç æ ¼å¼åŒ–
```

### è¿è¡Œæµ‹è¯•
```bash
uv run python -m pytest tests/
```

## ä½¿ç”¨ç¤ºä¾‹

### Python API

```python
import aienhance

# åˆ›å»ºç³»ç»Ÿ
system = aienhance.create_layered_system(
    system_type="educational",
    llm_provider="ollama",
    llm_model_name="qwen3:8b"
)

# å¤„ç†æŸ¥è¯¢
response = await system.process_query(
    query="ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
    user_id="user123"
)

print(response.content)
```

## æ–‡æ¡£

- [Gradioç•Œé¢ä½¿ç”¨æŒ‡å—](GRADIO_INTERFACE.md)
- [ç³»ç»Ÿè®¾è®¡æ–‡æ¡£](docs/design/memory-cognitive-system-design.md)

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## è®¸å¯è¯

[MIT License](LICENSE)