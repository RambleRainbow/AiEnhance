#!/usr/bin/env python3
"""
Ollamaé›†æˆç¤ºä¾‹
å±•ç¤ºå¦‚ä½•åœ¨å®é™…åº”ç”¨ä¸­é›†æˆOllama qwen3:8bæ¨¡å‹
"""

import asyncio
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

import aienhance
from aienhance.llm import ModelConfig, ModelType


class OllamaIntegrationExample:
    """Ollamaé›†æˆç¤ºä¾‹ç±»"""
    
    def __init__(self):
        self.system = None
        self.config = self._create_ollama_config()
    
    def _create_ollama_config(self):
        """åˆ›å»ºOllamaé…ç½®"""
        return {
            # åŸºç¡€é…ç½®
            "system_type": "educational",
            
            # LLMé…ç½®
            "llm_provider": "ollama",
            "llm_model_name": "qwen3:8b",
            "llm_api_base": "http://localhost:11434",
            "llm_temperature": 0.7,
            "llm_max_tokens": 1000,
            
            # åµŒå…¥æ¨¡å‹é…ç½®
            "embedding_provider": "ollama",
            "embedding_model_name": "bge-m3",
            "embedding_api_base": "http://localhost:11434"
        }
    
    async def initialize_system(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        print("ğŸ”§ åˆå§‹åŒ–AiEnhanceç³»ç»Ÿ...")
        
        try:
            # åˆ›å»ºç³»ç»Ÿå®ä¾‹
            self.system = aienhance.create_system(**self.config)
            
            # æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
            status = self.system.get_system_status()
            print(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
            print(f"   â€¢ LLMé…ç½®: {status.get('llm_provider', 'None')}")
            print(f"   â€¢ åµŒå…¥æ¨¡å‹: {status.get('embedding_provider', 'None')}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def check_ollama_status(self):
        """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
        print("\nğŸ” æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€...")
        
        import httpx
        try:
            async with httpx.AsyncClient() as client:
                # æ£€æŸ¥æœåŠ¡å¯ç”¨æ€§
                response = await client.get("http://localhost:11434/api/tags", timeout=5.0)
                
                if response.status_code == 200:
                    models_data = response.json()
                    available_models = [model['name'] for model in models_data.get('models', [])]
                    
                    print(f"âœ… OllamaæœåŠ¡æ­£å¸¸è¿è¡Œ")
                    print(f"ğŸ“š å¯ç”¨æ¨¡å‹: {', '.join(available_models)}")
                    
                    # æ£€æŸ¥å¿…éœ€æ¨¡å‹
                    required_models = ["qwen3:8b", "bge-m3"]
                    missing_models = [model for model in required_models if model not in available_models]
                    
                    if missing_models:
                        print(f"âš ï¸ ç¼ºå°‘æ¨¡å‹: {', '.join(missing_models)}")
                        print(f"ğŸ’¡ è¯·è¿è¡Œ: ollama pull {' && ollama pull '.join(missing_models)}")
                        return False
                    else:
                        print(f"âœ… æ‰€æœ‰å¿…éœ€æ¨¡å‹å·²å°±ç»ª")
                        return True
                else:
                    print(f"âŒ OllamaæœåŠ¡å¼‚å¸¸: HTTP {response.status_code}")
                    return False
                    
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥OllamaæœåŠ¡: {e}")
            print(f"ğŸ’¡ è¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ: ollama serve")
            return False
    
    async def demonstrate_basic_chat(self):
        """æ¼”ç¤ºåŸºç¡€å¯¹è¯åŠŸèƒ½"""
        print("\nğŸ’¬ åŸºç¡€å¯¹è¯åŠŸèƒ½æ¼”ç¤º")
        print("-" * 40)
        
        chat_examples = [
            {
                "user_input": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±",
                "expected": "åº”è¯¥åŒ…å«æ¨¡å‹ä»‹ç»"
            },
            {
                "user_input": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
                "expected": "åº”è¯¥è§£é‡Šæœºå™¨å­¦ä¹ æ¦‚å¿µ"
            },
            {
                "user_input": "è¯·å†™ä¸€ä¸ªPythonçš„Hello Worldç¨‹åº",
                "expected": "åº”è¯¥åŒ…å«Pythonä»£ç ç¤ºä¾‹"
            }
        ]
        
        for i, example in enumerate(chat_examples, 1):
            print(f"\n{i}. ğŸ‘¤ ç”¨æˆ·: {example['user_input']}")
            
            try:
                response = await self.system.process_query(
                    query=example['user_input'],
                    user_id="demo_user",
                    context={"demo_type": "basic_chat"}
                )
                
                if response.content:
                    print(f"   ğŸ¤– åŠ©æ‰‹: {response.content[:200]}...")
                    print(f"   ğŸ“Š å“åº”é•¿åº¦: {len(response.content)}å­—ç¬¦")
                    
                    # æ˜¾ç¤ºå¤„ç†ä¿¡æ¯
                    if hasattr(response, 'adaptation_info'):
                        print(f"   âš™ï¸ é€‚é…: {response.adaptation_info.density_level.value}å¯†åº¦")
                else:
                    print(f"   âŒ æ— å“åº”å†…å®¹ç”Ÿæˆ")
                    
            except Exception as e:
                print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
    
    async def demonstrate_educational_features(self):
        """æ¼”ç¤ºæ•™è‚²åŠŸèƒ½ç‰¹æ€§"""
        print("\nğŸ“ æ•™è‚²åŠŸèƒ½ç‰¹æ€§æ¼”ç¤º")
        print("-" * 40)
        
        educational_queries = [
            {
                "query": "è¯·è§£é‡Šæ·±åº¦å­¦ä¹ çš„åŸºæœ¬åŸç†ï¼Œæˆ‘æ˜¯åˆå­¦è€…",
                "context": {"difficulty_level": "beginner"},
                "expected_features": ["å¾ªåºæ¸è¿›", "åŸºç¡€æ¦‚å¿µ", "é€šä¿—æ˜“æ‡‚"]
            },
            {
                "query": "æ¯”è¾ƒç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ çš„åŒºåˆ«",
                "context": {"difficulty_level": "intermediate"},
                "expected_features": ["å¯¹æ¯”åˆ†æ", "å…·ä½“ä¾‹å­", "å®é™…åº”ç”¨"]
            },
            {
                "query": "ç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­ç®—æ³•çš„æ•°å­¦æ¨å¯¼",
                "context": {"difficulty_level": "advanced"},
                "expected_features": ["æ•°å­¦å…¬å¼", "è¯¦ç»†æ¨å¯¼", "ç†è®ºæ·±åº¦"]
            }
        ]
        
        for i, edu_query in enumerate(educational_queries, 1):
            print(f"\n{i}. ğŸ“š æ•™è‚²æŸ¥è¯¢: {edu_query['query']}")
            print(f"   ğŸ¯ é¢„æœŸç‰¹å¾: {', '.join(edu_query['expected_features'])}")
            
            try:
                response = await self.system.process_query(
                    query=edu_query['query'],
                    user_id="student_user",
                    context=edu_query['context']
                )
                
                if response.content:
                    print(f"   âœ… å“åº”ç”ŸæˆæˆåŠŸ ({len(response.content)}å­—ç¬¦)")
                    
                    # åˆ†ææ•™è‚²ç‰¹å¾
                    content_lower = response.content.lower()
                    features_found = []
                    
                    # ç®€å•çš„ç‰¹å¾æ£€æµ‹
                    if any(word in content_lower for word in ["é¦–å…ˆ", "ç„¶å", "æœ€å", "æ­¥éª¤"]):
                        features_found.append("ç»“æ„åŒ–")
                    if any(word in content_lower for word in ["ä¾‹å¦‚", "æ¯”å¦‚", "ä¸¾ä¾‹"]):
                        features_found.append("ä¸¾ä¾‹è¯´æ˜")
                    if any(word in content_lower for word in ["ç®€å•", "é€šä¿—", "åŸºç¡€"]):
                        features_found.append("æ˜“æ‡‚è¡¨è¾¾")
                    
                    print(f"   ğŸ“‹ æ£€æµ‹åˆ°ç‰¹å¾: {', '.join(features_found) if features_found else 'æ— æ˜æ˜¾ç‰¹å¾'}")
                    
                    # æ˜¾ç¤ºé€‚é…ä¿¡æ¯
                    if hasattr(response, 'adaptation_info'):
                        print(f"   ğŸ›ï¸ é€‚é…å‚æ•°: å¯†åº¦={response.adaptation_info.density_level.value}, è´Ÿè·={response.adaptation_info.cognitive_load:.2f}")
                else:
                    print(f"   âŒ æ— å“åº”å†…å®¹")
                    
            except Exception as e:
                print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
    
    async def demonstrate_multilingual_support(self):
        """æ¼”ç¤ºå¤šè¯­è¨€æ”¯æŒ"""
        print("\nğŸŒ å¤šè¯­è¨€æ”¯æŒæ¼”ç¤º")
        print("-" * 40)
        
        multilingual_tests = [
            {
                "language": "ä¸­æ–‡",
                "query": "è¯·ç”¨ä¸­æ–‡è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½",
                "expected_lang": "ä¸­æ–‡"
            },
            {
                "language": "English", 
                "query": "Please explain artificial intelligence in English",
                "expected_lang": "English"
            },
            {
                "language": "æ··åˆ",
                "query": "What is AIï¼Ÿè¯·ç”¨ä¸­è‹±æ–‡æ··åˆå›ç­”",
                "expected_lang": "ä¸­è‹±æ··åˆ"
            }
        ]
        
        for test in multilingual_tests:
            print(f"\nğŸ—£ï¸ {test['language']}æµ‹è¯•: {test['query']}")
            
            try:
                response = await self.system.process_query(
                    query=test['query'],
                    user_id="multilingual_user",
                    context={"language_test": test['language']}
                )
                
                if response.content:
                    print(f"   âœ… å“åº”ç”Ÿæˆ ({len(response.content)}å­—ç¬¦)")
                    # æ˜¾ç¤ºå“åº”ç‰‡æ®µ
                    preview = response.content[:150] + "..." if len(response.content) > 150 else response.content
                    print(f"   ğŸ“ å†…å®¹é¢„è§ˆ: {preview}")
                else:
                    print(f"   âŒ æ— å“åº”å†…å®¹")
                    
            except Exception as e:
                print(f"   âŒ å¤„ç†å¤±è´¥: {e}")
    
    async def demonstrate_performance_metrics(self):
        """æ¼”ç¤ºæ€§èƒ½æŒ‡æ ‡"""
        print("\nğŸ“Š æ€§èƒ½æŒ‡æ ‡æ¼”ç¤º")
        print("-" * 40)
        
        # æ€§èƒ½æµ‹è¯•æŸ¥è¯¢
        performance_queries = [
            "ç®€å•æŸ¥è¯¢ï¼š1+1ç­‰äºå‡ ï¼Ÿ",
            "ä¸­ç­‰æŸ¥è¯¢ï¼šè¯·è§£é‡Šæœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ",
            "å¤æ‚æŸ¥è¯¢ï¼šè¯·è¯¦ç»†åˆ†ææ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„æœ€æ–°å‘å±•è¶‹åŠ¿"
        ]
        
        results = []
        
        for i, query in enumerate(performance_queries, 1):
            print(f"\n{i}. â±ï¸ æµ‹è¯•æŸ¥è¯¢: {query}")
            
            start_time = asyncio.get_event_loop().time()
            
            try:
                response = await self.system.process_query(
                    query=query,
                    user_id="perf_test_user",
                    context={"performance_test": True}
                )
                
                end_time = asyncio.get_event_loop().time()
                duration = end_time - start_time
                
                if response.content:
                    result = {
                        "query_type": f"æµ‹è¯•{i}",
                        "duration": duration,
                        "content_length": len(response.content),
                        "words_per_second": len(response.content) / duration if duration > 0 else 0
                    }
                    results.append(result)
                    
                    print(f"   âœ… è€—æ—¶: {duration:.2f}ç§’")
                    print(f"   ğŸ“ é•¿åº¦: {len(response.content)}å­—ç¬¦")
                    print(f"   ğŸš€ é€Ÿåº¦: {result['words_per_second']:.1f}å­—ç¬¦/ç§’")
                else:
                    print(f"   âŒ æ— å†…å®¹ç”Ÿæˆ")
                    
            except Exception as e:
                print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
        
        # æ€§èƒ½æ€»ç»“
        if results:
            print(f"\nğŸ“ˆ æ€§èƒ½æ€»ç»“:")
            avg_duration = sum(r['duration'] for r in results) / len(results)
            avg_length = sum(r['content_length'] for r in results) / len(results)
            avg_speed = sum(r['words_per_second'] for r in results) / len(results)
            
            print(f"   â€¢ å¹³å‡å“åº”æ—¶é—´: {avg_duration:.2f}ç§’")
            print(f"   â€¢ å¹³å‡å“åº”é•¿åº¦: {avg_length:.0f}å­—ç¬¦")
            print(f"   â€¢ å¹³å‡ç”Ÿæˆé€Ÿåº¦: {avg_speed:.1f}å­—ç¬¦/ç§’")
    
    async def run_complete_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        print("ğŸš€ Ollamaé›†æˆå®Œæ•´æ¼”ç¤ºå¼€å§‹")
        print("=" * 60)
        
        # 1. æ£€æŸ¥ç¯å¢ƒ
        if not await self.check_ollama_status():
            print("âŒ Ollamaç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œæ¼”ç¤ºç»ˆæ­¢")
            return False
        
        # 2. åˆå§‹åŒ–ç³»ç»Ÿ
        if not await self.initialize_system():
            print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œæ¼”ç¤ºç»ˆæ­¢")
            return False
        
        # 3. è¿è¡Œå„é¡¹æ¼”ç¤º
        await self.demonstrate_basic_chat()
        await self.demonstrate_educational_features()
        await self.demonstrate_multilingual_support()
        await self.demonstrate_performance_metrics()
        
        print("\nğŸ‰ Ollamaé›†æˆæ¼”ç¤ºå®Œæˆï¼")
        print("=" * 60)
        print("âœ… æ‰€æœ‰åŠŸèƒ½æ¨¡å—æµ‹è¯•å®Œæˆ")
        print("âœ… Ollama qwen3:8bæ¨¡å‹é›†æˆæˆåŠŸ")
        print("âœ… æ•™è‚²ç³»ç»Ÿç‰¹æ€§éªŒè¯é€šè¿‡")
        print("âœ… æ€§èƒ½æŒ‡æ ‡æ”¶é›†å®Œæˆ")
        
        return True


async def main():
    """ä¸»å‡½æ•°"""
    example = OllamaIntegrationExample()
    success = await example.run_complete_demo()
    return success


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)