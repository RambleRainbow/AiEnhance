#!/usr/bin/env python3
"""
é›†ä¸­å¼æç¤ºè¯ç®¡ç†ç³»ç»Ÿæ¼”ç¤º
å±•ç¤ºå¦‚ä½•ä½¿ç”¨æ–°çš„æç¤ºè¯ç®¡ç†ç³»ç»Ÿè¿›è¡Œæ¨¡æ¿ç®¡ç†å’Œæ¸²æŸ“
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from aienhance.core.prompts import (
    get_prompt_manager,
    render_prompt,
    get_prompt_template,
    list_available_prompts,
    PromptTemplate,
)


def demonstrate_prompt_listing():
    """æ¼”ç¤ºæç¤ºè¯åˆ—è¡¨åŠŸèƒ½"""
    print("ğŸ”§ æç¤ºè¯ç®¡ç†ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)

    print("\n1ï¸âƒ£ æ‰€æœ‰å¯ç”¨æç¤ºè¯:")
    all_prompts = list_available_prompts()
    for prompt in all_prompts:
        print(f"   â€¢ {prompt}")

    print("\n2ï¸âƒ£ æŒ‰ç±»åˆ«åˆ†ç»„çš„æç¤ºè¯:")
    categories = ["domain_inference", "user_modeling", "cognitive_analysis"]

    for category in categories:
        print(f"\n   ğŸ“Œ {category}:")
        category_prompts = list_available_prompts(category)
        for prompt in category_prompts:
            print(f"      - {prompt}")


def demonstrate_template_info():
    """æ¼”ç¤ºæ¨¡æ¿ä¿¡æ¯æŸ¥çœ‹"""
    print("\n" + "=" * 50)
    print("ğŸ“‹ æ¨¡æ¿è¯¦ç»†ä¿¡æ¯")
    print("=" * 50)

    manager = get_prompt_manager()
    template_names = [
        "domain_inference_basic",
        "cognitive_analysis",
        "context_analysis",
    ]

    for name in template_names:
        try:
            info = manager.get_template_info(name)
            print(f"\nğŸ” æ¨¡æ¿: {name}")
            print(f"   æè¿°: {info['description']}")
            print(f"   ç±»åˆ«: {info['category']}")
            print(f"   å˜é‡: {info['variables']}")
            print(
                f"   æ¨èè®¾ç½®: T={info['recommended_settings']['temperature']}, "
                f"Max={info['recommended_settings']['max_tokens']}"
            )
            print(f"   ç‰ˆæœ¬: {info['versions']} (æœ€æ–°: {info['latest_version']})")
        except ValueError as e:
            print(f"   âŒ {name}: {e}")


def demonstrate_prompt_rendering():
    """æ¼”ç¤ºæç¤ºè¯æ¸²æŸ“"""
    print("\n" + "=" * 50)
    print("ğŸ¨ æç¤ºè¯æ¸²æŸ“æ¼”ç¤º")
    print("=" * 50)

    # é¢†åŸŸæ¨æ–­ç¤ºä¾‹
    print("\n1ï¸âƒ£ é¢†åŸŸæ¨æ–­æç¤ºè¯æ¸²æŸ“:")
    domain_prompt = render_prompt(
        name="domain_inference_basic",
        variables={
            "domains": "technology, science, education, business, art",
            "query": "å¦‚ä½•ä½¿ç”¨Pythonå¼€å‘æœºå™¨å­¦ä¹ åº”ç”¨ï¼Ÿ",
            "context": {"level": "intermediate", "background": "software_developer"},
        },
    )
    print("æ¸²æŸ“ç»“æœ:")
    print("â”€" * 40)
    print(domain_prompt[:300] + "..." if len(domain_prompt) > 300 else domain_prompt)

    # è®¤çŸ¥åˆ†æç¤ºä¾‹
    print("\n2ï¸âƒ£ è®¤çŸ¥åˆ†ææç¤ºè¯æ¸²æŸ“:")
    cognitive_prompt = render_prompt(
        name="cognitive_analysis",
        variables={
            "domain_context": "æŠ€æœ¯é¢†åŸŸï¼šå¹³è¡¡åˆ†æå„é¡¹è®¤çŸ¥èƒ½åŠ›",
            "current_query": "æˆ‘æƒ³æ·±å…¥å­¦ä¹ ç®—æ³•è®¾è®¡å’Œä¼˜åŒ–",
            "historical_data": "ç”¨æˆ·ä¹‹å‰è¯¢é—®è¿‡åŸºç¡€ç¼–ç¨‹é—®é¢˜",
        },
    )
    print("æ¸²æŸ“ç»“æœ:")
    print("â”€" * 40)
    print(
        cognitive_prompt[:300] + "..."
        if len(cognitive_prompt) > 300
        else cognitive_prompt
    )


def demonstrate_advanced_features():
    """æ¼”ç¤ºé«˜çº§åŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("âš™ï¸ é«˜çº§åŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)

    manager = get_prompt_manager()

    # 1. æ·»åŠ è‡ªå®šä¹‰æ¨¡æ¿
    print("\n1ï¸âƒ£ æ·»åŠ è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿:")
    custom_template = PromptTemplate(
        name="custom_example",
        version="1.0",
        template="è¿™æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰æ¨¡æ¿ç¤ºä¾‹ï¼š{content}\nå‚æ•°ï¼š{param1}, {param2}",
        description="è‡ªå®šä¹‰ç¤ºä¾‹æ¨¡æ¿",
        variables=["content", "param1", "param2"],
        category="examples",
        temperature=0.5,
        max_tokens=200,
    )

    success = manager.add_template(custom_template)
    print(f"   æ·»åŠ ç»“æœ: {'âœ… æˆåŠŸ' if success else 'âŒ å¤±è´¥'}")

    if success:
        # ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿
        custom_rendered = render_prompt(
            name="custom_example",
            variables={"content": "æµ‹è¯•å†…å®¹", "param1": "å‚æ•°1", "param2": "å‚æ•°2"},
        )
        print(f"   æ¸²æŸ“ç»“æœ: {custom_rendered}")

    # 2. ç‰ˆæœ¬ç®¡ç†æ¼”ç¤º
    print("\n2ï¸âƒ£ ç‰ˆæœ¬ç®¡ç†:")
    try:
        # è·å–ç‰¹å®šç‰ˆæœ¬
        template_v1 = get_prompt_template("domain_inference_basic", "1.0")
        print(f"   è·å–v1.0ç‰ˆæœ¬: âœ… {template_v1.name}")

        # è·å–æœ€æ–°ç‰ˆæœ¬ï¼ˆé»˜è®¤ï¼‰
        template_latest = get_prompt_template("domain_inference_basic")
        print(f"   è·å–æœ€æ–°ç‰ˆæœ¬: âœ… {template_latest.name} v{template_latest.version}")

    except ValueError as e:
        print(f"   ç‰ˆæœ¬è·å–å¤±è´¥: âŒ {e}")


def demonstrate_best_practices():
    """æ¼”ç¤ºæœ€ä½³å®è·µ"""
    print("\n" + "=" * 50)
    print("ğŸ’¡ æœ€ä½³å®è·µæ¼”ç¤º")
    print("=" * 50)

    print("\n1ï¸âƒ£ æç¤ºè¯è®¾è®¡åŸåˆ™:")
    print("   â€¢ æ˜ç¡®çš„æŒ‡ä»¤å’ŒæœŸæœ›è¾“å‡ºæ ¼å¼")
    print("   â€¢ åˆç†çš„å˜é‡å ä½ç¬¦è®¾è®¡")
    print("   â€¢ æ°å½“çš„æ¸©åº¦å’Œtokenè®¾ç½®")
    print("   â€¢ æ¸…æ™°çš„ç‰ˆæœ¬ç®¡ç†ç­–ç•¥")

    print("\n2ï¸âƒ£ æ¨¡æ¿ç»„ç»‡å»ºè®®:")
    print("   â€¢ æŒ‰ä¸šåŠ¡åŠŸèƒ½åˆ†ç±» (domain_inference, user_modelingç­‰)")
    print("   â€¢ ä½¿ç”¨è¯­ä¹‰åŒ–çš„ç‰ˆæœ¬å·")
    print("   â€¢ æä¾›è¯¦ç»†çš„æè¿°å’Œä½¿ç”¨è¯´æ˜")
    print("   â€¢ è®°å½•æ¨èçš„æ¨¡å‹å‚æ•°è®¾ç½®")

    print("\n3ï¸âƒ£ å˜æ›´ç®¡ç†æµç¨‹:")
    print("   â€¢ æ–°å¢æ¨¡æ¿æ—¶è¿›è¡Œå……åˆ†æµ‹è¯•")
    print("   â€¢ ç‰ˆæœ¬å‡çº§æ—¶ä¿æŒå‘åå…¼å®¹")
    print("   â€¢ åºŸå¼ƒæ—§ç‰ˆæœ¬æ—¶æä¾›è¿ç§»æŒ‡å—")
    print("   â€¢ ç»´æŠ¤æ¨¡æ¿ä½¿ç”¨æ–‡æ¡£å’Œç¤ºä¾‹")

    print("\n4ï¸âƒ£ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
    print("   â€¢ åˆç†æ§åˆ¶æç¤ºè¯é•¿åº¦")
    print("   â€¢ é¿å…è¿‡åº¦å¤æ‚çš„æ¨¡æ¿åµŒå¥—")
    print("   â€¢ ç¼“å­˜å¸¸ç”¨çš„æ¸²æŸ“ç»“æœ")
    print("   â€¢ ç›‘æ§ä¸åŒæ¨¡æ¿çš„æ•ˆæœå’Œæ€§èƒ½")


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ é›†ä¸­å¼æç¤ºè¯ç®¡ç†ç³»ç»Ÿå®Œæ•´æ¼”ç¤º")
    print("=" * 70)

    # åŸºç¡€åŠŸèƒ½æ¼”ç¤º
    demonstrate_prompt_listing()
    demonstrate_template_info()
    demonstrate_prompt_rendering()

    # é«˜çº§åŠŸèƒ½æ¼”ç¤º
    demonstrate_advanced_features()

    # æœ€ä½³å®è·µ
    demonstrate_best_practices()

    print("\n" + "=" * 70)
    print("âœ¨ æ¼”ç¤ºå®Œæˆ!")
    print("ğŸ’¡ è¿™ä¸ªç³»ç»Ÿæ”¯æŒ:")
    print("   â€¢ é›†ä¸­å¼æç¤ºè¯æ¨¡æ¿ç®¡ç†")
    print("   â€¢ ç‰ˆæœ¬æ§åˆ¶å’Œå‘åå…¼å®¹")
    print("   â€¢ çµæ´»çš„å˜é‡æ›¿æ¢å’Œæ¸²æŸ“")
    print("   â€¢ æŒ‰ç±»åˆ«ç»„ç»‡å’Œæ£€ç´¢æ¨¡æ¿")
    print("   â€¢ æ¨èå‚æ•°è®¾ç½®å’Œå…ƒæ•°æ®")
    print("   â€¢ æ˜“äºæ‰©å±•çš„æ’ä»¶æ¶æ„")
    print("=" * 70)


if __name__ == "__main__":
    main()
