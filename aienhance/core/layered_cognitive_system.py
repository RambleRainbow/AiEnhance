"""
åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿ
å®ç°æ„ŸçŸ¥å±‚ã€è®¤çŸ¥å±‚ã€è¡Œä¸ºå±‚ã€åä½œå±‚çš„ç»Ÿä¸€ç®¡ç†å’Œä¿¡æ¯æµæ§åˆ¶
"""

import asyncio
from datetime import datetime
from typing import Dict, List, Optional, Any, AsyncIterator
import logging

from .layer_interfaces import (
    ICognitiveLayers, SystemResponse, InformationFlow, ProcessingStatus,
    PerceptionInput, CognitionInput, BehaviorInput, CollaborationInput
)
from .perception_layer import PerceptionLayer
from .cognition_layer import CognitionLayer
from .behavior_layer import BehaviorLayer
from .collaboration_layer import CollaborationLayer
from ..memory.interfaces import MemorySystem, MemoryQuery, create_user_context, MemoryType
from ..llm.interfaces import LLMProvider

logger = logging.getLogger(__name__)


class LayeredCognitiveSystem(ICognitiveLayers):
    """åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None,
                 memory_system: Optional[MemorySystem] = None,
                 llm_provider: Optional[LLMProvider] = None):
        """
        åˆå§‹åŒ–åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿ
        
        Args:
            config: ç³»ç»Ÿé…ç½®
            memory_system: è®°å¿†ç³»ç»Ÿ
            llm_provider: å¤§è¯­è¨€æ¨¡å‹æä¾›å•†
        """
        self.config = config or {}
        self.memory_system = memory_system
        self.llm_provider = llm_provider
        
        # æ ¸å¿ƒå±‚å¯¹è±¡
        self.perception_layer: Optional[PerceptionLayer] = None
        self.cognition_layer: Optional[CognitionLayer] = None
        self.behavior_layer: Optional[BehaviorLayer] = None
        self.collaboration_layer: Optional[CollaborationLayer] = None
        
        # ç³»ç»ŸçŠ¶æ€
        self.is_initialized = False
        self.layers_initialized = {}
        
        # ä¿¡æ¯æµè®°å½•
        self.information_flows: List[InformationFlow] = []
        self.max_flow_history = 1000  # æœ€å¤§ä¿¡æ¯æµå†å²è®°å½•æ•°
        
        # æ€§èƒ½ç»Ÿè®¡
        self.processing_statistics = {
            'total_queries': 0,
            'successful_queries': 0,
            'failed_queries': 0,
            'average_processing_time': 0.0,
            'layer_performance': {}
        }
        
    async def initialize_layers(self) -> bool:
        """åˆå§‹åŒ–æ‰€æœ‰å±‚"""
        try:
            logger.info("Initializing Layered Cognitive System...")
            
            # 1. åˆå§‹åŒ–æ„ŸçŸ¥å±‚
            logger.info("Initializing Perception Layer...")
            self.perception_layer = PerceptionLayer(
                config=self.config.get('perception', {}),
                memory_system=self.memory_system
            )
            perception_success = await self.perception_layer.initialize()
            self.layers_initialized['perception'] = perception_success
            
            if perception_success:
                logger.info("âœ… Perception Layer initialized successfully")
            else:
                logger.error("âŒ Perception Layer initialization failed")
                return False
            
            # 2. åˆå§‹åŒ–è®¤çŸ¥å±‚
            logger.info("Initializing Cognition Layer...")
            self.cognition_layer = CognitionLayer(
                config=self.config.get('cognition', {})
            )
            cognition_success = await self.cognition_layer.initialize()
            self.layers_initialized['cognition'] = cognition_success
            
            if cognition_success:
                logger.info("âœ… Cognition Layer initialized successfully")
            else:
                logger.error("âŒ Cognition Layer initialization failed")
                return False
            
            # 3. åˆå§‹åŒ–è¡Œä¸ºå±‚
            logger.info("Initializing Behavior Layer...")
            self.behavior_layer = BehaviorLayer(
                config=self.config.get('behavior', {}),
                llm_provider=self.llm_provider
            )
            behavior_success = await self.behavior_layer.initialize()
            self.layers_initialized['behavior'] = behavior_success
            
            if behavior_success:
                logger.info("âœ… Behavior Layer initialized successfully")
            else:
                logger.error("âŒ Behavior Layer initialization failed")
                return False
            
            # 4. åˆå§‹åŒ–åä½œå±‚ï¼ˆå¯é€‰ï¼‰
            if self.config.get('enable_collaboration', True) and self.llm_provider:
                logger.info("Initializing Collaboration Layer...")
                self.collaboration_layer = CollaborationLayer(
                    config=self.config.get('collaboration', {}),
                    llm_provider=self.llm_provider,
                    memory_system=self.memory_system
                )
                collaboration_success = await self.collaboration_layer.initialize()
                self.layers_initialized['collaboration'] = collaboration_success
                
                if collaboration_success:
                    logger.info("âœ… Collaboration Layer initialized successfully")
                else:
                    logger.warning("âš ï¸ Collaboration Layer initialization failed, continuing without collaboration")
            else:
                logger.info("â­ï¸ Collaboration Layer disabled or LLM not available")
                self.layers_initialized['collaboration'] = False
            
            self.is_initialized = True
            logger.info("ğŸ‰ Layered Cognitive System initialization completed successfully")
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize Layered Cognitive System: {e}")
            self.is_initialized = False
            return False
    
    async def process_through_layers(self, query: str, user_id: str, 
                                   context: Dict[str, Any]) -> SystemResponse:
        """
        é€šè¿‡å„å±‚å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            user_id: ç”¨æˆ·ID
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            SystemResponse: ç³»ç»Ÿå“åº”
        """
        if not self.is_initialized:
            raise RuntimeError("Layered Cognitive System not initialized")
        
        start_time = datetime.now()
        processing_metadata = {
            'query': query,
            'user_id': user_id,
            'timestamp': start_time.isoformat(),
            'processing_steps': [],
            'layer_timings': {},
            'information_flows': []
        }
        
        try:
            logger.info(f"ğŸš€ Starting layered processing for user: {user_id}")
            self.processing_statistics['total_queries'] += 1
            
            # ==================== æ„ŸçŸ¥å±‚å¤„ç† ====================
            layer_start = datetime.now()
            processing_metadata['processing_steps'].append('perception_start')
            
            perception_input = PerceptionInput(
                query=query,
                user_id=user_id,
                context=context,
                historical_data=await self._get_user_historical_data(user_id)
            )
            
            self._record_information_flow('system', 'perception', perception_input, 'input')
            
            perception_output = await self.perception_layer.process(perception_input)
            
            self._record_information_flow('perception', 'system', perception_output, 'output')
            
            layer_end = datetime.now()
            perception_time = (layer_end - layer_start).total_seconds()
            processing_metadata['layer_timings']['perception'] = perception_time
            processing_metadata['processing_steps'].append('perception_complete')
            
            if perception_output.status != ProcessingStatus.COMPLETED:
                raise RuntimeError(f"Perception layer failed: {perception_output.error_message}")
            
            logger.info(f"âœ… Perception layer completed in {perception_time:.3f}s")
            
            # ==================== è®¤çŸ¥å±‚å¤„ç† ====================
            layer_start = datetime.now()
            processing_metadata['processing_steps'].append('cognition_start')
            
            # è·å–å¤–éƒ¨è®°å¿†
            external_memories = await self._retrieve_external_memories(query, user_id, context)
            
            cognition_input = CognitionInput(
                query=query,
                user_profile=perception_output.user_profile,
                context_profile=perception_output.context_profile,
                external_memories=external_memories,
                perception_insights=perception_output.perception_insights
            )
            
            self._record_information_flow('perception', 'cognition', cognition_input, 'input')
            
            cognition_output = await self.cognition_layer.process(cognition_input)
            
            self._record_information_flow('cognition', 'system', cognition_output, 'output')
            
            layer_end = datetime.now()
            cognition_time = (layer_end - layer_start).total_seconds()
            processing_metadata['layer_timings']['cognition'] = cognition_time
            processing_metadata['processing_steps'].append('cognition_complete')
            
            if cognition_output.status != ProcessingStatus.COMPLETED:
                raise RuntimeError(f"Cognition layer failed: {cognition_output.error_message}")
            
            logger.info(f"âœ… Cognition layer completed in {cognition_time:.3f}s")
            
            # ==================== è¡Œä¸ºå±‚å¤„ç† ====================
            layer_start = datetime.now()
            processing_metadata['processing_steps'].append('behavior_start')
            
            behavior_input = BehaviorInput(
                query=query,
                user_profile=perception_output.user_profile,
                context_profile=perception_output.context_profile,
                cognition_output=cognition_output,
                generation_requirements=context.get('generation_requirements', {})
            )
            
            self._record_information_flow('cognition', 'behavior', behavior_input, 'input')
            
            behavior_output = await self.behavior_layer.process(behavior_input)
            
            self._record_information_flow('behavior', 'system', behavior_output, 'output')
            
            layer_end = datetime.now()
            behavior_time = (layer_end - layer_start).total_seconds()
            processing_metadata['layer_timings']['behavior'] = behavior_time
            processing_metadata['processing_steps'].append('behavior_complete')
            
            if behavior_output.status != ProcessingStatus.COMPLETED:
                raise RuntimeError(f"Behavior layer failed: {behavior_output.error_message}")
            
            logger.info(f"âœ… Behavior layer completed in {behavior_time:.3f}s")
            
            # ==================== åä½œå±‚å¤„ç†ï¼ˆå¯é€‰ï¼‰====================
            collaboration_output = None
            if self.collaboration_layer and self.layers_initialized.get('collaboration', False):
                layer_start = datetime.now()
                processing_metadata['processing_steps'].append('collaboration_start')
                
                collaboration_input = CollaborationInput(
                    query=query,
                    user_profile=perception_output.user_profile,
                    context_profile=perception_output.context_profile,
                    behavior_output=behavior_output,
                    collaboration_context=context.get('collaboration_context', {})
                )
                
                self._record_information_flow('behavior', 'collaboration', collaboration_input, 'input')
                
                try:
                    collaboration_output = await self.collaboration_layer.process(collaboration_input)
                    
                    self._record_information_flow('collaboration', 'system', collaboration_output, 'output')
                    
                    layer_end = datetime.now()
                    collaboration_time = (layer_end - layer_start).total_seconds()
                    processing_metadata['layer_timings']['collaboration'] = collaboration_time
                    processing_metadata['processing_steps'].append('collaboration_complete')
                    
                    logger.info(f"âœ… Collaboration layer completed in {collaboration_time:.3f}s")
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ Collaboration layer failed, continuing without collaboration: {e}")
                    processing_metadata['collaboration_error'] = str(e)
                    processing_metadata['processing_steps'].append('collaboration_failed')
            else:
                processing_metadata['processing_steps'].append('collaboration_skipped')
            
            # ==================== åå¤„ç†å’Œè®°å¿†ä¿å­˜ ====================
            processing_metadata['processing_steps'].append('postprocessing_start')
            
            # ä¿å­˜å¤„ç†ç»“æœåˆ°è®°å¿†ç³»ç»Ÿ
            if self.memory_system:
                try:
                    await self._save_processing_results(
                        query, user_id, context, perception_output,
                        cognition_output, behavior_output, collaboration_output
                    )
                    processing_metadata['processing_steps'].append('memory_saved')
                except Exception as e:
                    logger.warning(f"Failed to save processing results: {e}")
                    processing_metadata['memory_save_error'] = str(e)
            
            # æ›´æ–°ç”¨æˆ·ç”»åƒ
            try:
                interaction_data = self._extract_interaction_data(
                    query, behavior_output, processing_metadata
                )
                await self.perception_layer.update_user_profile(user_id, interaction_data)
                processing_metadata['processing_steps'].append('profile_updated')
            except Exception as e:
                logger.warning(f"Failed to update user profile: {e}")
                processing_metadata['profile_update_error'] = str(e)
            
            # è®¡ç®—æ€»å¤„ç†æ—¶é—´
            end_time = datetime.now()
            total_processing_time = (end_time - start_time).total_seconds()
            processing_metadata['total_processing_time'] = total_processing_time
            processing_metadata['processing_steps'].append('completed')
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_processing_statistics(total_processing_time, processing_metadata, True)
            
            # æ„å»ºæœ€ç»ˆå“åº”
            final_content = behavior_output.adapted_content.content
            
            # å¦‚æœåä½œå±‚äº§ç”Ÿäº†å¢å¼ºå†…å®¹ï¼Œä½¿ç”¨å®ƒ
            if (collaboration_output and 
                collaboration_output.enhanced_content and 
                collaboration_output.status == ProcessingStatus.COMPLETED):
                final_content = collaboration_output.enhanced_content
            
            response = SystemResponse(
                content=final_content,
                perception_output=perception_output,
                cognition_output=cognition_output,
                behavior_output=behavior_output,
                collaboration_output=collaboration_output,
                processing_metadata=processing_metadata
            )
            
            logger.info(f"ğŸ‰ Layered processing completed successfully in {total_processing_time:.3f}s")
            self.processing_statistics['successful_queries'] += 1
            
            return response
            
        except Exception as e:
            end_time = datetime.now()
            total_processing_time = (end_time - start_time).total_seconds()
            
            logger.error(f"âŒ Layered processing failed: {e}")
            processing_metadata['error'] = str(e)
            processing_metadata['total_processing_time'] = total_processing_time
            processing_metadata['processing_steps'].append('error')
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self._update_processing_statistics(total_processing_time, processing_metadata, False)
            self.processing_statistics['failed_queries'] += 1
            
            raise RuntimeError(f"Layered processing failed: {e}")
    
    async def process_stream(self, query: str, user_id: str, 
                           context: Dict[str, Any]) -> AsyncIterator[str]:
        """
        æµå¼å¤„ç†ç”¨æˆ·æŸ¥è¯¢
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            user_id: ç”¨æˆ·ID
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Yields:
            str: æµå¼å¤„ç†æ­¥éª¤ä¿¡æ¯æˆ–å†…å®¹
        """
        if not self.is_initialized:
            raise RuntimeError("Layered Cognitive System not initialized")
        
        try:
            yield "ğŸš€ å¼€å§‹åˆ†å±‚è®¤çŸ¥å¤„ç†...\n"
            
            # ==================== æ„ŸçŸ¥å±‚å¤„ç† ====================
            yield "ğŸ§  æ„ŸçŸ¥å±‚ï¼šåˆ†æç”¨æˆ·æŸ¥è¯¢å’Œä¸Šä¸‹æ–‡...\n"
            
            perception_input = PerceptionInput(
                query=query,
                user_id=user_id,
                context=context,
                historical_data=await self._get_user_historical_data(user_id)
            )
            
            perception_output = await self.perception_layer.process(perception_input)
            
            if perception_output.status == ProcessingStatus.COMPLETED:
                yield "âœ… æ„ŸçŸ¥å±‚å¤„ç†å®Œæˆ\n"
            else:
                yield f"âŒ æ„ŸçŸ¥å±‚å¤„ç†å¤±è´¥: {perception_output.error_message}\n"
                return
            
            # ==================== è®¤çŸ¥å±‚å¤„ç† ====================
            yield "ğŸ’¾ è®¤çŸ¥å±‚ï¼šæ¿€æ´»è®°å¿†å’Œæ¨ç†åˆ†æ...\n"
            
            external_memories = await self._retrieve_external_memories(query, user_id, context)
            
            cognition_input = CognitionInput(
                query=query,
                user_profile=perception_output.user_profile,
                context_profile=perception_output.context_profile,
                external_memories=external_memories,
                perception_insights=perception_output.perception_insights
            )
            
            cognition_output = await self.cognition_layer.process(cognition_input)
            
            if cognition_output.status == ProcessingStatus.COMPLETED:
                yield "âœ… è®¤çŸ¥å±‚å¤„ç†å®Œæˆ\n"
            else:
                yield f"âŒ è®¤çŸ¥å±‚å¤„ç†å¤±è´¥: {cognition_output.error_message}\n"
                return
            
            # ==================== è¡Œä¸ºå±‚å¤„ç† ====================
            yield "âš™ï¸ è¡Œä¸ºå±‚ï¼šç”Ÿæˆä¸ªæ€§åŒ–å“åº”...\n"
            
            behavior_input = BehaviorInput(
                query=query,
                user_profile=perception_output.user_profile,
                context_profile=perception_output.context_profile,
                cognition_output=cognition_output,
                generation_requirements=context.get('generation_requirements', {})
            )
            
            # æ£€æŸ¥æ˜¯å¦æ”¯æŒæµå¼ç”Ÿæˆ
            if (self.behavior_layer.llm_initialized and 
                hasattr(self.behavior_layer.llm_provider, 'chat_stream')):
                
                yield "ğŸ¤– å¼€å§‹AIå†…å®¹ç”Ÿæˆ...\n"
                
                # æµå¼ç”Ÿæˆå†…å®¹
                async for chunk in self.behavior_layer.generate_response_stream(behavior_input):
                    yield chunk
                
                yield "\nâœ… è¡Œä¸ºå±‚å¤„ç†å®Œæˆ\n"
            else:
                # éæµå¼å¤„ç†
                behavior_output = await self.behavior_layer.process(behavior_input)
                
                if behavior_output.status == ProcessingStatus.COMPLETED:
                    yield behavior_output.adapted_content.content
                    yield "\nâœ… è¡Œä¸ºå±‚å¤„ç†å®Œæˆ\n"
                else:
                    yield f"âŒ è¡Œä¸ºå±‚å¤„ç†å¤±è´¥: {behavior_output.error_message}\n"
                    return
            
            # ==================== åä½œå±‚å¤„ç†ï¼ˆå¯é€‰ï¼‰====================
            if self.collaboration_layer and self.layers_initialized.get('collaboration', False):
                yield "ğŸ¤ åä½œå±‚ï¼šç”Ÿæˆå¤šå…ƒè§‚ç‚¹å’Œè®¤çŸ¥æŒ‘æˆ˜...\n"
                
                # åä½œå±‚é€šå¸¸ä¸æ”¯æŒæµå¼å¤„ç†ï¼Œå¿«é€Ÿå®Œæˆ
                try:
                    collaboration_input = CollaborationInput(
                        query=query,
                        user_profile=perception_output.user_profile,
                        context_profile=perception_output.context_profile,
                        behavior_output=behavior_output,
                        collaboration_context=context.get('collaboration_context', {})
                    )
                    
                    collaboration_output = await self.collaboration_layer.process(collaboration_input)
                    
                    if collaboration_output.status == ProcessingStatus.COMPLETED:
                        yield "âœ… åä½œå±‚å¤„ç†å®Œæˆ\n"
                        
                        # å¦‚æœæœ‰å¢å¼ºå†…å®¹ï¼Œè¾“å‡ºå·®å¼‚éƒ¨åˆ†
                        if collaboration_output.enhanced_content:
                            original_content = behavior_output.adapted_content.content
                            if collaboration_output.enhanced_content != original_content:
                                # è¾“å‡ºåä½œå¢å¼ºçš„éƒ¨åˆ†
                                enhanced_part = collaboration_output.enhanced_content[len(original_content):]
                                if enhanced_part:
                                    yield enhanced_part
                    else:
                        yield f"âš ï¸ åä½œå±‚å¤„ç†å¤±è´¥ï¼Œç»§ç»­å¤„ç†: {collaboration_output.error_message}\n"
                        
                except Exception as e:
                    yield f"âš ï¸ åä½œå±‚å¤„ç†å¼‚å¸¸ï¼Œç»§ç»­å¤„ç†: {e}\n"
            
            yield "\nğŸ¯ åˆ†å±‚è®¤çŸ¥å¤„ç†å®Œæˆï¼\n"
            
            # å¼‚æ­¥ä¿å­˜ç»“æœï¼ˆä¸é˜»å¡æµå¼è¾“å‡ºï¼‰
            asyncio.create_task(self._async_save_stream_results(
                query, user_id, context, perception_output, cognition_output
            ))
            
        except Exception as e:
            yield f"\nâŒ å¤„ç†å¤±è´¥: {e}\n"
    
    async def _get_user_historical_data(self, user_id: str) -> Optional[List[Any]]:
        """è·å–ç”¨æˆ·å†å²æ•°æ®"""
        try:
            if not self.memory_system:
                return None
            
            user_context = create_user_context(user_id)
            user_memories = await self.memory_system.get_user_memories(user_context, limit=20)
            
            return user_memories.memories
            
        except Exception as e:
            logger.warning(f"Failed to get user historical data: {e}")
            return None
    
    async def _retrieve_external_memories(self, query: str, user_id: str, 
                                        context: Dict[str, Any]) -> List[Any]:
        """æ£€ç´¢å¤–éƒ¨è®°å¿†"""
        try:
            if not self.memory_system:
                return []
            
            user_context = create_user_context(user_id, context.get('session_id'))
            memory_query = MemoryQuery(
                query=query,
                user_context=user_context,
                limit=20,
                similarity_threshold=0.6
            )
            
            memory_result = await self.memory_system.search_memories(memory_query)
            return memory_result.memories
            
        except Exception as e:
            logger.warning(f"Failed to retrieve external memories: {e}")
            return []
    
    def _record_information_flow(self, from_layer: str, to_layer: str, 
                                data: Any, flow_type: str):
        """è®°å½•å±‚é—´ä¿¡æ¯æµ"""
        try:
            flow = InformationFlow(
                from_layer=from_layer,
                to_layer=to_layer,
                data=data,
                flow_type=flow_type,
                timestamp=datetime.now().isoformat()
            )
            
            self.information_flows.append(flow)
            
            # é™åˆ¶ä¿¡æ¯æµå†å²è®°å½•æ•°é‡
            if len(self.information_flows) > self.max_flow_history:
                self.information_flows = self.information_flows[-self.max_flow_history:]
                
        except Exception as e:
            logger.warning(f"Failed to record information flow: {e}")
    
    async def _save_processing_results(self, query: str, user_id: str, context: Dict[str, Any],
                                     perception_output, cognition_output, 
                                     behavior_output, collaboration_output):
        """ä¿å­˜å¤„ç†ç»“æœåˆ°è®°å¿†ç³»ç»Ÿ"""
        try:
            if not self.memory_system:
                return
            
            user_context = create_user_context(user_id, context.get('session_id'))
            
            # ä¿å­˜ç”¨æˆ·æŸ¥è¯¢
            from ..memory.interfaces import create_memory_entry
            
            query_memory = create_memory_entry(
                content=f"ç”¨æˆ·æŸ¥è¯¢: {query}",
                memory_type=MemoryType.EPISODIC,
                user_context=user_context,
                metadata={
                    "type": "user_query",
                    "processing_layers": ["perception", "cognition", "behavior", "collaboration"],
                    "user_profile": perception_output.user_profile.__dict__,
                    "context_profile": perception_output.context_profile.__dict__
                }
            )
            await self.memory_system.add_memory(query_memory)
            
            # ä¿å­˜ç³»ç»Ÿå“åº”
            response_memory = create_memory_entry(
                content=f"ç³»ç»Ÿå“åº”: {behavior_output.adapted_content.content}",
                memory_type=MemoryType.EPISODIC,
                user_context=user_context,
                metadata={
                    "type": "system_response",
                    "adaptation_strategy": behavior_output.adapted_content.adaptation_strategy,
                    "cognitive_load": behavior_output.adapted_content.cognitive_load,
                    "quality_metrics": behavior_output.quality_metrics,
                    "collaboration_enhanced": collaboration_output is not None
                }
            )
            await self.memory_system.add_memory(response_memory)
            
            # ä¿å­˜é‡è¦çš„è®¤çŸ¥æ´å¯Ÿ
            if hasattr(cognition_output, 'cognitive_insights'):
                insights = cognition_output.cognitive_insights
                if insights.get('knowledge_gaps'):
                    for gap in insights['knowledge_gaps'][:3]:
                        gap_memory = create_memory_entry(
                            content=f"çŸ¥è¯†ç¼ºå£: {gap}",
                            memory_type=MemoryType.SEMANTIC,
                            user_context=user_context,
                            metadata={
                                "type": "knowledge_gap",
                                "query": query,
                                "cognitive_load": insights.get('cognitive_load', 0.5)
                            }
                        )
                        await self.memory_system.add_memory(gap_memory)
            
        except Exception as e:
            logger.error(f"Failed to save processing results: {e}")
    
    async def _async_save_stream_results(self, query: str, user_id: str, context: Dict[str, Any],
                                       perception_output, cognition_output):
        """å¼‚æ­¥ä¿å­˜æµå¼å¤„ç†ç»“æœ"""
        try:
            await self._save_processing_results(
                query, user_id, context, perception_output, cognition_output, 
                None, None  # æµå¼å¤„ç†æ—¶å¯èƒ½æ²¡æœ‰å®Œæ•´çš„behaviorå’Œcollaborationè¾“å‡º
            )
        except Exception as e:
            logger.error(f"Failed to save stream results: {e}")
    
    def _extract_interaction_data(self, query: str, behavior_output, 
                                processing_metadata: Dict[str, Any]) -> Dict[str, Any]:
        """æå–äº¤äº’æ•°æ®ç”¨äºæ›´æ–°ç”¨æˆ·ç”»åƒ"""
        return {
            'query': query,
            'response_quality': behavior_output.quality_metrics.get('overall_quality', 0.7),
            'cognitive_load': behavior_output.adapted_content.cognitive_load,
            'processing_time': processing_metadata.get('total_processing_time', 0.0),
            'adaptation_strategy': behavior_output.adapted_content.adaptation_strategy,
            'personalization_level': behavior_output.adapted_content.personalization_level
        }
    
    def _update_processing_statistics(self, processing_time: float, 
                                    metadata: Dict[str, Any], success: bool):
        """æ›´æ–°å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
            total_queries = self.processing_statistics['total_queries']
            current_avg = self.processing_statistics['average_processing_time']
            new_avg = (current_avg * (total_queries - 1) + processing_time) / total_queries
            self.processing_statistics['average_processing_time'] = new_avg
            
            # æ›´æ–°å±‚çº§æ€§èƒ½ç»Ÿè®¡
            layer_timings = metadata.get('layer_timings', {})
            for layer, timing in layer_timings.items():
                if layer not in self.processing_statistics['layer_performance']:
                    self.processing_statistics['layer_performance'][layer] = {
                        'total_time': 0.0,
                        'call_count': 0,
                        'average_time': 0.0
                    }
                
                layer_stats = self.processing_statistics['layer_performance'][layer]
                layer_stats['total_time'] += timing
                layer_stats['call_count'] += 1
                layer_stats['average_time'] = layer_stats['total_time'] / layer_stats['call_count']
                
        except Exception as e:
            logger.warning(f"Failed to update processing statistics: {e}")
    
    def get_layer_status(self, layer_name: str) -> Dict[str, Any]:
        """è·å–æŒ‡å®šå±‚çš„çŠ¶æ€"""
        layer_map = {
            'perception': self.perception_layer,
            'cognition': self.cognition_layer,
            'behavior': self.behavior_layer,
            'collaboration': self.collaboration_layer
        }
        
        layer = layer_map.get(layer_name)
        if layer and hasattr(layer, 'get_status'):
            return layer.get_status()
        else:
            return {
                'layer_name': layer_name,
                'exists': layer is not None,
                'initialized': self.layers_initialized.get(layer_name, False)
            }
    
    def get_information_flows(self) -> List[InformationFlow]:
        """è·å–ä¿¡æ¯æµè®°å½•"""
        return self.information_flows.copy()
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿæ•´ä½“çŠ¶æ€"""
        return {
            'system_initialized': self.is_initialized,
            'layers_initialized': self.layers_initialized.copy(),
            'processing_statistics': self.processing_statistics.copy(),
            'information_flow_count': len(self.information_flows),
            'layer_status': {
                'perception': self.get_layer_status('perception'),
                'cognition': self.get_layer_status('cognition'),
                'behavior': self.get_layer_status('behavior'),
                'collaboration': self.get_layer_status('collaboration')
            },
            'dependencies': {
                'memory_system': self.memory_system is not None,
                'llm_provider': self.llm_provider is not None
            }
        }
    
    async def cleanup_all_layers(self) -> None:
        """æ¸…ç†æ‰€æœ‰å±‚èµ„æº"""
        try:
            logger.info("Cleaning up all layers...")
            
            # æ¸…ç†å„ä¸ªå±‚
            cleanup_tasks = []
            
            if self.perception_layer:
                cleanup_tasks.append(self.perception_layer.cleanup())
            
            if self.cognition_layer:
                cleanup_tasks.append(self.cognition_layer.cleanup())
            
            if self.behavior_layer:
                cleanup_tasks.append(self.behavior_layer.cleanup())
            
            if self.collaboration_layer:
                cleanup_tasks.append(self.collaboration_layer.cleanup())
            
            # å¹¶è¡Œæ¸…ç†
            if cleanup_tasks:
                await asyncio.gather(*cleanup_tasks, return_exceptions=True)
            
            # æ¸…ç†ç³»ç»ŸçŠ¶æ€
            self.information_flows.clear()
            self.is_initialized = False
            self.layers_initialized.clear()
            
            logger.info("All layers cleanup completed")
            
        except Exception as e:
            logger.error(f"Failed to cleanup all layers: {e}")
    
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        if not self.is_initialized:
            await self.initialize_layers()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        await self.cleanup_all_layers()