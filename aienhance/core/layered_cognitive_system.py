"""
ÂàÜÂ±ÇËÆ§Áü•Á≥ªÁªü
ÂÆûÁé∞ÊÑüÁü•Â±Ç„ÄÅËÆ§Áü•Â±Ç„ÄÅË°å‰∏∫Â±Ç„ÄÅÂçè‰ΩúÂ±ÇÁöÑÁªü‰∏ÄÁÆ°ÁêÜÂíå‰ø°ÊÅØÊµÅÊéßÂà∂
"""

import asyncio
import logging
from collections.abc import AsyncIterator
from datetime import datetime
from typing import Any

from ..llm.interfaces import LLMProvider
from ..memory.interfaces import (
    MemoryQuery,
    MemorySystem,
    MemoryType,
    create_user_context,
)
from .behavior_layer import BehaviorLayer
from .cognition_layer import CognitionLayer
from .collaboration_layer import CollaborationLayer
from .layer_interfaces import (
    BehaviorInput,
    CognitionInput,
    CollaborationInput,
    ICognitiveLayers,
    InformationFlow,
    PerceptionInput,
    ProcessingStatus,
    SystemResponse,
)
from .perception_layer import PerceptionLayer

logger = logging.getLogger(__name__)


class LayeredCognitiveSystem(ICognitiveLayers):
    """ÂàÜÂ±ÇËÆ§Áü•Á≥ªÁªü‰∏ªÁ±ª"""

    def __init__(self, config: dict[str, Any] | None = None,
                 memory_system: MemorySystem | None = None,
                 llm_provider: LLMProvider | None = None):
        """
        ÂàùÂßãÂåñÂàÜÂ±ÇËÆ§Áü•Á≥ªÁªü
        
        Args:
            config: Á≥ªÁªüÈÖçÁΩÆ
            memory_system: ËÆ∞ÂøÜÁ≥ªÁªü
            llm_provider: Â§ßËØ≠Ë®ÄÊ®°ÂûãÊèê‰æõÂïÜ
        """
        self.config = config or {}
        self.memory_system = memory_system
        self.llm_provider = llm_provider

        # Ê†∏ÂøÉÂ±ÇÂØπË±°
        self.perception_layer: PerceptionLayer | None = None
        self.cognition_layer: CognitionLayer | None = None
        self.behavior_layer: BehaviorLayer | None = None
        self.collaboration_layer: CollaborationLayer | None = None

        # Á≥ªÁªüÁä∂ÊÄÅ
        self.is_initialized = False
        self.layers_initialized = {}

        # ‰ø°ÊÅØÊµÅËÆ∞ÂΩï
        self.information_flows: list[InformationFlow] = []
        self.max_flow_history = 1000  # ÊúÄÂ§ß‰ø°ÊÅØÊµÅÂéÜÂè≤ËÆ∞ÂΩïÊï∞

        # ÊÄßËÉΩÁªüËÆ°
        self.processing_statistics = {
            'total_queries': 0,
            'successful_queries': 0,
            'failed_queries': 0,
            'average_processing_time': 0.0,
            'layer_performance': {}
        }

    async def initialize_layers(self) -> bool:
        """ÂàùÂßãÂåñÊâÄÊúâÂ±Ç"""
        try:
            logger.info("Initializing Layered Cognitive System...")

            # 0. ÂàùÂßãÂåñËÆ∞ÂøÜÁ≥ªÁªüÔºàÂ¶ÇÊûúÂ≠òÂú®Ôºâ
            if self.memory_system:
                logger.info("Initializing Memory System...")
                memory_success = await self.memory_system.initialize()
                if memory_success:
                    logger.info("‚úÖ Memory System initialized successfully")
                else:
                    logger.warning("‚ö†Ô∏è Memory System initialization failed, continuing without memory")
                    self.memory_system = None

            # 1. ÂàùÂßãÂåñÊÑüÁü•Â±Ç
            logger.info("Initializing Perception Layer...")
            self.perception_layer = PerceptionLayer(
                config=self.config.get('perception', {}),
                memory_system=self.memory_system
            )
            perception_success = await self.perception_layer.initialize()
            self.layers_initialized['perception'] = perception_success

            if perception_success:
                logger.info("‚úÖ Perception Layer initialized successfully")
            else:
                logger.error("‚ùå Perception Layer initialization failed")
                return False

            # 2. ÂàùÂßãÂåñËÆ§Áü•Â±Ç
            logger.info("Initializing Cognition Layer...")
            self.cognition_layer = CognitionLayer(
                config=self.config.get('cognition', {})
            )
            cognition_success = await self.cognition_layer.initialize()
            self.layers_initialized['cognition'] = cognition_success

            if cognition_success:
                logger.info("‚úÖ Cognition Layer initialized successfully")
            else:
                logger.error("‚ùå Cognition Layer initialization failed")
                return False

            # 3. ÂàùÂßãÂåñË°å‰∏∫Â±Ç
            logger.info("Initializing Behavior Layer...")
            self.behavior_layer = BehaviorLayer(
                config=self.config.get('behavior', {}),
                llm_provider=self.llm_provider
            )
            behavior_success = await self.behavior_layer.initialize()
            self.layers_initialized['behavior'] = behavior_success

            if behavior_success:
                logger.info("‚úÖ Behavior Layer initialized successfully")
            else:
                logger.error("‚ùå Behavior Layer initialization failed")
                return False

            # 4. ÂàùÂßãÂåñÂçè‰ΩúÂ±ÇÔºàÂèØÈÄâÔºâ
            if self.config.get('enable_collaboration', True) and self.llm_provider:
                logger.info("Initializing Collaboration Layer...")
                self.collaboration_layer = CollaborationLayer(
                    config=self.config.get('collaboration', {}),
                    llm_provider=self.llm_provider,
                    memory_system=self.memory_system
                )
                collaboration_success = await self.collaboration_layer.initialize()
                self.layers_initialized['collaboration'] = collaboration_success

                if collaboration_success:
                    logger.info("‚úÖ Collaboration Layer initialized successfully")
                else:
                    logger.warning("‚ö†Ô∏è Collaboration Layer initialization failed, continuing without collaboration")
            else:
                logger.info("‚è≠Ô∏è Collaboration Layer disabled or LLM not available")
                self.layers_initialized['collaboration'] = False

            self.is_initialized = True
            logger.info("üéâ Layered Cognitive System initialization completed successfully")
            return True

        except Exception as e:
            logger.error(f"Failed to initialize Layered Cognitive System: {e}")
            self.is_initialized = False
            return False

    async def process_through_layers(self, query: str, user_id: str,
                                   context: dict[str, Any]) -> SystemResponse:
        """
        ÈÄöËøáÂêÑÂ±ÇÂ§ÑÁêÜÁî®Êà∑Êü•ËØ¢
        
        Args:
            query: Áî®Êà∑Êü•ËØ¢
            user_id: Áî®Êà∑ID
            context: ‰∏ä‰∏ãÊñá‰ø°ÊÅØ
            
        Returns:
            SystemResponse: Á≥ªÁªüÂìçÂ∫î
        """
        if not self.is_initialized:
            raise RuntimeError("Layered Cognitive System not initialized")

        start_time = datetime.now()
        processing_metadata = {
            'query': query,
            'user_id': user_id,
            'timestamp': start_time.isoformat(),
            'processing_steps': [],
            'layer_timings': {},
            'information_flows': []
        }

        try:
            logger.info(f"üöÄ Starting layered processing for user: {user_id}")
            self.processing_statistics['total_queries'] += 1

            # ==================== ÊÑüÁü•Â±ÇÂ§ÑÁêÜ ====================
            layer_start = datetime.now()
            processing_metadata['processing_steps'].append('perception_start')

            perception_input = PerceptionInput(
                query=query,
                user_id=user_id,
                context=context,
                historical_data=await self._get_user_historical_data(user_id)
            )

            self._record_information_flow('system', 'perception', perception_input, 'input')

            perception_output = await self.perception_layer.process(perception_input)

            self._record_information_flow('perception', 'system', perception_output, 'output')

            layer_end = datetime.now()
            perception_time = (layer_end - layer_start).total_seconds()
            processing_metadata['layer_timings']['perception'] = perception_time
            processing_metadata['processing_steps'].append('perception_complete')

            if perception_output.status != ProcessingStatus.COMPLETED:
                raise RuntimeError(f"Perception layer failed: {perception_output.error_message}")

            logger.info(f"‚úÖ Perception layer completed in {perception_time:.3f}s")

            # ==================== ËÆ§Áü•Â±ÇÂ§ÑÁêÜ ====================
            layer_start = datetime.now()
            processing_metadata['processing_steps'].append('cognition_start')

            # Ëé∑ÂèñÂ§ñÈÉ®ËÆ∞ÂøÜ
            external_memories = await self._retrieve_external_memories(query, user_id, context)

            cognition_input = CognitionInput(
                query=query,
                user_profile=perception_output.user_profile,
                context_profile=perception_output.context_profile,
                external_memories=external_memories,
                perception_insights=perception_output.perception_insights
            )

            self._record_information_flow('perception', 'cognition', cognition_input, 'input')

            cognition_output = await self.cognition_layer.process(cognition_input)

            self._record_information_flow('cognition', 'system', cognition_output, 'output')

            layer_end = datetime.now()
            cognition_time = (layer_end - layer_start).total_seconds()
            processing_metadata['layer_timings']['cognition'] = cognition_time
            processing_metadata['processing_steps'].append('cognition_complete')

            if cognition_output.status != ProcessingStatus.COMPLETED:
                raise RuntimeError(f"Cognition layer failed: {cognition_output.error_message}")

            logger.info(f"‚úÖ Cognition layer completed in {cognition_time:.3f}s")

            # ==================== Ë°å‰∏∫Â±ÇÂ§ÑÁêÜ ====================
            layer_start = datetime.now()
            processing_metadata['processing_steps'].append('behavior_start')

            behavior_input = BehaviorInput(
                query=query,
                user_profile=perception_output.user_profile,
                context_profile=perception_output.context_profile,
                cognition_output=cognition_output,
                generation_requirements=context.get('generation_requirements', {})
            )

            self._record_information_flow('cognition', 'behavior', behavior_input, 'input')

            behavior_output = await self.behavior_layer.process(behavior_input)

            self._record_information_flow('behavior', 'system', behavior_output, 'output')

            layer_end = datetime.now()
            behavior_time = (layer_end - layer_start).total_seconds()
            processing_metadata['layer_timings']['behavior'] = behavior_time
            processing_metadata['processing_steps'].append('behavior_complete')

            if behavior_output.status != ProcessingStatus.COMPLETED:
                raise RuntimeError(f"Behavior layer failed: {behavior_output.error_message}")

            logger.info(f"‚úÖ Behavior layer completed in {behavior_time:.3f}s")

            # ==================== Âçè‰ΩúÂ±ÇÂ§ÑÁêÜÔºàÂèØÈÄâÔºâ====================
            collaboration_output = None
            if self.collaboration_layer and self.layers_initialized.get('collaboration', False):
                layer_start = datetime.now()
                processing_metadata['processing_steps'].append('collaboration_start')

                collaboration_input = CollaborationInput(
                    query=query,
                    user_profile=perception_output.user_profile,
                    context_profile=perception_output.context_profile,
                    behavior_output=behavior_output,
                    collaboration_context=context.get('collaboration_context', {})
                )

                self._record_information_flow('behavior', 'collaboration', collaboration_input, 'input')

                try:
                    collaboration_output = await self.collaboration_layer.process(collaboration_input)

                    self._record_information_flow('collaboration', 'system', collaboration_output, 'output')

                    layer_end = datetime.now()
                    collaboration_time = (layer_end - layer_start).total_seconds()
                    processing_metadata['layer_timings']['collaboration'] = collaboration_time
                    processing_metadata['processing_steps'].append('collaboration_complete')

                    logger.info(f"‚úÖ Collaboration layer completed in {collaboration_time:.3f}s")

                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Collaboration layer failed, continuing without collaboration: {e}")
                    processing_metadata['collaboration_error'] = str(e)
                    processing_metadata['processing_steps'].append('collaboration_failed')
            else:
                processing_metadata['processing_steps'].append('collaboration_skipped')

            # ==================== ÂêéÂ§ÑÁêÜÂíåËÆ∞ÂøÜ‰øùÂ≠ò ====================
            processing_metadata['processing_steps'].append('postprocessing_start')

            # ‰øùÂ≠òÂ§ÑÁêÜÁªìÊûúÂà∞ËÆ∞ÂøÜÁ≥ªÁªü
            if self.memory_system:
                try:
                    await self._save_processing_results(
                        query, user_id, context, perception_output,
                        cognition_output, behavior_output, collaboration_output
                    )
                    processing_metadata['processing_steps'].append('memory_saved')
                except Exception as e:
                    logger.warning(f"Failed to save processing results: {e}")
                    processing_metadata['memory_save_error'] = str(e)

            # Êõ¥Êñ∞Áî®Êà∑ÁîªÂÉè
            try:
                interaction_data = self._extract_interaction_data(
                    query, behavior_output, processing_metadata
                )
                await self.perception_layer.update_user_profile(user_id, interaction_data)
                processing_metadata['processing_steps'].append('profile_updated')
            except Exception as e:
                logger.warning(f"Failed to update user profile: {e}")
                processing_metadata['profile_update_error'] = str(e)

            # ËÆ°ÁÆóÊÄªÂ§ÑÁêÜÊó∂Èó¥
            end_time = datetime.now()
            total_processing_time = (end_time - start_time).total_seconds()
            processing_metadata['total_processing_time'] = total_processing_time
            processing_metadata['processing_steps'].append('completed')

            # Êõ¥Êñ∞ÁªüËÆ°‰ø°ÊÅØ
            self._update_processing_statistics(total_processing_time, processing_metadata, True)

            # ÊûÑÂª∫ÊúÄÁªàÂìçÂ∫î
            final_content = behavior_output.adapted_content.content

            # Â¶ÇÊûúÂçè‰ΩúÂ±Ç‰∫ßÁîü‰∫ÜÂ¢ûÂº∫ÂÜÖÂÆπÔºå‰ΩøÁî®ÂÆÉ
            if (collaboration_output and
                collaboration_output.enhanced_content and
                collaboration_output.status == ProcessingStatus.COMPLETED):
                final_content = collaboration_output.enhanced_content

            response = SystemResponse(
                content=final_content,
                perception_output=perception_output,
                cognition_output=cognition_output,
                behavior_output=behavior_output,
                collaboration_output=collaboration_output,
                processing_metadata=processing_metadata
            )

            logger.info(f"üéâ Layered processing completed successfully in {total_processing_time:.3f}s")
            self.processing_statistics['successful_queries'] += 1

            return response

        except Exception as e:
            end_time = datetime.now()
            total_processing_time = (end_time - start_time).total_seconds()

            logger.error(f"‚ùå Layered processing failed: {e}")
            processing_metadata['error'] = str(e)
            processing_metadata['total_processing_time'] = total_processing_time
            processing_metadata['processing_steps'].append('error')

            # Êõ¥Êñ∞ÁªüËÆ°‰ø°ÊÅØ
            self._update_processing_statistics(total_processing_time, processing_metadata, False)
            self.processing_statistics['failed_queries'] += 1

            raise RuntimeError(f"Layered processing failed: {e}")

    async def process_stream(self, query: str, user_id: str,
                           context: dict[str, Any]) -> AsyncIterator[str]:
        """
        ÊµÅÂºèÂ§ÑÁêÜÁî®Êà∑Êü•ËØ¢
        
        Args:
            query: Áî®Êà∑Êü•ËØ¢
            user_id: Áî®Êà∑ID
            context: ‰∏ä‰∏ãÊñá‰ø°ÊÅØ
            
        Yields:
            str: ÊµÅÂºèÂ§ÑÁêÜÊ≠•È™§‰ø°ÊÅØÊàñÂÜÖÂÆπ
        """
        if not self.is_initialized:
            raise RuntimeError("Layered Cognitive System not initialized")

        try:
            yield "üöÄ ÂºÄÂßãÂàÜÂ±ÇËÆ§Áü•Â§ÑÁêÜ...\n"

            # ==================== ÊÑüÁü•Â±ÇÂ§ÑÁêÜ ====================
            yield "üß† ÊÑüÁü•Â±ÇÔºöÂàÜÊûêÁî®Êà∑Êü•ËØ¢Âíå‰∏ä‰∏ãÊñá...\n"

            perception_input = PerceptionInput(
                query=query,
                user_id=user_id,
                context=context,
                historical_data=await self._get_user_historical_data(user_id)
            )

            perception_output = await self.perception_layer.process(perception_input)

            if perception_output.status == ProcessingStatus.COMPLETED:
                yield "‚úÖ ÊÑüÁü•Â±ÇÂ§ÑÁêÜÂÆåÊàê\n"
            else:
                yield f"‚ùå ÊÑüÁü•Â±ÇÂ§ÑÁêÜÂ§±Ë¥•: {perception_output.error_message}\n"
                return

            # ==================== ËÆ§Áü•Â±ÇÂ§ÑÁêÜ ====================
            yield "üíæ ËÆ§Áü•Â±ÇÔºöÊøÄÊ¥ªËÆ∞ÂøÜÂíåÊé®ÁêÜÂàÜÊûê...\n"

            external_memories = await self._retrieve_external_memories(query, user_id, context)

            cognition_input = CognitionInput(
                query=query,
                user_profile=perception_output.user_profile,
                context_profile=perception_output.context_profile,
                external_memories=external_memories,
                perception_insights=perception_output.perception_insights
            )

            cognition_output = await self.cognition_layer.process(cognition_input)

            if cognition_output.status == ProcessingStatus.COMPLETED:
                yield "‚úÖ ËÆ§Áü•Â±ÇÂ§ÑÁêÜÂÆåÊàê\n"
            else:
                yield f"‚ùå ËÆ§Áü•Â±ÇÂ§ÑÁêÜÂ§±Ë¥•: {cognition_output.error_message}\n"
                return

            # ==================== Ë°å‰∏∫Â±ÇÂ§ÑÁêÜ ====================
            yield "‚öôÔ∏è Ë°å‰∏∫Â±ÇÔºöÁîüÊàê‰∏™ÊÄßÂåñÂìçÂ∫î...\n"

            behavior_input = BehaviorInput(
                query=query,
                user_profile=perception_output.user_profile,
                context_profile=perception_output.context_profile,
                cognition_output=cognition_output,
                generation_requirements=context.get('generation_requirements', {})
            )

            # Ê£ÄÊü•ÊòØÂê¶ÊîØÊåÅÊµÅÂºèÁîüÊàê
            if (self.behavior_layer.llm_initialized and
                hasattr(self.behavior_layer.llm_provider, 'chat_stream')):

                yield "ü§ñ ÂºÄÂßãAIÂÜÖÂÆπÁîüÊàê...\n"

                # ÊµÅÂºèÁîüÊàêÂÜÖÂÆπ
                async for chunk in self.behavior_layer.generate_response_stream(behavior_input):
                    yield chunk

                yield "\n‚úÖ Ë°å‰∏∫Â±ÇÂ§ÑÁêÜÂÆåÊàê\n"
            else:
                # ÈùûÊµÅÂºèÂ§ÑÁêÜ
                behavior_output = await self.behavior_layer.process(behavior_input)

                if behavior_output.status == ProcessingStatus.COMPLETED:
                    yield behavior_output.adapted_content.content
                    yield "\n‚úÖ Ë°å‰∏∫Â±ÇÂ§ÑÁêÜÂÆåÊàê\n"
                else:
                    yield f"‚ùå Ë°å‰∏∫Â±ÇÂ§ÑÁêÜÂ§±Ë¥•: {behavior_output.error_message}\n"
                    return

            # ==================== Âçè‰ΩúÂ±ÇÂ§ÑÁêÜÔºàÂèØÈÄâÔºâ====================
            if self.collaboration_layer and self.layers_initialized.get('collaboration', False):
                yield "ü§ù Âçè‰ΩúÂ±ÇÔºöÁîüÊàêÂ§öÂÖÉËßÇÁÇπÂíåËÆ§Áü•ÊåëÊàò...\n"

                # Âçè‰ΩúÂ±ÇÈÄöÂ∏∏‰∏çÊîØÊåÅÊµÅÂºèÂ§ÑÁêÜÔºåÂø´ÈÄüÂÆåÊàê
                try:
                    collaboration_input = CollaborationInput(
                        query=query,
                        user_profile=perception_output.user_profile,
                        context_profile=perception_output.context_profile,
                        behavior_output=behavior_output,
                        collaboration_context=context.get('collaboration_context', {})
                    )

                    collaboration_output = await self.collaboration_layer.process(collaboration_input)

                    if collaboration_output.status == ProcessingStatus.COMPLETED:
                        yield "‚úÖ Âçè‰ΩúÂ±ÇÂ§ÑÁêÜÂÆåÊàê\n"

                        # Â¶ÇÊûúÊúâÂ¢ûÂº∫ÂÜÖÂÆπÔºåËæìÂá∫Â∑ÆÂºÇÈÉ®ÂàÜ
                        if collaboration_output.enhanced_content:
                            original_content = behavior_output.adapted_content.content
                            if collaboration_output.enhanced_content != original_content:
                                # ËæìÂá∫Âçè‰ΩúÂ¢ûÂº∫ÁöÑÈÉ®ÂàÜ
                                enhanced_part = collaboration_output.enhanced_content[len(original_content):]
                                if enhanced_part:
                                    yield enhanced_part
                    else:
                        yield f"‚ö†Ô∏è Âçè‰ΩúÂ±ÇÂ§ÑÁêÜÂ§±Ë¥•ÔºåÁªßÁª≠Â§ÑÁêÜ: {collaboration_output.error_message}\n"

                except Exception as e:
                    yield f"‚ö†Ô∏è Âçè‰ΩúÂ±ÇÂ§ÑÁêÜÂºÇÂ∏∏ÔºåÁªßÁª≠Â§ÑÁêÜ: {e}\n"

            yield "\nüéØ ÂàÜÂ±ÇËÆ§Áü•Â§ÑÁêÜÂÆåÊàêÔºÅ\n"

            # ÂºÇÊ≠•‰øùÂ≠òÁªìÊûúÔºà‰∏çÈòªÂ°ûÊµÅÂºèËæìÂá∫Ôºâ
            asyncio.create_task(self._async_save_stream_results(
                query, user_id, context, perception_output, cognition_output
            ))

        except Exception as e:
            yield f"\n‚ùå Â§ÑÁêÜÂ§±Ë¥•: {e}\n"

    async def _get_user_historical_data(self, user_id: str) -> list[Any] | None:
        """Ëé∑ÂèñÁî®Êà∑ÂéÜÂè≤Êï∞ÊçÆ"""
        try:
            if not self.memory_system:
                return None

            user_context = create_user_context(user_id)
            user_memories = await self.memory_system.get_user_memories(user_context, limit=20)

            return user_memories.memories

        except Exception as e:
            logger.warning(f"Failed to get user historical data: {e}")
            return None

    async def _retrieve_external_memories(self, query: str, user_id: str,
                                        context: dict[str, Any]) -> list[Any]:
        """Ê£ÄÁ¥¢Â§ñÈÉ®ËÆ∞ÂøÜ"""
        try:
            if not self.memory_system:
                return []

            user_context = create_user_context(user_id, context.get('session_id'))
            memory_query = MemoryQuery(
                query=query,
                user_context=user_context,
                limit=20,
                similarity_threshold=0.6
            )

            memory_result = await self.memory_system.search_memories(memory_query)
            return memory_result.memories

        except Exception as e:
            logger.warning(f"Failed to retrieve external memories: {e}")
            return []

    def _record_information_flow(self, from_layer: str, to_layer: str,
                                data: Any, flow_type: str):
        """ËÆ∞ÂΩïÂ±ÇÈó¥‰ø°ÊÅØÊµÅ"""
        try:
            flow = InformationFlow(
                from_layer=from_layer,
                to_layer=to_layer,
                data=data,
                flow_type=flow_type,
                timestamp=datetime.now().isoformat()
            )

            self.information_flows.append(flow)

            # ÈôêÂà∂‰ø°ÊÅØÊµÅÂéÜÂè≤ËÆ∞ÂΩïÊï∞Èáè
            if len(self.information_flows) > self.max_flow_history:
                self.information_flows = self.information_flows[-self.max_flow_history:]

        except Exception as e:
            logger.warning(f"Failed to record information flow: {e}")

    async def _save_processing_results(self, query: str, user_id: str, context: dict[str, Any],
                                     perception_output, cognition_output,
                                     behavior_output, collaboration_output):
        """‰øùÂ≠òÂ§ÑÁêÜÁªìÊûúÂà∞ËÆ∞ÂøÜÁ≥ªÁªü"""
        try:
            if not self.memory_system:
                return

            user_context = create_user_context(user_id, context.get('session_id'))

            # ‰øùÂ≠òÁî®Êà∑Êü•ËØ¢
            from ..memory.interfaces import create_memory_entry

            query_memory = create_memory_entry(
                content=f"Áî®Êà∑Êü•ËØ¢: {query}",
                memory_type=MemoryType.EPISODIC,
                user_context=user_context,
                metadata={
                    "type": "user_query",
                    "processing_layers": ["perception", "cognition", "behavior", "collaboration"],
                    "user_profile": perception_output.user_profile.__dict__,
                    "context_profile": perception_output.context_profile.__dict__
                }
            )
            await self.memory_system.add_memory(query_memory)

            # ‰øùÂ≠òÁ≥ªÁªüÂìçÂ∫î
            response_memory = create_memory_entry(
                content=f"Á≥ªÁªüÂìçÂ∫î: {behavior_output.adapted_content.content}",
                memory_type=MemoryType.EPISODIC,
                user_context=user_context,
                metadata={
                    "type": "system_response",
                    "adaptation_strategy": behavior_output.adapted_content.adaptation_strategy,
                    "cognitive_load": behavior_output.adapted_content.cognitive_load,
                    "quality_metrics": behavior_output.quality_metrics,
                    "collaboration_enhanced": collaboration_output is not None
                }
            )
            await self.memory_system.add_memory(response_memory)

            # ‰øùÂ≠òÈáçË¶ÅÁöÑËÆ§Áü•Ê¥ûÂØü
            if hasattr(cognition_output, 'cognitive_insights'):
                insights = cognition_output.cognitive_insights
                if insights.get('knowledge_gaps'):
                    for gap in insights['knowledge_gaps'][:3]:
                        gap_memory = create_memory_entry(
                            content=f"Áü•ËØÜÁº∫Âè£: {gap}",
                            memory_type=MemoryType.SEMANTIC,
                            user_context=user_context,
                            metadata={
                                "type": "knowledge_gap",
                                "query": query,
                                "cognitive_load": insights.get('cognitive_load', 0.5)
                            }
                        )
                        await self.memory_system.add_memory(gap_memory)

        except Exception as e:
            logger.error(f"Failed to save processing results: {e}")

    async def _async_save_stream_results(self, query: str, user_id: str, context: dict[str, Any],
                                       perception_output, cognition_output):
        """ÂºÇÊ≠•‰øùÂ≠òÊµÅÂºèÂ§ÑÁêÜÁªìÊûú"""
        try:
            await self._save_processing_results(
                query, user_id, context, perception_output, cognition_output,
                None, None  # ÊµÅÂºèÂ§ÑÁêÜÊó∂ÂèØËÉΩÊ≤°ÊúâÂÆåÊï¥ÁöÑbehaviorÂíåcollaborationËæìÂá∫
            )
        except Exception as e:
            logger.error(f"Failed to save stream results: {e}")

    def _extract_interaction_data(self, query: str, behavior_output,
                                processing_metadata: dict[str, Any]) -> dict[str, Any]:
        """ÊèêÂèñ‰∫§‰∫íÊï∞ÊçÆÁî®‰∫éÊõ¥Êñ∞Áî®Êà∑ÁîªÂÉè"""
        return {
            'query': query,
            'response_quality': behavior_output.quality_metrics.get('overall_quality', 0.7),
            'cognitive_load': behavior_output.adapted_content.cognitive_load,
            'processing_time': processing_metadata.get('total_processing_time', 0.0),
            'adaptation_strategy': behavior_output.adapted_content.adaptation_strategy,
            'personalization_level': behavior_output.adapted_content.personalization_level
        }

    def _update_processing_statistics(self, processing_time: float,
                                    metadata: dict[str, Any], success: bool):
        """Êõ¥Êñ∞Â§ÑÁêÜÁªüËÆ°‰ø°ÊÅØ"""
        try:
            # Êõ¥Êñ∞Âπ≥ÂùáÂ§ÑÁêÜÊó∂Èó¥
            total_queries = self.processing_statistics['total_queries']
            current_avg = self.processing_statistics['average_processing_time']
            new_avg = (current_avg * (total_queries - 1) + processing_time) / total_queries
            self.processing_statistics['average_processing_time'] = new_avg

            # Êõ¥Êñ∞Â±ÇÁ∫ßÊÄßËÉΩÁªüËÆ°
            layer_timings = metadata.get('layer_timings', {})
            for layer, timing in layer_timings.items():
                if layer not in self.processing_statistics['layer_performance']:
                    self.processing_statistics['layer_performance'][layer] = {
                        'total_time': 0.0,
                        'call_count': 0,
                        'average_time': 0.0
                    }

                layer_stats = self.processing_statistics['layer_performance'][layer]
                layer_stats['total_time'] += timing
                layer_stats['call_count'] += 1
                layer_stats['average_time'] = layer_stats['total_time'] / layer_stats['call_count']

        except Exception as e:
            logger.warning(f"Failed to update processing statistics: {e}")

    def get_layer_status(self, layer_name: str) -> dict[str, Any]:
        """Ëé∑ÂèñÊåáÂÆöÂ±ÇÁöÑÁä∂ÊÄÅ"""
        layer_map = {
            'perception': self.perception_layer,
            'cognition': self.cognition_layer,
            'behavior': self.behavior_layer,
            'collaboration': self.collaboration_layer
        }

        layer = layer_map.get(layer_name)
        if layer and hasattr(layer, 'get_status'):
            return layer.get_status()
        else:
            return {
                'layer_name': layer_name,
                'exists': layer is not None,
                'initialized': self.layers_initialized.get(layer_name, False)
            }

    def get_information_flows(self) -> list[InformationFlow]:
        """Ëé∑Âèñ‰ø°ÊÅØÊµÅËÆ∞ÂΩï"""
        return self.information_flows.copy()

    def get_system_status(self) -> dict[str, Any]:
        """Ëé∑ÂèñÁ≥ªÁªüÊï¥‰ΩìÁä∂ÊÄÅ"""
        return {
            'system_initialized': self.is_initialized,
            'layers_initialized': self.layers_initialized.copy(),
            'processing_statistics': self.processing_statistics.copy(),
            'information_flow_count': len(self.information_flows),
            'layer_status': {
                'perception': self.get_layer_status('perception'),
                'cognition': self.get_layer_status('cognition'),
                'behavior': self.get_layer_status('behavior'),
                'collaboration': self.get_layer_status('collaboration')
            },
            'dependencies': {
                'memory_system': self.memory_system is not None,
                'llm_provider': self.llm_provider is not None
            }
        }

    async def cleanup_all_layers(self) -> None:
        """Ê∏ÖÁêÜÊâÄÊúâÂ±ÇËµÑÊ∫ê"""
        try:
            logger.info("Cleaning up all layers...")

            # Ê∏ÖÁêÜÂêÑ‰∏™Â±Ç
            cleanup_tasks = []

            if self.perception_layer:
                cleanup_tasks.append(self.perception_layer.cleanup())

            if self.cognition_layer:
                cleanup_tasks.append(self.cognition_layer.cleanup())

            if self.behavior_layer:
                cleanup_tasks.append(self.behavior_layer.cleanup())

            if self.collaboration_layer:
                cleanup_tasks.append(self.collaboration_layer.cleanup())

            # Âπ∂Ë°åÊ∏ÖÁêÜ
            if cleanup_tasks:
                await asyncio.gather(*cleanup_tasks, return_exceptions=True)

            # Ê∏ÖÁêÜÁ≥ªÁªüÁä∂ÊÄÅ
            self.information_flows.clear()
            self.is_initialized = False
            self.layers_initialized.clear()

            logger.info("All layers cleanup completed")

        except Exception as e:
            logger.error(f"Failed to cleanup all layers: {e}")

    async def __aenter__(self):
        """ÂºÇÊ≠•‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂô®ÂÖ•Âè£"""
        if not self.is_initialized:
            await self.initialize_layers()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ÂºÇÊ≠•‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂô®Âá∫Âè£"""
        await self.cleanup_all_layers()

    def get_system_info(self) -> dict[str, Any]:
        """Ëé∑ÂèñÁ≥ªÁªü‰ø°ÊÅØ"""
        info = {
            "system_type": "layered_cognitive",
            "config": self.config,
            "initialized": self.is_initialized,
            "layers": {
                "perception": {
                    "initialized": self.layers_initialized.get('perception', False),
                    "class": self.perception_layer.__class__.__name__ if self.perception_layer else None
                },
                "cognition": {
                    "initialized": self.layers_initialized.get('cognition', False),
                    "class": self.cognition_layer.__class__.__name__ if self.cognition_layer else None
                },
                "behavior": {
                    "initialized": self.layers_initialized.get('behavior', False),
                    "class": self.behavior_layer.__class__.__name__ if self.behavior_layer else None
                },
                "collaboration": {
                    "initialized": self.layers_initialized.get('collaboration', False),
                    "class": self.collaboration_layer.__class__.__name__ if self.collaboration_layer else None
                }
            },
            "components": {
                "memory_system": {
                    "available": self.memory_system is not None,
                    "type": self.memory_system.__class__.__name__ if self.memory_system else None,
                    "initialized": getattr(self.memory_system, 'is_initialized', False) if self.memory_system else False
                },
                "llm_provider": {
                    "available": self.llm_provider is not None,
                    "type": self.llm_provider.__class__.__name__ if self.llm_provider else None,
                    "provider": getattr(getattr(self.llm_provider, 'config', None), 'provider', None) if self.llm_provider else None,
                    "model": getattr(getattr(self.llm_provider, 'config', None), 'model_name', None) if self.llm_provider else None
                }
            },
            "information_flows": len(self.information_flows),
            "features": {
                "streaming": True,
                "async_processing": True,
                "layer_communication": True,
                "memory_integration": self.memory_system is not None,
                "llm_integration": self.llm_provider is not None,
                "collaboration_support": self.collaboration_layer is not None
            }
        }

        # Ê∑ªÂä†ËÆ∞ÂøÜÁ≥ªÁªüËØ¶ÁªÜ‰ø°ÊÅØ
        if self.memory_system and hasattr(self.memory_system, 'get_system_info'):
            try:
                info["components"]["memory_system"]["details"] = self.memory_system.get_system_info()
            except Exception as e:
                info["components"]["memory_system"]["error"] = str(e)

        return info
