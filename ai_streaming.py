#!/usr/bin/env python3
"""
AiEnhance æµå¼å‘½ä»¤è¡Œå·¥å…·
æ”¯æŒå®æ—¶æµå¼è¾“å‡ºï¼Œæå‡é•¿æ—¶é—´å¤„ç†çš„ç”¨æˆ·ä½“éªŒ
"""

import aienhance
import asyncio
import sys
import argparse
from pathlib import Path
from typing import AsyncIterator
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))


class AiEnhanceStreamingCliTool:
    """AiEnhanceæµå¼å‘½ä»¤è¡Œå·¥å…·"""

    def __init__(self):
        self.system = None

    async def check_ollama(self):
        """æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€"""
        try:
            import httpx
            async with httpx.AsyncClient() as client:
                response = await client.get("http://localhost:11434/api/tags", timeout=3.0)
                if response.status_code == 200:
                    return True
                return False
        except:
            return False

    async def initialize_system(self, system_type="educational", temperature=0.7, use_memory=True):
        """åˆå§‹åŒ–åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿ"""
        try:
            if use_memory:
                # ä½¿ç”¨æ–°çš„åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿï¼ŒåŒ…å«å®Œæ•´åŠŸèƒ½
                print(f"ğŸ§  æ­£åœ¨åˆå§‹åŒ–åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿ (ç±»å‹: {system_type})...")
                if system_type == "educational":
                    self.system = aienhance.create_educational_layered_system(
                        model_name="qwen3:8b",
                        llm_temperature=temperature,
                        llm_max_tokens=800
                    )
                elif system_type == "research":
                    self.system = aienhance.create_research_layered_system(
                        model_name="qwen3:8b",
                        llm_temperature=temperature,
                        llm_max_tokens=800
                    )
                else:
                    # ä½¿ç”¨é€šç”¨åˆ†å±‚ç³»ç»Ÿ
                    self.system = aienhance.create_layered_system(
                        system_type=system_type,
                        memory_system_type="mirix_unified",
                        llm_provider="ollama",
                        llm_model_name="qwen3:8b",
                        llm_temperature=temperature,
                        llm_max_tokens=800
                    )
            else:
                # ç®€åŒ–é…ç½®ï¼Œä»…ä½¿ç”¨LLMåŠŸèƒ½
                print("âš ï¸  ç®€åŒ–æ¨¡å¼ï¼šä»…å¯ç”¨LLMåŠŸèƒ½ï¼Œä¸åŒ…å«è®°å¿†ç³»ç»Ÿ")
                # åˆ›å»ºè½»é‡çº§åˆ†å±‚ç³»ç»Ÿï¼ˆä¸ä½¿ç”¨è®°å¿†ï¼‰
                self.system = aienhance.create_layered_system(
                    system_type="lightweight",
                    llm_provider="ollama",
                    llm_model_name="qwen3:8b",
                    llm_temperature=temperature,
                    llm_max_tokens=800
                )
            
            # åˆå§‹åŒ–åˆ†å±‚ç³»ç»Ÿ
            success = await self.system.initialize_layers()
            if success:
                print("âœ… åˆ†å±‚è®¤çŸ¥ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
                print("   ğŸ“‹ æ„ŸçŸ¥å±‚: ç”¨æˆ·å»ºæ¨¡ä¸ä¸Šä¸‹æ–‡åˆ†æ")
                print("   ğŸ§  è®¤çŸ¥å±‚: è®°å¿†æ¿€æ´»ä¸è¯­ä¹‰å¢å¼º")
                print("   ğŸ¯ è¡Œä¸ºå±‚: å†…å®¹é€‚é…ä¸ç”Ÿæˆ")
                if system_type != "lightweight":
                    print("   ğŸ¤ åä½œå±‚: å¤šå…ƒè§‚ç‚¹ä¸è®¤çŸ¥æŒ‘æˆ˜")
                return True
            else:
                print("âŒ åˆ†å±‚ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
                return False
        except Exception as e:
            print(f"âŒ åˆ†å±‚ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            # å¦‚æœå®Œæ•´æ¨¡å¼å¤±è´¥ï¼Œå°è¯•ç®€åŒ–æ¨¡å¼
            if use_memory:
                print("ğŸ”„ å°è¯•è½»é‡çº§æ¨¡å¼...")
                return await self.initialize_system(system_type, temperature, use_memory=False)
            return False

    async def stream_query_processing(self, query: str, user_id: str, context: dict) -> AsyncIterator[str]:
        """æµå¼å¤„ç†æŸ¥è¯¢ï¼Œä½¿ç”¨åˆ†å±‚ç³»ç»Ÿçš„å¤„ç†æ–¹æ³•"""
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰æµå¼å¤„ç†æ–¹æ³•
            if hasattr(self.system, 'process_stream'):
                # ä½¿ç”¨ç³»ç»Ÿçš„æµå¼å¤„ç†æ–¹æ³•
                async for chunk in self.system.process_stream(
                    query=query,
                    user_id=user_id,
                    context=context,
                    yield_steps=True
                ):
                    yield chunk
            else:
                # ä½¿ç”¨æ ‡å‡†å¤„ç†æ–¹æ³•ï¼Œæ¨¡æ‹Ÿæµå¼è¾“å‡º
                yield "ğŸ“‹ æ„ŸçŸ¥å±‚å¤„ç†ä¸­...\n"
                
                yield "ğŸ§  è®¤çŸ¥å±‚æ¿€æ´»è®°å¿†...\n"
                yield "ğŸ¯ è¡Œä¸ºå±‚é€‚é…å†…å®¹...\n"
                
                # å¤„ç†æŸ¥è¯¢
                result = await self.system.process_through_layers(
                    query=query,
                    user_id=user_id,
                    context=context
                )
                
                if result and hasattr(result, 'final_output'):
                    # è·å–æœ€ç»ˆè¾“å‡ºå†…å®¹
                    content = result.final_output
                    
                    # æ¨¡æ‹Ÿæµå¼è¾“å‡ºï¼ŒæŒ‰å¥å­åˆ†å‰²
                    import re
                    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', content)
                    for sentence in sentences:
                        if sentence.strip():
                            yield sentence.strip() + "ã€‚"
                            await asyncio.sleep(0.08)  # æ¨¡æ‹Ÿæµå¼å»¶è¿Ÿ
                    
                    yield "\n"
                    
                    # å¦‚æœæœ‰åä½œå±‚ä¿¡æ¯
                    if hasattr(result, 'collaboration_output') and result.collaboration_output:
                        collab_out = result.collaboration_output
                        if hasattr(collab_out, 'enhanced_content') and collab_out.enhanced_content:
                            yield "\nğŸ¤ åä½œå¢å¼º:\n"
                            enhanced_sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', collab_out.enhanced_content)
                            for sentence in enhanced_sentences[:3]:  # é™åˆ¶åä½œå†…å®¹é•¿åº¦
                                if sentence.strip():
                                    yield sentence.strip() + "ã€‚"
                                    await asyncio.sleep(0.05)
                            yield "\n"
                else:
                    yield "æŠ±æ­‰ï¼Œç³»ç»Ÿå¤„ç†å‡ºç°é—®é¢˜ã€‚è¯·æ£€æŸ¥é…ç½®æˆ–ç¨åé‡è¯•ã€‚\n"
                
        except Exception as e:
            yield f"âŒ åˆ†å±‚ç³»ç»Ÿå¤„ç†å¤±è´¥: {e}\n"


    async def single_query_stream(self, query, system_type="educational", temperature=0.7, show_progress=True):
        """å•æ¬¡æµå¼æŸ¥è¯¢"""
        print("ğŸ”§ åˆå§‹åŒ–ç³»ç»Ÿ...")
        if not await self.initialize_system(system_type, temperature):
            return

        if show_progress:
            print("ğŸš€ å¼€å§‹æµå¼å¤„ç†...\n")
        
        try:
            # æµå¼å¤„ç†æŸ¥è¯¢
            async for chunk in self.stream_query_processing(
                query=query,
                user_id="cli_user",
                context={"source": "cli_streaming"}
            ):
                print(chunk, end='', flush=True)
                
            # èµ„æºå°†åœ¨ç³»ç»Ÿé€€å‡ºæ—¶è‡ªåŠ¨æ¸…ç†
                
        except Exception as e:
            print(f"\nâŒ æŸ¥è¯¢å¤„ç†å¤±è´¥: {e}")

    async def interactive_mode_stream(self, system_type="educational", temperature=0.7):
        """æµå¼äº¤äº’æ¨¡å¼"""
        print("ğŸš€ AiEnhance æµå¼äº¤äº’æ¨¡å¼")
        print("=" * 50)
        print("ğŸ’¡ æç¤º:")
        print("  â€¢ ç›´æ¥è¾“å…¥é—®é¢˜ï¼ŒæŒ‰å›è½¦å‘é€")
        print("  â€¢ è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("  â€¢ è¾“å…¥ 'clear' æ¸…å±")
        print("=" * 50)

        # åˆå§‹åŒ–ç³»ç»Ÿ
        print("ğŸ”§ åˆå§‹åŒ–ç³»ç»Ÿ...")
        if not await self.initialize_system(system_type, temperature):
            return
        print(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ (ç±»å‹: {system_type}, æ¸©åº¦: {temperature})")

        session_count = 0

        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input(f"\n[{session_count}] ğŸ‘¤ æ‚¨: ").strip()

                # å¤„ç†ç‰¹æ®Šå‘½ä»¤
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                    print("ğŸ‘‹ å†è§ï¼æ„Ÿè°¢ä½¿ç”¨AiEnhance")
                    break
                elif user_input.lower() == 'clear':
                    import os
                    os.system('clear' if os.name == 'posix' else 'cls')
                    continue
                elif not user_input:
                    continue

                # å¼€å§‹æµå¼å¤„ç†
                print(f"\nğŸ¤– AI: ", end='', flush=True)
                start_time = time.time()
                
                try:
                    async for chunk in self.stream_query_processing(
                        query=user_input,
                        user_id="interactive_user",
                        context={"session": session_count}
                    ):
                        # åªè¾“å‡ºå†…å®¹ï¼Œä¸è¾“å‡ºå¤„ç†æ­¥éª¤
                        if not chunk.startswith(('ğŸ§ ', 'ğŸ’¾', 'ğŸ”„', 'ğŸ¤–', 'ğŸ“', 'ğŸ¯')):
                            print(chunk, end='', flush=True)
                    
                    end_time = time.time()
                    print(f"\n    â±ï¸ å¤„ç†æ—¶é—´: {end_time - start_time:.1f}ç§’")
                    
                except Exception as e:
                    print(f"\nâŒ å¤„ç†é”™è¯¯: {e}")

                session_count += 1

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
                break
            except Exception as e:
                print(f"âŒ äº¤äº’é”™è¯¯: {e}")

    async def demo_mode_stream(self):
        """æµå¼æ¼”ç¤ºæ¨¡å¼"""
        print("ğŸ® AiEnhance æµå¼æ¼”ç¤ºæ¨¡å¼")
        print("=" * 50)

        # æ¼”ç¤ºæŸ¥è¯¢
        demo_queries = [
            ("åŸºç¡€é—®ç­”", "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"),
            ("çŸ¥è¯†è§£é‡Š", "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿè¯·ç®€å•è§£é‡Š"),
            ("åˆ›æ„æ€ç»´", "è®¾è®¡ä¸€ä¸ªæ™ºèƒ½å®¶å±…ç³»ç»Ÿçš„åŸºæœ¬æ–¹æ¡ˆ"),
            ("é—®é¢˜åˆ†æ", "åˆ†æä¸€ä¸‹è¿œç¨‹å·¥ä½œçš„åˆ©å¼Š")
        ]

        # åˆå§‹åŒ–ç³»ç»Ÿ
        print("ğŸ”§ åˆå§‹åŒ–æ¼”ç¤ºç³»ç»Ÿ...")
        if not await self.initialize_system("educational", 0.7):
            return
        print("âœ… ç³»ç»Ÿå°±ç»ª\n")

        for i, (category, query) in enumerate(demo_queries, 1):
            print(f"\n{i}ï¸âƒ£ {category}æ¼”ç¤º")
            print("-" * 30)
            print(f"ğŸ‘¤ ç”¨æˆ·: {query}")
            print(f"ğŸ¤– AI: ", end='', flush=True)

            try:
                async for chunk in self.stream_query_processing(
                    query=query,
                    user_id="demo_user",
                    context={"demo_type": category}
                ):
                    # åªè¾“å‡ºAIå›ç­”å†…å®¹
                    if not chunk.startswith(('ğŸ§ ', 'ğŸ’¾', 'ğŸ”„', 'ğŸ¤–', 'ğŸ“', 'ğŸ¯')):
                        print(chunk, end='', flush=True)

                print("\n" + "-" * 50)

                # çŸ­æš‚åœé¡¿
                if i < len(demo_queries):
                    await asyncio.sleep(2)

            except Exception as e:
                print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
                print("-" * 50)

        print("\nğŸ‰ æµå¼æ¼”ç¤ºå®Œæˆï¼")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="AiEnhance æµå¼å‘½ä»¤è¡Œå·¥å…· - è®°å¿†-è®¤çŸ¥ååŒç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python ai_streaming.py "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ"                    # æµå¼å•æ¬¡æŸ¥è¯¢
  python ai_streaming.py -i                                    # æµå¼äº¤äº’æ¨¡å¼  
  python ai_streaming.py -d                                    # æµå¼æ¼”ç¤ºæ¨¡å¼
  python ai_streaming.py "è§£é‡Šæ·±åº¦å­¦ä¹ " --type research        # ç ”ç©¶æ¨¡å¼æŸ¥è¯¢
  python ai_streaming.py "åˆ›æ„å†™ä½œ" --temp 0.9 --no-progress   # æ— è¿›åº¦æ˜¾ç¤º
        """
    )

    # ä½ç½®å‚æ•°
    parser.add_argument('query', nargs='?', help='è¦å¤„ç†çš„æŸ¥è¯¢é—®é¢˜')

    # å¯é€‰å‚æ•°
    parser.add_argument('-i', '--interactive',
                        action='store_true', help='å¯åŠ¨æµå¼äº¤äº’æ¨¡å¼')
    parser.add_argument('-d', '--demo', action='store_true', help='è¿è¡Œæµå¼æ¼”ç¤ºæ¨¡å¼')
    parser.add_argument('--type', 
                        choices=['educational', 'research', 'creative', 'lightweight'],
                        default='educational', help='åˆ†å±‚ç³»ç»Ÿç±»å‹ (é»˜è®¤: educational)')
    parser.add_argument('--temp', type=float, default=0.7,
                        help='æ¸©åº¦å‚æ•° 0.0-1.0 (é»˜è®¤: 0.7)')
    parser.add_argument('--no-progress', action='store_true', help='ä¸æ˜¾ç¤ºå¤„ç†è¿›åº¦')

    args = parser.parse_args()

    # åˆ›å»ºå·¥å…·å®ä¾‹
    tool = AiEnhanceStreamingCliTool()

    # æ£€æŸ¥OllamaæœåŠ¡
    print("ğŸ” æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€...")
    if not await tool.check_ollama():
        print("âŒ OllamaæœåŠ¡æœªè¿è¡Œæˆ–æ¨¡å‹æœªå®‰è£…")
        print("ğŸ’¡ è¯·ç¡®ä¿:")
        print("   1. OllamaæœåŠ¡è¿è¡Œ: ollama serve")
        print("   2. æ¨¡å‹å·²å®‰è£…: ollama pull qwen3:8b")
        return
    print("âœ… OllamaæœåŠ¡æ­£å¸¸")

    # æ ¹æ®å‚æ•°é€‰æ‹©æ¨¡å¼
    if args.interactive:
        await tool.interactive_mode_stream(args.type, args.temp)
    elif args.demo:
        await tool.demo_mode_stream()
    elif args.query:
        await tool.single_query_stream(args.query, args.type, args.temp, not args.no_progress)
    else:
        # é»˜è®¤æ˜¾ç¤ºå¸®åŠ©
        parser.print_help()
        print("\nğŸ’¡ å¿«é€Ÿå¼€å§‹:")
        print('  python ai_streaming.py "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½"')
        print("  python ai_streaming.py -i  # è¿›å…¥æµå¼äº¤äº’æ¨¡å¼")
        print("  python ai_streaming.py -d  # æŸ¥çœ‹æµå¼æ¼”ç¤º")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"âŒ ç¨‹åºé”™è¯¯: {e}")